[0;32mCMD> [0mbash tools/cmake/cmake-generate-proto-py-host.sh
CMAKE_VERSION: 3.22.1
CROSSTOOL_ROOT:
CMAKE_TOOLCHAIN_FILE:
CMAKE_INSTALL_PREFIX: /home/ana/nio2/mace/build/cmake-build/host/install
MACE_ENABLE_CPU            = ON
MACE_ENABLE_NEON           = OFF
MACE_ENABLE_QUANTIZE       = OFF
MACE_ENABLE_OPENCL         = OFF
MACE_ENABLE_CUDA           = OFF
MACE_ENABLE_HEXAGON_DSP    = OFF
MACE_ENABLE_HEXAGON_HTA    = OFF
MACE_ENABLE_MTK_APU        = OFF
MACE_ENABLE_BFLOAT16       = OFF
MACE_ENABLE_FP16           = OFF
MACE_ENABLE_QNN            =
MACE_ENABLE_TESTS          = ON
MACE_ENABLE_BENCHMARKS     = ON
MACE_ENABLE_OPT_SIZE       = ON
MACE_ENABLE_OBFUSCATE      = ON
MACE_ENABLE_CCACHE         = ON
MACE_ENABLE_CODE_MODE      = OFF
MACE_ENABLE_RPCMEM         = OFF
-- Configuring done
-- Generating done
-- Build files have been written to: /home/ana/nio2/mace/build/cmake-build/host
[ 66%] Built target protoc_bin
[100%] Built target mace_proto_py
[ 66%] Built target protoc_bin
[100%] Built target micro_mem_proto_py

[92m{'platform': <Platform.ONNX: 2>, 'model_file_path': 'build/bert/org_model/bert_modify.onnx-fdc6102a916d280bef55531682d526bb7168f203eeb942ed352f812ed7ab0f29.pb', 'model_sha256_checksum': 'fdc6102a916d280bef55531682d526bb7168f203eeb942ed352f812ed7ab0f29', 'subgraphs': {'default_graph': {'platform': <Platform.ONNX: 2>, 'model_file_path': 'build/bert/org_model/bert_modify.onnx-fdc6102a916d280bef55531682d526bb7168f203eeb942ed352f812ed7ab0f29.pb', 'model_sha256_checksum': 'fdc6102a916d280bef55531682d526bb7168f203eeb942ed352f812ed7ab0f29', 'runtime': <DeviceType.HEXAGON: 3>, 'quantize_range_file': 'build/bert/model/my_overall_range_bert-.pb', 'quantize': 1, 'limit_opencl_kernel_time': 0, 'nnlib_graph_mode': 0, 'obfuscate': 0, 'input_data_formats': [<DataFormat.NONE: 0>, <DataFormat.NONE: 0>, <DataFormat.NONE: 0>], 'input_ranges': [[-1.0, 1.0], [-1.0, 1.0], [-1.0, 1.0]], 'output_data_formats': [<DataFormat.NONE: 0>, <DataFormat.NONE: 0>], 'input_tensors': ['input_ids', 'attention_mask', 'token_type_ids'], 'output_tensors': ['last_hidden_state', 'pooler_output'], 'validation_inputs_data': ['/home/ana/nio2/workspace/bert/bert_data/inputs/input_ids.raw', '/home/ana/nio2/workspace/bert/bert_data/inputs/token_type_ids.raw', '/home/ana/nio2/workspace/bert/bert_data/inputs/attention_mask.raw'], 'data_type': 1, 'input_shapes': [[1, 6, 768], [1, 6, 768], [1, 1, 1, 6]], 'output_shapes': [[1, 6, 768], [1, 768]], 'backend': ['pytorch'], 'input_data_types': [1, 1, 1], 'output_data_types': [1, 1]}}, 'runtime': <DeviceType.HEXAGON: 3>, 'quantize_range_file': 'build/bert/model/my_overall_range_bert-.pb', 'quantize': 1, 'limit_opencl_kernel_time': 0, 'nnlib_graph_mode': 0, 'obfuscate': 0, 'input_data_formats': [], 'input_ranges': [], 'output_data_formats': [], 'input_tensors': ['input_ids', 'attention_mask', 'token_type_ids'], 'output_tensors': ['last_hidden_state', 'pooler_output'], 'validation_inputs_data': ['/home/ana/nio2/workspace/bert/bert_data/inputs/input_ids.raw', '/home/ana/nio2/workspace/bert/bert_data/inputs/token_type_ids.raw', '/home/ana/nio2/workspace/bert/bert_data/inputs/attention_mask.raw'], 'data_type': 1}[0m
Transform model to one that can better run on device
onnx model IR version:  7
constains ops domain:   version: 12
After convert shapeeeeeeeeeeee: /Mul_output_0 [1, 1, 1, 6]
After convert shapeeeeeeeeeeee: /embeddings/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /embeddings/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.0/attention/self/Div_output_0 [1, 12, 6, 6]
After convert shapeeeeeeeeeeee: /encoder/layer.0/attention/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.0/attention/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.0/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.0/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.1/attention/self/Div_output_0 [1, 12, 6, 6]
After convert shapeeeeeeeeeeee: /encoder/layer.1/attention/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.1/attention/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.1/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.1/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.2/attention/self/Div_output_0 [1, 12, 6, 6]
After convert shapeeeeeeeeeeee: /encoder/layer.2/attention/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.2/attention/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.2/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.2/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.3/attention/self/Div_output_0 [1, 12, 6, 6]
After convert shapeeeeeeeeeeee: /encoder/layer.3/attention/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.3/attention/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.3/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.3/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.4/attention/self/Div_output_0 [1, 12, 6, 6]
After convert shapeeeeeeeeeeee: /encoder/layer.4/attention/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.4/attention/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.4/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.4/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.5/attention/self/Div_output_0 [1, 12, 6, 6]
After convert shapeeeeeeeeeeee: /encoder/layer.5/attention/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.5/attention/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.5/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.5/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.6/attention/self/Div_output_0 [1, 12, 6, 6]
After convert shapeeeeeeeeeeee: /encoder/layer.6/attention/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.6/attention/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.6/intermediate/intermediate_act_fn/Div_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.6/intermediate/intermediate_act_fn/Add_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.6/intermediate/intermediate_act_fn/Mul_1_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.6/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.6/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.7/attention/self/Div_output_0 [1, 12, 6, 6]
After convert shapeeeeeeeeeeee: /encoder/layer.7/attention/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.7/attention/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.7/intermediate/intermediate_act_fn/Div_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.7/intermediate/intermediate_act_fn/Add_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.7/intermediate/intermediate_act_fn/Mul_1_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.7/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.7/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.8/attention/self/Div_output_0 [1, 12, 6, 6]
After convert shapeeeeeeeeeeee: /encoder/layer.8/attention/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.8/attention/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.8/intermediate/intermediate_act_fn/Div_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.8/intermediate/intermediate_act_fn/Add_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.8/intermediate/intermediate_act_fn/Mul_1_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.8/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.8/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.9/attention/self/Div_output_0 [1, 12, 6, 6]
After convert shapeeeeeeeeeeee: /encoder/layer.9/attention/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.9/attention/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.9/intermediate/intermediate_act_fn/Div_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.9/intermediate/intermediate_act_fn/Add_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.9/intermediate/intermediate_act_fn/Mul_1_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.9/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.9/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.10/attention/self/Div_output_0 [1, 12, 6, 6]
After convert shapeeeeeeeeeeee: /encoder/layer.10/attention/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.10/attention/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.10/intermediate/intermediate_act_fn/Div_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.10/intermediate/intermediate_act_fn/Add_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.10/intermediate/intermediate_act_fn/Mul_1_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.10/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.10/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.11/attention/self/Div_output_0 [1, 12, 6, 6]
After convert shapeeeeeeeeeeee: /encoder/layer.11/attention/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.11/attention/output/LayerNorm/Add_output_0 [1, 6, 1]
After convert shapeeeeeeeeeeee: /encoder/layer.11/intermediate/intermediate_act_fn/Div_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.11/intermediate/intermediate_act_fn/Add_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.11/intermediate/intermediate_act_fn/Mul_1_output_0 [1, 6, 3072]
After convert shapeeeeeeeeeeee: /encoder/layer.11/output/LayerNorm/Pow_output_0 [1, 6, 768]
After convert shapeeeeeeeeeeee: /encoder/layer.11/output/LayerNorm/Add_output_0 [1, 6, 1]
start convert gatherrrrrrrrrrrr
input: "last_hidden_state"
input: "/Constant_output_0"
output: "/pooler/Gather_output_0"
name: "/pooler/Gather"
type: "Gather"
arg {
  name: "T"
  i: 1
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 768
}

the type_arg of op: name: "activation"
s: "TANH"

encoder.layer.0.intermediate.dense.bias
/encoder/layer.0/intermediate/dense/MatMul_output_0
After fold shapeeeeeeeeee: [1, 6, 3072]
activation type of GELU: GELU name: "activation"
s: "GELU"

Fold Gelu: (Gelu_/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1),type: (Activation)
encoder.layer.1.intermediate.dense.bias
/encoder/layer.1/intermediate/dense/MatMul_output_0
After fold shapeeeeeeeeee: [1, 6, 3072]
activation type of GELU: GELU name: "activation"
s: "GELU"

Fold Gelu: (Gelu_/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1),type: (Activation)
encoder.layer.2.intermediate.dense.bias
/encoder/layer.2/intermediate/dense/MatMul_output_0
After fold shapeeeeeeeeee: [1, 6, 3072]
activation type of GELU: GELU name: "activation"
s: "GELU"

Fold Gelu: (Gelu_/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1),type: (Activation)
encoder.layer.3.intermediate.dense.bias
/encoder/layer.3/intermediate/dense/MatMul_output_0
After fold shapeeeeeeeeee: [1, 6, 3072]
activation type of GELU: GELU name: "activation"
s: "GELU"

Fold Gelu: (Gelu_/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1),type: (Activation)
encoder.layer.4.intermediate.dense.bias
/encoder/layer.4/intermediate/dense/MatMul_output_0
After fold shapeeeeeeeeee: [1, 6, 3072]
activation type of GELU: GELU name: "activation"
s: "GELU"

Fold Gelu: (Gelu_/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1),type: (Activation)
encoder.layer.5.intermediate.dense.bias
/encoder/layer.5/intermediate/dense/MatMul_output_0
After fold shapeeeeeeeeee: [1, 6, 3072]
activation type of GELU: GELU name: "activation"
s: "GELU"

Fold Gelu: (Gelu_/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1),type: (Activation)
encoder.layer.6.intermediate.dense.bias
/encoder/layer.6/intermediate/dense/MatMul_output_0
After fold shapeeeeeeeeee: [1, 6, 3072]
activation type of GELU: GELU name: "activation"
s: "GELU"

Fold Gelu: (Gelu_/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1),type: (Activation)
encoder.layer.7.intermediate.dense.bias
/encoder/layer.7/intermediate/dense/MatMul_output_0
After fold shapeeeeeeeeee: [1, 6, 3072]
activation type of GELU: GELU name: "activation"
s: "GELU"

Fold Gelu: (Gelu_/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1),type: (Activation)
encoder.layer.8.intermediate.dense.bias
/encoder/layer.8/intermediate/dense/MatMul_output_0
After fold shapeeeeeeeeee: [1, 6, 3072]
activation type of GELU: GELU name: "activation"
s: "GELU"

Fold Gelu: (Gelu_/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1),type: (Activation)
encoder.layer.9.intermediate.dense.bias
/encoder/layer.9/intermediate/dense/MatMul_output_0
After fold shapeeeeeeeeee: [1, 6, 3072]
activation type of GELU: GELU name: "activation"
s: "GELU"

Fold Gelu: (Gelu_/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1),type: (Activation)
encoder.layer.10.intermediate.dense.bias
/encoder/layer.10/intermediate/dense/MatMul_output_0
After fold shapeeeeeeeeee: [1, 6, 3072]
activation type of GELU: GELU name: "activation"
s: "GELU"

Fold Gelu: (Gelu_/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1),type: (Activation)
encoder.layer.11.intermediate.dense.bias
/encoder/layer.11/intermediate/dense/MatMul_output_0
After fold shapeeeeeeeeee: [1, 6, 3072]
activation type of GELU: GELU name: "activation"
s: "GELU"

Fold Gelu: (Gelu_/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1),type: (Activation)
Transform fake quantize
update op with float data type
Add OpenCL informations
update data format
/encoder/layer.0/attention/self/Reshape(Reshape) is not a transposable op in this model.
/encoder/layer.0/attention/self/Reshape_1(Reshape) is not a transposable op in this model.
/encoder/layer.0/attention/self/Reshape_2(Reshape) is not a transposable op in this model.
/encoder/layer.0/attention/self/Transpose_3(Transpose) is not a transposable op in this model.
/encoder/layer.0/attention/self/Reshape_3(Reshape) is not a transposable op in this model.
/encoder/layer.1/attention/self/Reshape(Reshape) is not a transposable op in this model.
/encoder/layer.1/attention/self/Reshape_1(Reshape) is not a transposable op in this model.
/encoder/layer.1/attention/self/Reshape_2(Reshape) is not a transposable op in this model.
/encoder/layer.1/attention/self/Transpose_3(Transpose) is not a transposable op in this model.
/encoder/layer.1/attention/self/Reshape_3(Reshape) is not a transposable op in this model.
/encoder/layer.2/attention/self/Reshape(Reshape) is not a transposable op in this model.
/encoder/layer.2/attention/self/Reshape_1(Reshape) is not a transposable op in this model.
/encoder/layer.2/attention/self/Reshape_2(Reshape) is not a transposable op in this model.
/encoder/layer.2/attention/self/Transpose_3(Transpose) is not a transposable op in this model.
/encoder/layer.2/attention/self/Reshape_3(Reshape) is not a transposable op in this model.
/encoder/layer.3/attention/self/Reshape(Reshape) is not a transposable op in this model.
/encoder/layer.3/attention/self/Reshape_1(Reshape) is not a transposable op in this model.
/encoder/layer.3/attention/self/Reshape_2(Reshape) is not a transposable op in this model.
/encoder/layer.3/attention/self/Transpose_3(Transpose) is not a transposable op in this model.
/encoder/layer.3/attention/self/Reshape_3(Reshape) is not a transposable op in this model.
/encoder/layer.4/attention/self/Reshape(Reshape) is not a transposable op in this model.
/encoder/layer.4/attention/self/Reshape_1(Reshape) is not a transposable op in this model.
/encoder/layer.4/attention/self/Reshape_2(Reshape) is not a transposable op in this model.
/encoder/layer.4/attention/self/Transpose_3(Transpose) is not a transposable op in this model.
/encoder/layer.4/attention/self/Reshape_3(Reshape) is not a transposable op in this model.
/encoder/layer.5/attention/self/Reshape(Reshape) is not a transposable op in this model.
/encoder/layer.5/attention/self/Reshape_1(Reshape) is not a transposable op in this model.
/encoder/layer.5/attention/self/Reshape_2(Reshape) is not a transposable op in this model.
/encoder/layer.5/attention/self/Transpose_3(Transpose) is not a transposable op in this model.
/encoder/layer.5/attention/self/Reshape_3(Reshape) is not a transposable op in this model.
/encoder/layer.6/attention/self/Reshape(Reshape) is not a transposable op in this model.
/encoder/layer.6/attention/self/Reshape_1(Reshape) is not a transposable op in this model.
/encoder/layer.6/attention/self/Reshape_2(Reshape) is not a transposable op in this model.
/encoder/layer.6/attention/self/Transpose_3(Transpose) is not a transposable op in this model.
/encoder/layer.6/attention/self/Reshape_3(Reshape) is not a transposable op in this model.
/encoder/layer.7/attention/self/Reshape(Reshape) is not a transposable op in this model.
/encoder/layer.7/attention/self/Reshape_1(Reshape) is not a transposable op in this model.
/encoder/layer.7/attention/self/Reshape_2(Reshape) is not a transposable op in this model.
/encoder/layer.7/attention/self/Transpose_3(Transpose) is not a transposable op in this model.
/encoder/layer.7/attention/self/Reshape_3(Reshape) is not a transposable op in this model.
/encoder/layer.8/attention/self/Reshape(Reshape) is not a transposable op in this model.
/encoder/layer.8/attention/self/Reshape_1(Reshape) is not a transposable op in this model.
/encoder/layer.8/attention/self/Reshape_2(Reshape) is not a transposable op in this model.
/encoder/layer.8/attention/self/Transpose_3(Transpose) is not a transposable op in this model.
/encoder/layer.8/attention/self/Reshape_3(Reshape) is not a transposable op in this model.
/encoder/layer.9/attention/self/Reshape(Reshape) is not a transposable op in this model.
/encoder/layer.9/attention/self/Reshape_1(Reshape) is not a transposable op in this model.
/encoder/layer.9/attention/self/Reshape_2(Reshape) is not a transposable op in this model.
/encoder/layer.9/attention/self/Transpose_3(Transpose) is not a transposable op in this model.
/encoder/layer.9/attention/self/Reshape_3(Reshape) is not a transposable op in this model.
/encoder/layer.10/attention/self/Reshape(Reshape) is not a transposable op in this model.
/encoder/layer.10/attention/self/Reshape_1(Reshape) is not a transposable op in this model.
/encoder/layer.10/attention/self/Reshape_2(Reshape) is not a transposable op in this model.
/encoder/layer.10/attention/self/Transpose_3(Transpose) is not a transposable op in this model.
/encoder/layer.10/attention/self/Reshape_3(Reshape) is not a transposable op in this model.
/encoder/layer.11/attention/self/Reshape(Reshape) is not a transposable op in this model.
/encoder/layer.11/attention/self/Reshape_1(Reshape) is not a transposable op in this model.
/encoder/layer.11/attention/self/Reshape_2(Reshape) is not a transposable op in this model.
/encoder/layer.11/attention/self/Transpose_3(Transpose) is not a transposable op in this model.
/encoder/layer.11/attention/self/Reshape_3(Reshape) is not a transposable op in this model.
Transpose arguments based on data format
Transpose filters to HWIO/HWIM
Sort by execution
Final ops:
/embeddings/Add (Eltwise, index:0): [[1, 6, 768]]
/embeddings/Add_1 (Eltwise, index:1): [[1, 6, 768]]
/embeddings/LayerNorm/ReduceMean (Reduce, index:2): [[1, 6, 1]]
/embeddings/LayerNorm/Sub (Eltwise, index:3): [[1, 6, 768]]
/embeddings/LayerNorm/Pow (Eltwise, index:4): [[1, 6, 768]]
/embeddings/LayerNorm/ReduceMean_1 (Reduce, index:5): [[1, 6, 1]]
/embeddings/LayerNorm/Add (Eltwise, index:6): [[1, 6, 1]]
/embeddings/LayerNorm/Sqrt (Eltwise, index:7): [[1, 6, 1]]
/embeddings/LayerNorm/Div (Eltwise, index:8): [[1, 6, 768]]
/embeddings/LayerNorm/Mul (Eltwise, index:9): [[1, 6, 768]]
/embeddings/LayerNorm/Add_1 (Eltwise, index:10): [[1, 6, 768]]
/encoder/layer.0/attention/self/query/MatMul (MatMul, index:11): [[1, 6, 768]]
/encoder/layer.0/attention/self/query/Add (Eltwise, index:12): [[1, 6, 768]]
/encoder/layer.0/attention/self/Reshape_2 (Reshape, index:13): [[1, 6, 12, 64]]
/encoder/layer.0/attention/self/Transpose_1 (Transpose, index:14): [[1, 12, 6, 64]]
/encoder/layer.0/attention/self/key/MatMul (MatMul, index:15): [[1, 6, 768]]
/encoder/layer.0/attention/self/key/Add (Eltwise, index:16): [[1, 6, 768]]
/encoder/layer.0/attention/self/Reshape (Reshape, index:17): [[1, 6, 12, 64]]
/encoder/layer.0/attention/self/Transpose_2 (Transpose, index:18): [[1, 12, 64, 6]]
/encoder/layer.0/attention/self/MatMul (MatMul, index:19): [[1, 12, 6, 6]]
/encoder/layer.0/attention/self/Div (Eltwise, index:20): [[1, 12, 6, 6]]
/Sub (Eltwise, index:21): [[1, 1, 1, 6]]
/Mul (Eltwise, index:22): [[1, 1, 1, 6]]
/encoder/layer.0/attention/self/Add (Eltwise, index:23): [[1, 12, 6, 6]]
/encoder/layer.0/attention/self/Softmax (Softmax, index:24): [[1, 12, 6, 6]]
/encoder/layer.0/attention/self/value/MatMul (MatMul, index:25): [[1, 6, 768]]
/encoder/layer.0/attention/self/value/Add (Eltwise, index:26): [[1, 6, 768]]
/encoder/layer.0/attention/self/Reshape_1 (Reshape, index:27): [[1, 6, 12, 64]]
/encoder/layer.0/attention/self/Transpose (Transpose, index:28): [[1, 12, 6, 64]]
/encoder/layer.0/attention/self/MatMul_1 (MatMul, index:29): [[1, 12, 6, 64]]
/encoder/layer.0/attention/self/Transpose_3 (Transpose, index:30): [[1, 6, 12, 64]]
/encoder/layer.0/attention/self/Reshape_3 (Reshape, index:31): [[1, 6, 768]]
/encoder/layer.0/attention/output/dense/MatMul (MatMul, index:32): [[1, 6, 768]]
/encoder/layer.0/attention/output/dense/Add (Eltwise, index:33): [[1, 6, 768]]
/encoder/layer.0/attention/output/Add (Eltwise, index:34): [[1, 6, 768]]
/encoder/layer.0/attention/output/LayerNorm/ReduceMean (Reduce, index:35): [[1, 6, 1]]
/encoder/layer.0/attention/output/LayerNorm/Sub (Eltwise, index:36): [[1, 6, 768]]
/encoder/layer.0/attention/output/LayerNorm/Pow (Eltwise, index:37): [[1, 6, 768]]
/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:38): [[1, 6, 1]]
/encoder/layer.0/attention/output/LayerNorm/Add (Eltwise, index:39): [[1, 6, 1]]
/encoder/layer.0/attention/output/LayerNorm/Sqrt (Eltwise, index:40): [[1, 6, 1]]
/encoder/layer.0/attention/output/LayerNorm/Div (Eltwise, index:41): [[1, 6, 768]]
/encoder/layer.0/attention/output/LayerNorm/Mul (Eltwise, index:42): [[1, 6, 768]]
/encoder/layer.0/attention/output/LayerNorm/Add_1 (Eltwise, index:43): [[1, 6, 768]]
/encoder/layer.0/intermediate/dense/MatMul (MatMul, index:44): [[1, 6, 3072]]
Gelu_/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1 (Activation, index:45): [[1, 6, 3072]]
/encoder/layer.0/output/dense/MatMul (MatMul, index:46): [[1, 6, 768]]
/encoder/layer.0/output/dense/Add (Eltwise, index:47): [[1, 6, 768]]
/encoder/layer.0/output/Add (Eltwise, index:48): [[1, 6, 768]]
/encoder/layer.0/output/LayerNorm/ReduceMean (Reduce, index:49): [[1, 6, 1]]
/encoder/layer.0/output/LayerNorm/Sub (Eltwise, index:50): [[1, 6, 768]]
/encoder/layer.0/output/LayerNorm/Pow (Eltwise, index:51): [[1, 6, 768]]
/encoder/layer.0/output/LayerNorm/ReduceMean_1 (Reduce, index:52): [[1, 6, 1]]
/encoder/layer.0/output/LayerNorm/Add (Eltwise, index:53): [[1, 6, 1]]
/encoder/layer.0/output/LayerNorm/Sqrt (Eltwise, index:54): [[1, 6, 1]]
/encoder/layer.0/output/LayerNorm/Div (Eltwise, index:55): [[1, 6, 768]]
/encoder/layer.0/output/LayerNorm/Mul (Eltwise, index:56): [[1, 6, 768]]
/encoder/layer.0/output/LayerNorm/Add_1 (Eltwise, index:57): [[1, 6, 768]]
/encoder/layer.1/attention/self/query/MatMul (MatMul, index:58): [[1, 6, 768]]
/encoder/layer.1/attention/self/query/Add (Eltwise, index:59): [[1, 6, 768]]
/encoder/layer.1/attention/self/Reshape_2 (Reshape, index:60): [[1, 6, 12, 64]]
/encoder/layer.1/attention/self/Transpose_1 (Transpose, index:61): [[1, 12, 6, 64]]
/encoder/layer.1/attention/self/key/MatMul (MatMul, index:62): [[1, 6, 768]]
/encoder/layer.1/attention/self/key/Add (Eltwise, index:63): [[1, 6, 768]]
/encoder/layer.1/attention/self/Reshape (Reshape, index:64): [[1, 6, 12, 64]]
/encoder/layer.1/attention/self/Transpose_2 (Transpose, index:65): [[1, 12, 64, 6]]
/encoder/layer.1/attention/self/MatMul (MatMul, index:66): [[1, 12, 6, 6]]
/encoder/layer.1/attention/self/Div (Eltwise, index:67): [[1, 12, 6, 6]]
/encoder/layer.1/attention/self/Add (Eltwise, index:68): [[1, 12, 6, 6]]
/encoder/layer.1/attention/self/Softmax (Softmax, index:69): [[1, 12, 6, 6]]
/encoder/layer.1/attention/self/value/MatMul (MatMul, index:70): [[1, 6, 768]]
/encoder/layer.1/attention/self/value/Add (Eltwise, index:71): [[1, 6, 768]]
/encoder/layer.1/attention/self/Reshape_1 (Reshape, index:72): [[1, 6, 12, 64]]
/encoder/layer.1/attention/self/Transpose (Transpose, index:73): [[1, 12, 6, 64]]
/encoder/layer.1/attention/self/MatMul_1 (MatMul, index:74): [[1, 12, 6, 64]]
/encoder/layer.1/attention/self/Transpose_3 (Transpose, index:75): [[1, 6, 12, 64]]
/encoder/layer.1/attention/self/Reshape_3 (Reshape, index:76): [[1, 6, 768]]
/encoder/layer.1/attention/output/dense/MatMul (MatMul, index:77): [[1, 6, 768]]
/encoder/layer.1/attention/output/dense/Add (Eltwise, index:78): [[1, 6, 768]]
/encoder/layer.1/attention/output/Add (Eltwise, index:79): [[1, 6, 768]]
/encoder/layer.1/attention/output/LayerNorm/ReduceMean (Reduce, index:80): [[1, 6, 1]]
/encoder/layer.1/attention/output/LayerNorm/Sub (Eltwise, index:81): [[1, 6, 768]]
/encoder/layer.1/attention/output/LayerNorm/Pow (Eltwise, index:82): [[1, 6, 768]]
/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:83): [[1, 6, 1]]
/encoder/layer.1/attention/output/LayerNorm/Add (Eltwise, index:84): [[1, 6, 1]]
/encoder/layer.1/attention/output/LayerNorm/Sqrt (Eltwise, index:85): [[1, 6, 1]]
/encoder/layer.1/attention/output/LayerNorm/Div (Eltwise, index:86): [[1, 6, 768]]
/encoder/layer.1/attention/output/LayerNorm/Mul (Eltwise, index:87): [[1, 6, 768]]
/encoder/layer.1/attention/output/LayerNorm/Add_1 (Eltwise, index:88): [[1, 6, 768]]
/encoder/layer.1/intermediate/dense/MatMul (MatMul, index:89): [[1, 6, 3072]]
Gelu_/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1 (Activation, index:90): [[1, 6, 3072]]
/encoder/layer.1/output/dense/MatMul (MatMul, index:91): [[1, 6, 768]]
/encoder/layer.1/output/dense/Add (Eltwise, index:92): [[1, 6, 768]]
/encoder/layer.1/output/Add (Eltwise, index:93): [[1, 6, 768]]
/encoder/layer.1/output/LayerNorm/ReduceMean (Reduce, index:94): [[1, 6, 1]]
/encoder/layer.1/output/LayerNorm/Sub (Eltwise, index:95): [[1, 6, 768]]
/encoder/layer.1/output/LayerNorm/Pow (Eltwise, index:96): [[1, 6, 768]]
/encoder/layer.1/output/LayerNorm/ReduceMean_1 (Reduce, index:97): [[1, 6, 1]]
/encoder/layer.1/output/LayerNorm/Add (Eltwise, index:98): [[1, 6, 1]]
/encoder/layer.1/output/LayerNorm/Sqrt (Eltwise, index:99): [[1, 6, 1]]
/encoder/layer.1/output/LayerNorm/Div (Eltwise, index:100): [[1, 6, 768]]
/encoder/layer.1/output/LayerNorm/Mul (Eltwise, index:101): [[1, 6, 768]]
/encoder/layer.1/output/LayerNorm/Add_1 (Eltwise, index:102): [[1, 6, 768]]
/encoder/layer.2/attention/self/query/MatMul (MatMul, index:103): [[1, 6, 768]]
/encoder/layer.2/attention/self/query/Add (Eltwise, index:104): [[1, 6, 768]]
/encoder/layer.2/attention/self/Reshape_2 (Reshape, index:105): [[1, 6, 12, 64]]
/encoder/layer.2/attention/self/Transpose_1 (Transpose, index:106): [[1, 12, 6, 64]]
/encoder/layer.2/attention/self/key/MatMul (MatMul, index:107): [[1, 6, 768]]
/encoder/layer.2/attention/self/key/Add (Eltwise, index:108): [[1, 6, 768]]
/encoder/layer.2/attention/self/Reshape (Reshape, index:109): [[1, 6, 12, 64]]
/encoder/layer.2/attention/self/Transpose_2 (Transpose, index:110): [[1, 12, 64, 6]]
/encoder/layer.2/attention/self/MatMul (MatMul, index:111): [[1, 12, 6, 6]]
/encoder/layer.2/attention/self/Div (Eltwise, index:112): [[1, 12, 6, 6]]
/encoder/layer.2/attention/self/Add (Eltwise, index:113): [[1, 12, 6, 6]]
/encoder/layer.2/attention/self/Softmax (Softmax, index:114): [[1, 12, 6, 6]]
/encoder/layer.2/attention/self/value/MatMul (MatMul, index:115): [[1, 6, 768]]
/encoder/layer.2/attention/self/value/Add (Eltwise, index:116): [[1, 6, 768]]
/encoder/layer.2/attention/self/Reshape_1 (Reshape, index:117): [[1, 6, 12, 64]]
/encoder/layer.2/attention/self/Transpose (Transpose, index:118): [[1, 12, 6, 64]]
/encoder/layer.2/attention/self/MatMul_1 (MatMul, index:119): [[1, 12, 6, 64]]
/encoder/layer.2/attention/self/Transpose_3 (Transpose, index:120): [[1, 6, 12, 64]]
/encoder/layer.2/attention/self/Reshape_3 (Reshape, index:121): [[1, 6, 768]]
/encoder/layer.2/attention/output/dense/MatMul (MatMul, index:122): [[1, 6, 768]]
/encoder/layer.2/attention/output/dense/Add (Eltwise, index:123): [[1, 6, 768]]
/encoder/layer.2/attention/output/Add (Eltwise, index:124): [[1, 6, 768]]
/encoder/layer.2/attention/output/LayerNorm/ReduceMean (Reduce, index:125): [[1, 6, 1]]
/encoder/layer.2/attention/output/LayerNorm/Sub (Eltwise, index:126): [[1, 6, 768]]
/encoder/layer.2/attention/output/LayerNorm/Pow (Eltwise, index:127): [[1, 6, 768]]
/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:128): [[1, 6, 1]]
/encoder/layer.2/attention/output/LayerNorm/Add (Eltwise, index:129): [[1, 6, 1]]
/encoder/layer.2/attention/output/LayerNorm/Sqrt (Eltwise, index:130): [[1, 6, 1]]
/encoder/layer.2/attention/output/LayerNorm/Div (Eltwise, index:131): [[1, 6, 768]]
/encoder/layer.2/attention/output/LayerNorm/Mul (Eltwise, index:132): [[1, 6, 768]]
/encoder/layer.2/attention/output/LayerNorm/Add_1 (Eltwise, index:133): [[1, 6, 768]]
/encoder/layer.2/intermediate/dense/MatMul (MatMul, index:134): [[1, 6, 3072]]
Gelu_/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1 (Activation, index:135): [[1, 6, 3072]]
/encoder/layer.2/output/dense/MatMul (MatMul, index:136): [[1, 6, 768]]
/encoder/layer.2/output/dense/Add (Eltwise, index:137): [[1, 6, 768]]
/encoder/layer.2/output/Add (Eltwise, index:138): [[1, 6, 768]]
/encoder/layer.2/output/LayerNorm/ReduceMean (Reduce, index:139): [[1, 6, 1]]
/encoder/layer.2/output/LayerNorm/Sub (Eltwise, index:140): [[1, 6, 768]]
/encoder/layer.2/output/LayerNorm/Pow (Eltwise, index:141): [[1, 6, 768]]
/encoder/layer.2/output/LayerNorm/ReduceMean_1 (Reduce, index:142): [[1, 6, 1]]
/encoder/layer.2/output/LayerNorm/Add (Eltwise, index:143): [[1, 6, 1]]
/encoder/layer.2/output/LayerNorm/Sqrt (Eltwise, index:144): [[1, 6, 1]]
/encoder/layer.2/output/LayerNorm/Div (Eltwise, index:145): [[1, 6, 768]]
/encoder/layer.2/output/LayerNorm/Mul (Eltwise, index:146): [[1, 6, 768]]
/encoder/layer.2/output/LayerNorm/Add_1 (Eltwise, index:147): [[1, 6, 768]]
/encoder/layer.3/attention/self/query/MatMul (MatMul, index:148): [[1, 6, 768]]
/encoder/layer.3/attention/self/query/Add (Eltwise, index:149): [[1, 6, 768]]
/encoder/layer.3/attention/self/Reshape_2 (Reshape, index:150): [[1, 6, 12, 64]]
/encoder/layer.3/attention/self/Transpose_1 (Transpose, index:151): [[1, 12, 6, 64]]
/encoder/layer.3/attention/self/key/MatMul (MatMul, index:152): [[1, 6, 768]]
/encoder/layer.3/attention/self/key/Add (Eltwise, index:153): [[1, 6, 768]]
/encoder/layer.3/attention/self/Reshape (Reshape, index:154): [[1, 6, 12, 64]]
/encoder/layer.3/attention/self/Transpose_2 (Transpose, index:155): [[1, 12, 64, 6]]
/encoder/layer.3/attention/self/MatMul (MatMul, index:156): [[1, 12, 6, 6]]
/encoder/layer.3/attention/self/Div (Eltwise, index:157): [[1, 12, 6, 6]]
/encoder/layer.3/attention/self/Add (Eltwise, index:158): [[1, 12, 6, 6]]
/encoder/layer.3/attention/self/Softmax (Softmax, index:159): [[1, 12, 6, 6]]
/encoder/layer.3/attention/self/value/MatMul (MatMul, index:160): [[1, 6, 768]]
/encoder/layer.3/attention/self/value/Add (Eltwise, index:161): [[1, 6, 768]]
/encoder/layer.3/attention/self/Reshape_1 (Reshape, index:162): [[1, 6, 12, 64]]
/encoder/layer.3/attention/self/Transpose (Transpose, index:163): [[1, 12, 6, 64]]
/encoder/layer.3/attention/self/MatMul_1 (MatMul, index:164): [[1, 12, 6, 64]]
/encoder/layer.3/attention/self/Transpose_3 (Transpose, index:165): [[1, 6, 12, 64]]
/encoder/layer.3/attention/self/Reshape_3 (Reshape, index:166): [[1, 6, 768]]
/encoder/layer.3/attention/output/dense/MatMul (MatMul, index:167): [[1, 6, 768]]
/encoder/layer.3/attention/output/dense/Add (Eltwise, index:168): [[1, 6, 768]]
/encoder/layer.3/attention/output/Add (Eltwise, index:169): [[1, 6, 768]]
/encoder/layer.3/attention/output/LayerNorm/ReduceMean (Reduce, index:170): [[1, 6, 1]]
/encoder/layer.3/attention/output/LayerNorm/Sub (Eltwise, index:171): [[1, 6, 768]]
/encoder/layer.3/attention/output/LayerNorm/Pow (Eltwise, index:172): [[1, 6, 768]]
/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:173): [[1, 6, 1]]
/encoder/layer.3/attention/output/LayerNorm/Add (Eltwise, index:174): [[1, 6, 1]]
/encoder/layer.3/attention/output/LayerNorm/Sqrt (Eltwise, index:175): [[1, 6, 1]]
/encoder/layer.3/attention/output/LayerNorm/Div (Eltwise, index:176): [[1, 6, 768]]
/encoder/layer.3/attention/output/LayerNorm/Mul (Eltwise, index:177): [[1, 6, 768]]
/encoder/layer.3/attention/output/LayerNorm/Add_1 (Eltwise, index:178): [[1, 6, 768]]
/encoder/layer.3/intermediate/dense/MatMul (MatMul, index:179): [[1, 6, 3072]]
Gelu_/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1 (Activation, index:180): [[1, 6, 3072]]
/encoder/layer.3/output/dense/MatMul (MatMul, index:181): [[1, 6, 768]]
/encoder/layer.3/output/dense/Add (Eltwise, index:182): [[1, 6, 768]]
/encoder/layer.3/output/Add (Eltwise, index:183): [[1, 6, 768]]
/encoder/layer.3/output/LayerNorm/ReduceMean (Reduce, index:184): [[1, 6, 1]]
/encoder/layer.3/output/LayerNorm/Sub (Eltwise, index:185): [[1, 6, 768]]
/encoder/layer.3/output/LayerNorm/Pow (Eltwise, index:186): [[1, 6, 768]]
/encoder/layer.3/output/LayerNorm/ReduceMean_1 (Reduce, index:187): [[1, 6, 1]]
/encoder/layer.3/output/LayerNorm/Add (Eltwise, index:188): [[1, 6, 1]]
/encoder/layer.3/output/LayerNorm/Sqrt (Eltwise, index:189): [[1, 6, 1]]
/encoder/layer.3/output/LayerNorm/Div (Eltwise, index:190): [[1, 6, 768]]
/encoder/layer.3/output/LayerNorm/Mul (Eltwise, index:191): [[1, 6, 768]]
/encoder/layer.3/output/LayerNorm/Add_1 (Eltwise, index:192): [[1, 6, 768]]
/encoder/layer.4/attention/self/query/MatMul (MatMul, index:193): [[1, 6, 768]]
/encoder/layer.4/attention/self/query/Add (Eltwise, index:194): [[1, 6, 768]]
/encoder/layer.4/attention/self/Reshape_2 (Reshape, index:195): [[1, 6, 12, 64]]
/encoder/layer.4/attention/self/Transpose_1 (Transpose, index:196): [[1, 12, 6, 64]]
/encoder/layer.4/attention/self/key/MatMul (MatMul, index:197): [[1, 6, 768]]
/encoder/layer.4/attention/self/key/Add (Eltwise, index:198): [[1, 6, 768]]
/encoder/layer.4/attention/self/Reshape (Reshape, index:199): [[1, 6, 12, 64]]
/encoder/layer.4/attention/self/Transpose_2 (Transpose, index:200): [[1, 12, 64, 6]]
/encoder/layer.4/attention/self/MatMul (MatMul, index:201): [[1, 12, 6, 6]]
/encoder/layer.4/attention/self/Div (Eltwise, index:202): [[1, 12, 6, 6]]
/encoder/layer.4/attention/self/Add (Eltwise, index:203): [[1, 12, 6, 6]]
/encoder/layer.4/attention/self/Softmax (Softmax, index:204): [[1, 12, 6, 6]]
/encoder/layer.4/attention/self/value/MatMul (MatMul, index:205): [[1, 6, 768]]
/encoder/layer.4/attention/self/value/Add (Eltwise, index:206): [[1, 6, 768]]
/encoder/layer.4/attention/self/Reshape_1 (Reshape, index:207): [[1, 6, 12, 64]]
/encoder/layer.4/attention/self/Transpose (Transpose, index:208): [[1, 12, 6, 64]]
/encoder/layer.4/attention/self/MatMul_1 (MatMul, index:209): [[1, 12, 6, 64]]
/encoder/layer.4/attention/self/Transpose_3 (Transpose, index:210): [[1, 6, 12, 64]]
/encoder/layer.4/attention/self/Reshape_3 (Reshape, index:211): [[1, 6, 768]]
/encoder/layer.4/attention/output/dense/MatMul (MatMul, index:212): [[1, 6, 768]]
/encoder/layer.4/attention/output/dense/Add (Eltwise, index:213): [[1, 6, 768]]
/encoder/layer.4/attention/output/Add (Eltwise, index:214): [[1, 6, 768]]
/encoder/layer.4/attention/output/LayerNorm/ReduceMean (Reduce, index:215): [[1, 6, 1]]
/encoder/layer.4/attention/output/LayerNorm/Sub (Eltwise, index:216): [[1, 6, 768]]
/encoder/layer.4/attention/output/LayerNorm/Pow (Eltwise, index:217): [[1, 6, 768]]
/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:218): [[1, 6, 1]]
/encoder/layer.4/attention/output/LayerNorm/Add (Eltwise, index:219): [[1, 6, 1]]
/encoder/layer.4/attention/output/LayerNorm/Sqrt (Eltwise, index:220): [[1, 6, 1]]
/encoder/layer.4/attention/output/LayerNorm/Div (Eltwise, index:221): [[1, 6, 768]]
/encoder/layer.4/attention/output/LayerNorm/Mul (Eltwise, index:222): [[1, 6, 768]]
/encoder/layer.4/attention/output/LayerNorm/Add_1 (Eltwise, index:223): [[1, 6, 768]]
/encoder/layer.4/intermediate/dense/MatMul (MatMul, index:224): [[1, 6, 3072]]
Gelu_/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1 (Activation, index:225): [[1, 6, 3072]]
/encoder/layer.4/output/dense/MatMul (MatMul, index:226): [[1, 6, 768]]
/encoder/layer.4/output/dense/Add (Eltwise, index:227): [[1, 6, 768]]
/encoder/layer.4/output/Add (Eltwise, index:228): [[1, 6, 768]]
/encoder/layer.4/output/LayerNorm/ReduceMean (Reduce, index:229): [[1, 6, 1]]
/encoder/layer.4/output/LayerNorm/Sub (Eltwise, index:230): [[1, 6, 768]]
/encoder/layer.4/output/LayerNorm/Pow (Eltwise, index:231): [[1, 6, 768]]
/encoder/layer.4/output/LayerNorm/ReduceMean_1 (Reduce, index:232): [[1, 6, 1]]
/encoder/layer.4/output/LayerNorm/Add (Eltwise, index:233): [[1, 6, 1]]
/encoder/layer.4/output/LayerNorm/Sqrt (Eltwise, index:234): [[1, 6, 1]]
/encoder/layer.4/output/LayerNorm/Div (Eltwise, index:235): [[1, 6, 768]]
/encoder/layer.4/output/LayerNorm/Mul (Eltwise, index:236): [[1, 6, 768]]
/encoder/layer.4/output/LayerNorm/Add_1 (Eltwise, index:237): [[1, 6, 768]]
/encoder/layer.5/attention/self/query/MatMul (MatMul, index:238): [[1, 6, 768]]
/encoder/layer.5/attention/self/query/Add (Eltwise, index:239): [[1, 6, 768]]
/encoder/layer.5/attention/self/Reshape_2 (Reshape, index:240): [[1, 6, 12, 64]]
/encoder/layer.5/attention/self/Transpose_1 (Transpose, index:241): [[1, 12, 6, 64]]
/encoder/layer.5/attention/self/key/MatMul (MatMul, index:242): [[1, 6, 768]]
/encoder/layer.5/attention/self/key/Add (Eltwise, index:243): [[1, 6, 768]]
/encoder/layer.5/attention/self/Reshape (Reshape, index:244): [[1, 6, 12, 64]]
/encoder/layer.5/attention/self/Transpose_2 (Transpose, index:245): [[1, 12, 64, 6]]
/encoder/layer.5/attention/self/MatMul (MatMul, index:246): [[1, 12, 6, 6]]
/encoder/layer.5/attention/self/Div (Eltwise, index:247): [[1, 12, 6, 6]]
/encoder/layer.5/attention/self/Add (Eltwise, index:248): [[1, 12, 6, 6]]
/encoder/layer.5/attention/self/Softmax (Softmax, index:249): [[1, 12, 6, 6]]
/encoder/layer.5/attention/self/value/MatMul (MatMul, index:250): [[1, 6, 768]]
/encoder/layer.5/attention/self/value/Add (Eltwise, index:251): [[1, 6, 768]]
/encoder/layer.5/attention/self/Reshape_1 (Reshape, index:252): [[1, 6, 12, 64]]
/encoder/layer.5/attention/self/Transpose (Transpose, index:253): [[1, 12, 6, 64]]
/encoder/layer.5/attention/self/MatMul_1 (MatMul, index:254): [[1, 12, 6, 64]]
/encoder/layer.5/attention/self/Transpose_3 (Transpose, index:255): [[1, 6, 12, 64]]
/encoder/layer.5/attention/self/Reshape_3 (Reshape, index:256): [[1, 6, 768]]
/encoder/layer.5/attention/output/dense/MatMul (MatMul, index:257): [[1, 6, 768]]
/encoder/layer.5/attention/output/dense/Add (Eltwise, index:258): [[1, 6, 768]]
/encoder/layer.5/attention/output/Add (Eltwise, index:259): [[1, 6, 768]]
/encoder/layer.5/attention/output/LayerNorm/ReduceMean (Reduce, index:260): [[1, 6, 1]]
/encoder/layer.5/attention/output/LayerNorm/Sub (Eltwise, index:261): [[1, 6, 768]]
/encoder/layer.5/attention/output/LayerNorm/Pow (Eltwise, index:262): [[1, 6, 768]]
/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:263): [[1, 6, 1]]
/encoder/layer.5/attention/output/LayerNorm/Add (Eltwise, index:264): [[1, 6, 1]]
/encoder/layer.5/attention/output/LayerNorm/Sqrt (Eltwise, index:265): [[1, 6, 1]]
/encoder/layer.5/attention/output/LayerNorm/Div (Eltwise, index:266): [[1, 6, 768]]
/encoder/layer.5/attention/output/LayerNorm/Mul (Eltwise, index:267): [[1, 6, 768]]
/encoder/layer.5/attention/output/LayerNorm/Add_1 (Eltwise, index:268): [[1, 6, 768]]
/encoder/layer.5/intermediate/dense/MatMul (MatMul, index:269): [[1, 6, 3072]]
Gelu_/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1 (Activation, index:270): [[1, 6, 3072]]
/encoder/layer.5/output/dense/MatMul (MatMul, index:271): [[1, 6, 768]]
/encoder/layer.5/output/dense/Add (Eltwise, index:272): [[1, 6, 768]]
/encoder/layer.5/output/Add (Eltwise, index:273): [[1, 6, 768]]
/encoder/layer.5/output/LayerNorm/ReduceMean (Reduce, index:274): [[1, 6, 1]]
/encoder/layer.5/output/LayerNorm/Sub (Eltwise, index:275): [[1, 6, 768]]
/encoder/layer.5/output/LayerNorm/Pow (Eltwise, index:276): [[1, 6, 768]]
/encoder/layer.5/output/LayerNorm/ReduceMean_1 (Reduce, index:277): [[1, 6, 1]]
/encoder/layer.5/output/LayerNorm/Add (Eltwise, index:278): [[1, 6, 1]]
/encoder/layer.5/output/LayerNorm/Sqrt (Eltwise, index:279): [[1, 6, 1]]
/encoder/layer.5/output/LayerNorm/Div (Eltwise, index:280): [[1, 6, 768]]
/encoder/layer.5/output/LayerNorm/Mul (Eltwise, index:281): [[1, 6, 768]]
/encoder/layer.5/output/LayerNorm/Add_1 (Eltwise, index:282): [[1, 6, 768]]
/encoder/layer.6/attention/self/query/MatMul (MatMul, index:283): [[1, 6, 768]]
/encoder/layer.6/attention/self/query/Add (Eltwise, index:284): [[1, 6, 768]]
/encoder/layer.6/attention/self/Reshape_2 (Reshape, index:285): [[1, 6, 12, 64]]
/encoder/layer.6/attention/self/Transpose_1 (Transpose, index:286): [[1, 12, 6, 64]]
/encoder/layer.6/attention/self/key/MatMul (MatMul, index:287): [[1, 6, 768]]
/encoder/layer.6/attention/self/key/Add (Eltwise, index:288): [[1, 6, 768]]
/encoder/layer.6/attention/self/Reshape (Reshape, index:289): [[1, 6, 12, 64]]
/encoder/layer.6/attention/self/Transpose_2 (Transpose, index:290): [[1, 12, 64, 6]]
/encoder/layer.6/attention/self/MatMul (MatMul, index:291): [[1, 12, 6, 6]]
/encoder/layer.6/attention/self/Div (Eltwise, index:292): [[1, 12, 6, 6]]
/encoder/layer.6/attention/self/Add (Eltwise, index:293): [[1, 12, 6, 6]]
/encoder/layer.6/attention/self/Softmax (Softmax, index:294): [[1, 12, 6, 6]]
/encoder/layer.6/attention/self/value/MatMul (MatMul, index:295): [[1, 6, 768]]
/encoder/layer.6/attention/self/value/Add (Eltwise, index:296): [[1, 6, 768]]
/encoder/layer.6/attention/self/Reshape_1 (Reshape, index:297): [[1, 6, 12, 64]]
/encoder/layer.6/attention/self/Transpose (Transpose, index:298): [[1, 12, 6, 64]]
/encoder/layer.6/attention/self/MatMul_1 (MatMul, index:299): [[1, 12, 6, 64]]
/encoder/layer.6/attention/self/Transpose_3 (Transpose, index:300): [[1, 6, 12, 64]]
/encoder/layer.6/attention/self/Reshape_3 (Reshape, index:301): [[1, 6, 768]]
/encoder/layer.6/attention/output/dense/MatMul (MatMul, index:302): [[1, 6, 768]]
/encoder/layer.6/attention/output/dense/Add (Eltwise, index:303): [[1, 6, 768]]
/encoder/layer.6/attention/output/Add (Eltwise, index:304): [[1, 6, 768]]
/encoder/layer.6/attention/output/LayerNorm/ReduceMean (Reduce, index:305): [[1, 6, 1]]
/encoder/layer.6/attention/output/LayerNorm/Sub (Eltwise, index:306): [[1, 6, 768]]
/encoder/layer.6/attention/output/LayerNorm/Pow (Eltwise, index:307): [[1, 6, 768]]
/encoder/layer.6/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:308): [[1, 6, 1]]
/encoder/layer.6/attention/output/LayerNorm/Add (Eltwise, index:309): [[1, 6, 1]]
/encoder/layer.6/attention/output/LayerNorm/Sqrt (Eltwise, index:310): [[1, 6, 1]]
/encoder/layer.6/attention/output/LayerNorm/Div (Eltwise, index:311): [[1, 6, 768]]
/encoder/layer.6/attention/output/LayerNorm/Mul (Eltwise, index:312): [[1, 6, 768]]
/encoder/layer.6/attention/output/LayerNorm/Add_1 (Eltwise, index:313): [[1, 6, 768]]
/encoder/layer.6/intermediate/dense/MatMul (MatMul, index:314): [[1, 6, 3072]]
Gelu_/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1 (Activation, index:315): [[1, 6, 3072]]
/encoder/layer.6/output/dense/MatMul (MatMul, index:316): [[1, 6, 768]]
/encoder/layer.6/output/dense/Add (Eltwise, index:317): [[1, 6, 768]]
/encoder/layer.6/output/Add (Eltwise, index:318): [[1, 6, 768]]
/encoder/layer.6/output/LayerNorm/ReduceMean (Reduce, index:319): [[1, 6, 1]]
/encoder/layer.6/output/LayerNorm/Sub (Eltwise, index:320): [[1, 6, 768]]
/encoder/layer.6/output/LayerNorm/Pow (Eltwise, index:321): [[1, 6, 768]]
/encoder/layer.6/output/LayerNorm/ReduceMean_1 (Reduce, index:322): [[1, 6, 1]]
/encoder/layer.6/output/LayerNorm/Add (Eltwise, index:323): [[1, 6, 1]]
/encoder/layer.6/output/LayerNorm/Sqrt (Eltwise, index:324): [[1, 6, 1]]
/encoder/layer.6/output/LayerNorm/Div (Eltwise, index:325): [[1, 6, 768]]
/encoder/layer.6/output/LayerNorm/Mul (Eltwise, index:326): [[1, 6, 768]]
/encoder/layer.6/output/LayerNorm/Add_1 (Eltwise, index:327): [[1, 6, 768]]
/encoder/layer.7/attention/self/query/MatMul (MatMul, index:328): [[1, 6, 768]]
/encoder/layer.7/attention/self/query/Add (Eltwise, index:329): [[1, 6, 768]]
/encoder/layer.7/attention/self/Reshape_2 (Reshape, index:330): [[1, 6, 12, 64]]
/encoder/layer.7/attention/self/Transpose_1 (Transpose, index:331): [[1, 12, 6, 64]]
/encoder/layer.7/attention/self/key/MatMul (MatMul, index:332): [[1, 6, 768]]
/encoder/layer.7/attention/self/key/Add (Eltwise, index:333): [[1, 6, 768]]
/encoder/layer.7/attention/self/Reshape (Reshape, index:334): [[1, 6, 12, 64]]
/encoder/layer.7/attention/self/Transpose_2 (Transpose, index:335): [[1, 12, 64, 6]]
/encoder/layer.7/attention/self/MatMul (MatMul, index:336): [[1, 12, 6, 6]]
/encoder/layer.7/attention/self/Div (Eltwise, index:337): [[1, 12, 6, 6]]
/encoder/layer.7/attention/self/Add (Eltwise, index:338): [[1, 12, 6, 6]]
/encoder/layer.7/attention/self/Softmax (Softmax, index:339): [[1, 12, 6, 6]]
/encoder/layer.7/attention/self/value/MatMul (MatMul, index:340): [[1, 6, 768]]
/encoder/layer.7/attention/self/value/Add (Eltwise, index:341): [[1, 6, 768]]
/encoder/layer.7/attention/self/Reshape_1 (Reshape, index:342): [[1, 6, 12, 64]]
/encoder/layer.7/attention/self/Transpose (Transpose, index:343): [[1, 12, 6, 64]]
/encoder/layer.7/attention/self/MatMul_1 (MatMul, index:344): [[1, 12, 6, 64]]
/encoder/layer.7/attention/self/Transpose_3 (Transpose, index:345): [[1, 6, 12, 64]]
/encoder/layer.7/attention/self/Reshape_3 (Reshape, index:346): [[1, 6, 768]]
/encoder/layer.7/attention/output/dense/MatMul (MatMul, index:347): [[1, 6, 768]]
/encoder/layer.7/attention/output/dense/Add (Eltwise, index:348): [[1, 6, 768]]
/encoder/layer.7/attention/output/Add (Eltwise, index:349): [[1, 6, 768]]
/encoder/layer.7/attention/output/LayerNorm/ReduceMean (Reduce, index:350): [[1, 6, 1]]
/encoder/layer.7/attention/output/LayerNorm/Sub (Eltwise, index:351): [[1, 6, 768]]
/encoder/layer.7/attention/output/LayerNorm/Pow (Eltwise, index:352): [[1, 6, 768]]
/encoder/layer.7/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:353): [[1, 6, 1]]
/encoder/layer.7/attention/output/LayerNorm/Add (Eltwise, index:354): [[1, 6, 1]]
/encoder/layer.7/attention/output/LayerNorm/Sqrt (Eltwise, index:355): [[1, 6, 1]]
/encoder/layer.7/attention/output/LayerNorm/Div (Eltwise, index:356): [[1, 6, 768]]
/encoder/layer.7/attention/output/LayerNorm/Mul (Eltwise, index:357): [[1, 6, 768]]
/encoder/layer.7/attention/output/LayerNorm/Add_1 (Eltwise, index:358): [[1, 6, 768]]
/encoder/layer.7/intermediate/dense/MatMul (MatMul, index:359): [[1, 6, 3072]]
Gelu_/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1 (Activation, index:360): [[1, 6, 3072]]
/encoder/layer.7/output/dense/MatMul (MatMul, index:361): [[1, 6, 768]]
/encoder/layer.7/output/dense/Add (Eltwise, index:362): [[1, 6, 768]]
/encoder/layer.7/output/Add (Eltwise, index:363): [[1, 6, 768]]
/encoder/layer.7/output/LayerNorm/ReduceMean (Reduce, index:364): [[1, 6, 1]]
/encoder/layer.7/output/LayerNorm/Sub (Eltwise, index:365): [[1, 6, 768]]
/encoder/layer.7/output/LayerNorm/Pow (Eltwise, index:366): [[1, 6, 768]]
/encoder/layer.7/output/LayerNorm/ReduceMean_1 (Reduce, index:367): [[1, 6, 1]]
/encoder/layer.7/output/LayerNorm/Add (Eltwise, index:368): [[1, 6, 1]]
/encoder/layer.7/output/LayerNorm/Sqrt (Eltwise, index:369): [[1, 6, 1]]
/encoder/layer.7/output/LayerNorm/Div (Eltwise, index:370): [[1, 6, 768]]
/encoder/layer.7/output/LayerNorm/Mul (Eltwise, index:371): [[1, 6, 768]]
/encoder/layer.7/output/LayerNorm/Add_1 (Eltwise, index:372): [[1, 6, 768]]
/encoder/layer.8/attention/self/query/MatMul (MatMul, index:373): [[1, 6, 768]]
/encoder/layer.8/attention/self/query/Add (Eltwise, index:374): [[1, 6, 768]]
/encoder/layer.8/attention/self/Reshape_2 (Reshape, index:375): [[1, 6, 12, 64]]
/encoder/layer.8/attention/self/Transpose_1 (Transpose, index:376): [[1, 12, 6, 64]]
/encoder/layer.8/attention/self/key/MatMul (MatMul, index:377): [[1, 6, 768]]
/encoder/layer.8/attention/self/key/Add (Eltwise, index:378): [[1, 6, 768]]
/encoder/layer.8/attention/self/Reshape (Reshape, index:379): [[1, 6, 12, 64]]
/encoder/layer.8/attention/self/Transpose_2 (Transpose, index:380): [[1, 12, 64, 6]]
/encoder/layer.8/attention/self/MatMul (MatMul, index:381): [[1, 12, 6, 6]]
/encoder/layer.8/attention/self/Div (Eltwise, index:382): [[1, 12, 6, 6]]
/encoder/layer.8/attention/self/Add (Eltwise, index:383): [[1, 12, 6, 6]]
/encoder/layer.8/attention/self/Softmax (Softmax, index:384): [[1, 12, 6, 6]]
/encoder/layer.8/attention/self/value/MatMul (MatMul, index:385): [[1, 6, 768]]
/encoder/layer.8/attention/self/value/Add (Eltwise, index:386): [[1, 6, 768]]
/encoder/layer.8/attention/self/Reshape_1 (Reshape, index:387): [[1, 6, 12, 64]]
/encoder/layer.8/attention/self/Transpose (Transpose, index:388): [[1, 12, 6, 64]]
/encoder/layer.8/attention/self/MatMul_1 (MatMul, index:389): [[1, 12, 6, 64]]
/encoder/layer.8/attention/self/Transpose_3 (Transpose, index:390): [[1, 6, 12, 64]]
/encoder/layer.8/attention/self/Reshape_3 (Reshape, index:391): [[1, 6, 768]]
/encoder/layer.8/attention/output/dense/MatMul (MatMul, index:392): [[1, 6, 768]]
/encoder/layer.8/attention/output/dense/Add (Eltwise, index:393): [[1, 6, 768]]
/encoder/layer.8/attention/output/Add (Eltwise, index:394): [[1, 6, 768]]
/encoder/layer.8/attention/output/LayerNorm/ReduceMean (Reduce, index:395): [[1, 6, 1]]
/encoder/layer.8/attention/output/LayerNorm/Sub (Eltwise, index:396): [[1, 6, 768]]
/encoder/layer.8/attention/output/LayerNorm/Pow (Eltwise, index:397): [[1, 6, 768]]
/encoder/layer.8/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:398): [[1, 6, 1]]
/encoder/layer.8/attention/output/LayerNorm/Add (Eltwise, index:399): [[1, 6, 1]]
/encoder/layer.8/attention/output/LayerNorm/Sqrt (Eltwise, index:400): [[1, 6, 1]]
/encoder/layer.8/attention/output/LayerNorm/Div (Eltwise, index:401): [[1, 6, 768]]
/encoder/layer.8/attention/output/LayerNorm/Mul (Eltwise, index:402): [[1, 6, 768]]
/encoder/layer.8/attention/output/LayerNorm/Add_1 (Eltwise, index:403): [[1, 6, 768]]
/encoder/layer.8/intermediate/dense/MatMul (MatMul, index:404): [[1, 6, 3072]]
Gelu_/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1 (Activation, index:405): [[1, 6, 3072]]
/encoder/layer.8/output/dense/MatMul (MatMul, index:406): [[1, 6, 768]]
/encoder/layer.8/output/dense/Add (Eltwise, index:407): [[1, 6, 768]]
/encoder/layer.8/output/Add (Eltwise, index:408): [[1, 6, 768]]
/encoder/layer.8/output/LayerNorm/ReduceMean (Reduce, index:409): [[1, 6, 1]]
/encoder/layer.8/output/LayerNorm/Sub (Eltwise, index:410): [[1, 6, 768]]
/encoder/layer.8/output/LayerNorm/Pow (Eltwise, index:411): [[1, 6, 768]]
/encoder/layer.8/output/LayerNorm/ReduceMean_1 (Reduce, index:412): [[1, 6, 1]]
/encoder/layer.8/output/LayerNorm/Add (Eltwise, index:413): [[1, 6, 1]]
/encoder/layer.8/output/LayerNorm/Sqrt (Eltwise, index:414): [[1, 6, 1]]
/encoder/layer.8/output/LayerNorm/Div (Eltwise, index:415): [[1, 6, 768]]
/encoder/layer.8/output/LayerNorm/Mul (Eltwise, index:416): [[1, 6, 768]]
/encoder/layer.8/output/LayerNorm/Add_1 (Eltwise, index:417): [[1, 6, 768]]
/encoder/layer.9/attention/self/query/MatMul (MatMul, index:418): [[1, 6, 768]]
/encoder/layer.9/attention/self/query/Add (Eltwise, index:419): [[1, 6, 768]]
/encoder/layer.9/attention/self/Reshape_2 (Reshape, index:420): [[1, 6, 12, 64]]
/encoder/layer.9/attention/self/Transpose_1 (Transpose, index:421): [[1, 12, 6, 64]]
/encoder/layer.9/attention/self/key/MatMul (MatMul, index:422): [[1, 6, 768]]
/encoder/layer.9/attention/self/key/Add (Eltwise, index:423): [[1, 6, 768]]
/encoder/layer.9/attention/self/Reshape (Reshape, index:424): [[1, 6, 12, 64]]
/encoder/layer.9/attention/self/Transpose_2 (Transpose, index:425): [[1, 12, 64, 6]]
/encoder/layer.9/attention/self/MatMul (MatMul, index:426): [[1, 12, 6, 6]]
/encoder/layer.9/attention/self/Div (Eltwise, index:427): [[1, 12, 6, 6]]
/encoder/layer.9/attention/self/Add (Eltwise, index:428): [[1, 12, 6, 6]]
/encoder/layer.9/attention/self/Softmax (Softmax, index:429): [[1, 12, 6, 6]]
/encoder/layer.9/attention/self/value/MatMul (MatMul, index:430): [[1, 6, 768]]
/encoder/layer.9/attention/self/value/Add (Eltwise, index:431): [[1, 6, 768]]
/encoder/layer.9/attention/self/Reshape_1 (Reshape, index:432): [[1, 6, 12, 64]]
/encoder/layer.9/attention/self/Transpose (Transpose, index:433): [[1, 12, 6, 64]]
/encoder/layer.9/attention/self/MatMul_1 (MatMul, index:434): [[1, 12, 6, 64]]
/encoder/layer.9/attention/self/Transpose_3 (Transpose, index:435): [[1, 6, 12, 64]]
/encoder/layer.9/attention/self/Reshape_3 (Reshape, index:436): [[1, 6, 768]]
/encoder/layer.9/attention/output/dense/MatMul (MatMul, index:437): [[1, 6, 768]]
/encoder/layer.9/attention/output/dense/Add (Eltwise, index:438): [[1, 6, 768]]
/encoder/layer.9/attention/output/Add (Eltwise, index:439): [[1, 6, 768]]
/encoder/layer.9/attention/output/LayerNorm/ReduceMean (Reduce, index:440): [[1, 6, 1]]
/encoder/layer.9/attention/output/LayerNorm/Sub (Eltwise, index:441): [[1, 6, 768]]
/encoder/layer.9/attention/output/LayerNorm/Pow (Eltwise, index:442): [[1, 6, 768]]
/encoder/layer.9/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:443): [[1, 6, 1]]
/encoder/layer.9/attention/output/LayerNorm/Add (Eltwise, index:444): [[1, 6, 1]]
/encoder/layer.9/attention/output/LayerNorm/Sqrt (Eltwise, index:445): [[1, 6, 1]]
/encoder/layer.9/attention/output/LayerNorm/Div (Eltwise, index:446): [[1, 6, 768]]
/encoder/layer.9/attention/output/LayerNorm/Mul (Eltwise, index:447): [[1, 6, 768]]
/encoder/layer.9/attention/output/LayerNorm/Add_1 (Eltwise, index:448): [[1, 6, 768]]
/encoder/layer.9/intermediate/dense/MatMul (MatMul, index:449): [[1, 6, 3072]]
Gelu_/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1 (Activation, index:450): [[1, 6, 3072]]
/encoder/layer.9/output/dense/MatMul (MatMul, index:451): [[1, 6, 768]]
/encoder/layer.9/output/dense/Add (Eltwise, index:452): [[1, 6, 768]]
/encoder/layer.9/output/Add (Eltwise, index:453): [[1, 6, 768]]
/encoder/layer.9/output/LayerNorm/ReduceMean (Reduce, index:454): [[1, 6, 1]]
/encoder/layer.9/output/LayerNorm/Sub (Eltwise, index:455): [[1, 6, 768]]
/encoder/layer.9/output/LayerNorm/Pow (Eltwise, index:456): [[1, 6, 768]]
/encoder/layer.9/output/LayerNorm/ReduceMean_1 (Reduce, index:457): [[1, 6, 1]]
/encoder/layer.9/output/LayerNorm/Add (Eltwise, index:458): [[1, 6, 1]]
/encoder/layer.9/output/LayerNorm/Sqrt (Eltwise, index:459): [[1, 6, 1]]
/encoder/layer.9/output/LayerNorm/Div (Eltwise, index:460): [[1, 6, 768]]
/encoder/layer.9/output/LayerNorm/Mul (Eltwise, index:461): [[1, 6, 768]]
/encoder/layer.9/output/LayerNorm/Add_1 (Eltwise, index:462): [[1, 6, 768]]
/encoder/layer.10/attention/self/query/MatMul (MatMul, index:463): [[1, 6, 768]]
/encoder/layer.10/attention/self/query/Add (Eltwise, index:464): [[1, 6, 768]]
/encoder/layer.10/attention/self/Reshape_2 (Reshape, index:465): [[1, 6, 12, 64]]
/encoder/layer.10/attention/self/Transpose_1 (Transpose, index:466): [[1, 12, 6, 64]]
/encoder/layer.10/attention/self/key/MatMul (MatMul, index:467): [[1, 6, 768]]
/encoder/layer.10/attention/self/key/Add (Eltwise, index:468): [[1, 6, 768]]
/encoder/layer.10/attention/self/Reshape (Reshape, index:469): [[1, 6, 12, 64]]
/encoder/layer.10/attention/self/Transpose_2 (Transpose, index:470): [[1, 12, 64, 6]]
/encoder/layer.10/attention/self/MatMul (MatMul, index:471): [[1, 12, 6, 6]]
/encoder/layer.10/attention/self/Div (Eltwise, index:472): [[1, 12, 6, 6]]
/encoder/layer.10/attention/self/Add (Eltwise, index:473): [[1, 12, 6, 6]]
/encoder/layer.10/attention/self/Softmax (Softmax, index:474): [[1, 12, 6, 6]]
/encoder/layer.10/attention/self/value/MatMul (MatMul, index:475): [[1, 6, 768]]
/encoder/layer.10/attention/self/value/Add (Eltwise, index:476): [[1, 6, 768]]
/encoder/layer.10/attention/self/Reshape_1 (Reshape, index:477): [[1, 6, 12, 64]]
/encoder/layer.10/attention/self/Transpose (Transpose, index:478): [[1, 12, 6, 64]]
/encoder/layer.10/attention/self/MatMul_1 (MatMul, index:479): [[1, 12, 6, 64]]
/encoder/layer.10/attention/self/Transpose_3 (Transpose, index:480): [[1, 6, 12, 64]]
/encoder/layer.10/attention/self/Reshape_3 (Reshape, index:481): [[1, 6, 768]]
/encoder/layer.10/attention/output/dense/MatMul (MatMul, index:482): [[1, 6, 768]]
/encoder/layer.10/attention/output/dense/Add (Eltwise, index:483): [[1, 6, 768]]
/encoder/layer.10/attention/output/Add (Eltwise, index:484): [[1, 6, 768]]
/encoder/layer.10/attention/output/LayerNorm/ReduceMean (Reduce, index:485): [[1, 6, 1]]
/encoder/layer.10/attention/output/LayerNorm/Sub (Eltwise, index:486): [[1, 6, 768]]
/encoder/layer.10/attention/output/LayerNorm/Pow (Eltwise, index:487): [[1, 6, 768]]
/encoder/layer.10/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:488): [[1, 6, 1]]
/encoder/layer.10/attention/output/LayerNorm/Add (Eltwise, index:489): [[1, 6, 1]]
/encoder/layer.10/attention/output/LayerNorm/Sqrt (Eltwise, index:490): [[1, 6, 1]]
/encoder/layer.10/attention/output/LayerNorm/Div (Eltwise, index:491): [[1, 6, 768]]
/encoder/layer.10/attention/output/LayerNorm/Mul (Eltwise, index:492): [[1, 6, 768]]
/encoder/layer.10/attention/output/LayerNorm/Add_1 (Eltwise, index:493): [[1, 6, 768]]
/encoder/layer.10/intermediate/dense/MatMul (MatMul, index:494): [[1, 6, 3072]]
Gelu_/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1 (Activation, index:495): [[1, 6, 3072]]
/encoder/layer.10/output/dense/MatMul (MatMul, index:496): [[1, 6, 768]]
/encoder/layer.10/output/dense/Add (Eltwise, index:497): [[1, 6, 768]]
/encoder/layer.10/output/Add (Eltwise, index:498): [[1, 6, 768]]
/encoder/layer.10/output/LayerNorm/ReduceMean (Reduce, index:499): [[1, 6, 1]]
/encoder/layer.10/output/LayerNorm/Sub (Eltwise, index:500): [[1, 6, 768]]
/encoder/layer.10/output/LayerNorm/Pow (Eltwise, index:501): [[1, 6, 768]]
/encoder/layer.10/output/LayerNorm/ReduceMean_1 (Reduce, index:502): [[1, 6, 1]]
/encoder/layer.10/output/LayerNorm/Add (Eltwise, index:503): [[1, 6, 1]]
/encoder/layer.10/output/LayerNorm/Sqrt (Eltwise, index:504): [[1, 6, 1]]
/encoder/layer.10/output/LayerNorm/Div (Eltwise, index:505): [[1, 6, 768]]
/encoder/layer.10/output/LayerNorm/Mul (Eltwise, index:506): [[1, 6, 768]]
/encoder/layer.10/output/LayerNorm/Add_1 (Eltwise, index:507): [[1, 6, 768]]
/encoder/layer.11/attention/self/query/MatMul (MatMul, index:508): [[1, 6, 768]]
/encoder/layer.11/attention/self/query/Add (Eltwise, index:509): [[1, 6, 768]]
/encoder/layer.11/attention/self/Reshape_2 (Reshape, index:510): [[1, 6, 12, 64]]
/encoder/layer.11/attention/self/Transpose_1 (Transpose, index:511): [[1, 12, 6, 64]]
/encoder/layer.11/attention/self/key/MatMul (MatMul, index:512): [[1, 6, 768]]
/encoder/layer.11/attention/self/key/Add (Eltwise, index:513): [[1, 6, 768]]
/encoder/layer.11/attention/self/Reshape (Reshape, index:514): [[1, 6, 12, 64]]
/encoder/layer.11/attention/self/Transpose_2 (Transpose, index:515): [[1, 12, 64, 6]]
/encoder/layer.11/attention/self/MatMul (MatMul, index:516): [[1, 12, 6, 6]]
/encoder/layer.11/attention/self/Div (Eltwise, index:517): [[1, 12, 6, 6]]
/encoder/layer.11/attention/self/Add (Eltwise, index:518): [[1, 12, 6, 6]]
/encoder/layer.11/attention/self/Softmax (Softmax, index:519): [[1, 12, 6, 6]]
/encoder/layer.11/attention/self/value/MatMul (MatMul, index:520): [[1, 6, 768]]
/encoder/layer.11/attention/self/value/Add (Eltwise, index:521): [[1, 6, 768]]
/encoder/layer.11/attention/self/Reshape_1 (Reshape, index:522): [[1, 6, 12, 64]]
/encoder/layer.11/attention/self/Transpose (Transpose, index:523): [[1, 12, 6, 64]]
/encoder/layer.11/attention/self/MatMul_1 (MatMul, index:524): [[1, 12, 6, 64]]
/encoder/layer.11/attention/self/Transpose_3 (Transpose, index:525): [[1, 6, 12, 64]]
/encoder/layer.11/attention/self/Reshape_3 (Reshape, index:526): [[1, 6, 768]]
/encoder/layer.11/attention/output/dense/MatMul (MatMul, index:527): [[1, 6, 768]]
/encoder/layer.11/attention/output/dense/Add (Eltwise, index:528): [[1, 6, 768]]
/encoder/layer.11/attention/output/Add (Eltwise, index:529): [[1, 6, 768]]
/encoder/layer.11/attention/output/LayerNorm/ReduceMean (Reduce, index:530): [[1, 6, 1]]
/encoder/layer.11/attention/output/LayerNorm/Sub (Eltwise, index:531): [[1, 6, 768]]
/encoder/layer.11/attention/output/LayerNorm/Pow (Eltwise, index:532): [[1, 6, 768]]
/encoder/layer.11/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:533): [[1, 6, 1]]
/encoder/layer.11/attention/output/LayerNorm/Add (Eltwise, index:534): [[1, 6, 1]]
/encoder/layer.11/attention/output/LayerNorm/Sqrt (Eltwise, index:535): [[1, 6, 1]]
/encoder/layer.11/attention/output/LayerNorm/Div (Eltwise, index:536): [[1, 6, 768]]
/encoder/layer.11/attention/output/LayerNorm/Mul (Eltwise, index:537): [[1, 6, 768]]
/encoder/layer.11/attention/output/LayerNorm/Add_1 (Eltwise, index:538): [[1, 6, 768]]
/encoder/layer.11/intermediate/dense/MatMul (MatMul, index:539): [[1, 6, 3072]]
Gelu_/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1 (Activation, index:540): [[1, 6, 3072]]
/encoder/layer.11/output/dense/MatMul (MatMul, index:541): [[1, 6, 768]]
/encoder/layer.11/output/dense/Add (Eltwise, index:542): [[1, 6, 768]]
/encoder/layer.11/output/Add (Eltwise, index:543): [[1, 6, 768]]
/encoder/layer.11/output/LayerNorm/ReduceMean (Reduce, index:544): [[1, 6, 1]]
/encoder/layer.11/output/LayerNorm/Sub (Eltwise, index:545): [[1, 6, 768]]
/encoder/layer.11/output/LayerNorm/Pow (Eltwise, index:546): [[1, 6, 768]]
/encoder/layer.11/output/LayerNorm/ReduceMean_1 (Reduce, index:547): [[1, 6, 1]]
/encoder/layer.11/output/LayerNorm/Add (Eltwise, index:548): [[1, 6, 1]]
/encoder/layer.11/output/LayerNorm/Sqrt (Eltwise, index:549): [[1, 6, 1]]
/encoder/layer.11/output/LayerNorm/Div (Eltwise, index:550): [[1, 6, 768]]
/encoder/layer.11/output/LayerNorm/Mul (Eltwise, index:551): [[1, 6, 768]]
/encoder/layer.11/output/LayerNorm/Add_1 (Eltwise, index:552): [[1, 6, 768]]
/pooler/Gather (Gather, index:553): [[1, 1, 768]]
/pooler/dense/Gemm (MatMul, index:554): [[1, 768]]
/pooler/activation/Tanh (Activation, index:555): [[1, 768]]
Add quantize tensor range
Add default quantize info for input
Input range input_ids: [-1.0, 1.0]
Input range attention_mask: [-1.0, 1.0]
Input range token_type_ids: [-1.0, 1.0]
Add default quantize info for ops like Pooling, Softmax
Add mace quantize and dequantize nodes
Quantize weights
Sort by execution
Final ops:
mace_input_node_input_ids (Quantize, index:): [[1, 6, 768]]
mace_input_node_attention_mask (Quantize, index:): [[1, 6, 768]]
/embeddings/Add (Eltwise, index:0): [[1, 6, 768]]
/embeddings/Add_1 (Eltwise, index:1): [[1, 6, 768]]
/embeddings/LayerNorm/ReduceMean (Reduce, index:2): [[1, 6, 1]]
/embeddings/LayerNorm/Sub (Eltwise, index:3): [[1, 6, 768]]
/embeddings/LayerNorm/Pow (Eltwise, index:4): [[1, 6, 768]]
/embeddings/LayerNorm/ReduceMean_1 (Reduce, index:5): [[1, 6, 1]]
/embeddings/LayerNorm/Add (Eltwise, index:6): [[1, 6, 1]]
/embeddings/LayerNorm/Sqrt (Eltwise, index:7): [[1, 6, 1]]
/embeddings/LayerNorm/Div (Eltwise, index:8): [[1, 6, 768]]
/embeddings/LayerNorm/Mul (Eltwise, index:9): [[1, 6, 768]]
/embeddings/LayerNorm/Add_1 (Eltwise, index:10): [[1, 6, 768]]
/encoder/layer.0/attention/self/query/MatMul (MatMul, index:11): [[1, 6, 768]]
/encoder/layer.0/attention/self/query/Add (Eltwise, index:12): [[1, 6, 768]]
/encoder/layer.0/attention/self/Reshape_2 (Reshape, index:13): [[1, 6, 12, 64]]
/encoder/layer.0/attention/self/Transpose_1 (Transpose, index:14): [[1, 12, 6, 64]]
/encoder/layer.0/attention/self/key/MatMul (MatMul, index:15): [[1, 6, 768]]
/encoder/layer.0/attention/self/key/Add (Eltwise, index:16): [[1, 6, 768]]
/encoder/layer.0/attention/self/Reshape (Reshape, index:17): [[1, 6, 12, 64]]
/encoder/layer.0/attention/self/Transpose_2 (Transpose, index:18): [[1, 12, 64, 6]]
/encoder/layer.0/attention/self/MatMul (MatMul, index:19): [[1, 12, 6, 6]]
/encoder/layer.0/attention/self/Div (Eltwise, index:20): [[1, 12, 6, 6]]
mace_input_node_token_type_ids (Quantize, index:): [[1, 1, 1, 6]]
/Sub (Eltwise, index:21): [[1, 1, 1, 6]]
/Mul (Eltwise, index:22): [[1, 1, 1, 6]]
/encoder/layer.0/attention/self/Add (Eltwise, index:23): [[1, 12, 6, 6]]
/encoder/layer.0/attention/self/Softmax (Softmax, index:24): [[1, 12, 6, 6]]
/encoder/layer.0/attention/self/value/MatMul (MatMul, index:25): [[1, 6, 768]]
/encoder/layer.0/attention/self/value/Add (Eltwise, index:26): [[1, 6, 768]]
/encoder/layer.0/attention/self/Reshape_1 (Reshape, index:27): [[1, 6, 12, 64]]
/encoder/layer.0/attention/self/Transpose (Transpose, index:28): [[1, 12, 6, 64]]
/encoder/layer.0/attention/self/MatMul_1 (MatMul, index:29): [[1, 12, 6, 64]]
/encoder/layer.0/attention/self/Transpose_3 (Transpose, index:30): [[1, 6, 12, 64]]
/encoder/layer.0/attention/self/Reshape_3 (Reshape, index:31): [[1, 6, 768]]
/encoder/layer.0/attention/output/dense/MatMul (MatMul, index:32): [[1, 6, 768]]
/encoder/layer.0/attention/output/dense/Add (Eltwise, index:33): [[1, 6, 768]]
/encoder/layer.0/attention/output/Add (Eltwise, index:34): [[1, 6, 768]]
/encoder/layer.0/attention/output/LayerNorm/ReduceMean (Reduce, index:35): [[1, 6, 1]]
/encoder/layer.0/attention/output/LayerNorm/Sub (Eltwise, index:36): [[1, 6, 768]]
/encoder/layer.0/attention/output/LayerNorm/Pow (Eltwise, index:37): [[1, 6, 768]]
/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:38): [[1, 6, 1]]
/encoder/layer.0/attention/output/LayerNorm/Add (Eltwise, index:39): [[1, 6, 1]]
/encoder/layer.0/attention/output/LayerNorm/Sqrt (Eltwise, index:40): [[1, 6, 1]]
/encoder/layer.0/attention/output/LayerNorm/Div (Eltwise, index:41): [[1, 6, 768]]
/encoder/layer.0/attention/output/LayerNorm/Mul (Eltwise, index:42): [[1, 6, 768]]
/encoder/layer.0/attention/output/LayerNorm/Add_1 (Eltwise, index:43): [[1, 6, 768]]
/encoder/layer.0/intermediate/dense/MatMul (MatMul, index:44): [[1, 6, 3072]]
Gelu_/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1 (Activation, index:45): [[1, 6, 3072]]
/encoder/layer.0/output/dense/MatMul (MatMul, index:46): [[1, 6, 768]]
/encoder/layer.0/output/dense/Add (Eltwise, index:47): [[1, 6, 768]]
/encoder/layer.0/output/Add (Eltwise, index:48): [[1, 6, 768]]
/encoder/layer.0/output/LayerNorm/ReduceMean (Reduce, index:49): [[1, 6, 1]]
/encoder/layer.0/output/LayerNorm/Sub (Eltwise, index:50): [[1, 6, 768]]
/encoder/layer.0/output/LayerNorm/Pow (Eltwise, index:51): [[1, 6, 768]]
/encoder/layer.0/output/LayerNorm/ReduceMean_1 (Reduce, index:52): [[1, 6, 1]]
/encoder/layer.0/output/LayerNorm/Add (Eltwise, index:53): [[1, 6, 1]]
/encoder/layer.0/output/LayerNorm/Sqrt (Eltwise, index:54): [[1, 6, 1]]
/encoder/layer.0/output/LayerNorm/Div (Eltwise, index:55): [[1, 6, 768]]
/encoder/layer.0/output/LayerNorm/Mul (Eltwise, index:56): [[1, 6, 768]]
/encoder/layer.0/output/LayerNorm/Add_1 (Eltwise, index:57): [[1, 6, 768]]
/encoder/layer.1/attention/self/query/MatMul (MatMul, index:58): [[1, 6, 768]]
/encoder/layer.1/attention/self/query/Add (Eltwise, index:59): [[1, 6, 768]]
/encoder/layer.1/attention/self/Reshape_2 (Reshape, index:60): [[1, 6, 12, 64]]
/encoder/layer.1/attention/self/Transpose_1 (Transpose, index:61): [[1, 12, 6, 64]]
/encoder/layer.1/attention/self/key/MatMul (MatMul, index:62): [[1, 6, 768]]
/encoder/layer.1/attention/self/key/Add (Eltwise, index:63): [[1, 6, 768]]
/encoder/layer.1/attention/self/Reshape (Reshape, index:64): [[1, 6, 12, 64]]
/encoder/layer.1/attention/self/Transpose_2 (Transpose, index:65): [[1, 12, 64, 6]]
/encoder/layer.1/attention/self/MatMul (MatMul, index:66): [[1, 12, 6, 6]]
/encoder/layer.1/attention/self/Div (Eltwise, index:67): [[1, 12, 6, 6]]
/encoder/layer.1/attention/self/Add (Eltwise, index:68): [[1, 12, 6, 6]]
/encoder/layer.1/attention/self/Softmax (Softmax, index:69): [[1, 12, 6, 6]]
/encoder/layer.1/attention/self/value/MatMul (MatMul, index:70): [[1, 6, 768]]
/encoder/layer.1/attention/self/value/Add (Eltwise, index:71): [[1, 6, 768]]
/encoder/layer.1/attention/self/Reshape_1 (Reshape, index:72): [[1, 6, 12, 64]]
/encoder/layer.1/attention/self/Transpose (Transpose, index:73): [[1, 12, 6, 64]]
/encoder/layer.1/attention/self/MatMul_1 (MatMul, index:74): [[1, 12, 6, 64]]
/encoder/layer.1/attention/self/Transpose_3 (Transpose, index:75): [[1, 6, 12, 64]]
/encoder/layer.1/attention/self/Reshape_3 (Reshape, index:76): [[1, 6, 768]]
/encoder/layer.1/attention/output/dense/MatMul (MatMul, index:77): [[1, 6, 768]]
/encoder/layer.1/attention/output/dense/Add (Eltwise, index:78): [[1, 6, 768]]
/encoder/layer.1/attention/output/Add (Eltwise, index:79): [[1, 6, 768]]
/encoder/layer.1/attention/output/LayerNorm/ReduceMean (Reduce, index:80): [[1, 6, 1]]
/encoder/layer.1/attention/output/LayerNorm/Sub (Eltwise, index:81): [[1, 6, 768]]
/encoder/layer.1/attention/output/LayerNorm/Pow (Eltwise, index:82): [[1, 6, 768]]
/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:83): [[1, 6, 1]]
/encoder/layer.1/attention/output/LayerNorm/Add (Eltwise, index:84): [[1, 6, 1]]
/encoder/layer.1/attention/output/LayerNorm/Sqrt (Eltwise, index:85): [[1, 6, 1]]
/encoder/layer.1/attention/output/LayerNorm/Div (Eltwise, index:86): [[1, 6, 768]]
/encoder/layer.1/attention/output/LayerNorm/Mul (Eltwise, index:87): [[1, 6, 768]]
/encoder/layer.1/attention/output/LayerNorm/Add_1 (Eltwise, index:88): [[1, 6, 768]]
/encoder/layer.1/intermediate/dense/MatMul (MatMul, index:89): [[1, 6, 3072]]
Gelu_/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1 (Activation, index:90): [[1, 6, 3072]]
/encoder/layer.1/output/dense/MatMul (MatMul, index:91): [[1, 6, 768]]
/encoder/layer.1/output/dense/Add (Eltwise, index:92): [[1, 6, 768]]
/encoder/layer.1/output/Add (Eltwise, index:93): [[1, 6, 768]]
/encoder/layer.1/output/LayerNorm/ReduceMean (Reduce, index:94): [[1, 6, 1]]
/encoder/layer.1/output/LayerNorm/Sub (Eltwise, index:95): [[1, 6, 768]]
/encoder/layer.1/output/LayerNorm/Pow (Eltwise, index:96): [[1, 6, 768]]
/encoder/layer.1/output/LayerNorm/ReduceMean_1 (Reduce, index:97): [[1, 6, 1]]
/encoder/layer.1/output/LayerNorm/Add (Eltwise, index:98): [[1, 6, 1]]
/encoder/layer.1/output/LayerNorm/Sqrt (Eltwise, index:99): [[1, 6, 1]]
/encoder/layer.1/output/LayerNorm/Div (Eltwise, index:100): [[1, 6, 768]]
/encoder/layer.1/output/LayerNorm/Mul (Eltwise, index:101): [[1, 6, 768]]
/encoder/layer.1/output/LayerNorm/Add_1 (Eltwise, index:102): [[1, 6, 768]]
/encoder/layer.2/attention/self/query/MatMul (MatMul, index:103): [[1, 6, 768]]
/encoder/layer.2/attention/self/query/Add (Eltwise, index:104): [[1, 6, 768]]
/encoder/layer.2/attention/self/Reshape_2 (Reshape, index:105): [[1, 6, 12, 64]]
/encoder/layer.2/attention/self/Transpose_1 (Transpose, index:106): [[1, 12, 6, 64]]
/encoder/layer.2/attention/self/key/MatMul (MatMul, index:107): [[1, 6, 768]]
/encoder/layer.2/attention/self/key/Add (Eltwise, index:108): [[1, 6, 768]]
/encoder/layer.2/attention/self/Reshape (Reshape, index:109): [[1, 6, 12, 64]]
/encoder/layer.2/attention/self/Transpose_2 (Transpose, index:110): [[1, 12, 64, 6]]
/encoder/layer.2/attention/self/MatMul (MatMul, index:111): [[1, 12, 6, 6]]
/encoder/layer.2/attention/self/Div (Eltwise, index:112): [[1, 12, 6, 6]]
/encoder/layer.2/attention/self/Add (Eltwise, index:113): [[1, 12, 6, 6]]
/encoder/layer.2/attention/self/Softmax (Softmax, index:114): [[1, 12, 6, 6]]
/encoder/layer.2/attention/self/value/MatMul (MatMul, index:115): [[1, 6, 768]]
/encoder/layer.2/attention/self/value/Add (Eltwise, index:116): [[1, 6, 768]]
/encoder/layer.2/attention/self/Reshape_1 (Reshape, index:117): [[1, 6, 12, 64]]
/encoder/layer.2/attention/self/Transpose (Transpose, index:118): [[1, 12, 6, 64]]
/encoder/layer.2/attention/self/MatMul_1 (MatMul, index:119): [[1, 12, 6, 64]]
/encoder/layer.2/attention/self/Transpose_3 (Transpose, index:120): [[1, 6, 12, 64]]
/encoder/layer.2/attention/self/Reshape_3 (Reshape, index:121): [[1, 6, 768]]
/encoder/layer.2/attention/output/dense/MatMul (MatMul, index:122): [[1, 6, 768]]
/encoder/layer.2/attention/output/dense/Add (Eltwise, index:123): [[1, 6, 768]]
/encoder/layer.2/attention/output/Add (Eltwise, index:124): [[1, 6, 768]]
/encoder/layer.2/attention/output/LayerNorm/ReduceMean (Reduce, index:125): [[1, 6, 1]]
/encoder/layer.2/attention/output/LayerNorm/Sub (Eltwise, index:126): [[1, 6, 768]]
/encoder/layer.2/attention/output/LayerNorm/Pow (Eltwise, index:127): [[1, 6, 768]]
/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:128): [[1, 6, 1]]
/encoder/layer.2/attention/output/LayerNorm/Add (Eltwise, index:129): [[1, 6, 1]]
/encoder/layer.2/attention/output/LayerNorm/Sqrt (Eltwise, index:130): [[1, 6, 1]]
/encoder/layer.2/attention/output/LayerNorm/Div (Eltwise, index:131): [[1, 6, 768]]
/encoder/layer.2/attention/output/LayerNorm/Mul (Eltwise, index:132): [[1, 6, 768]]
/encoder/layer.2/attention/output/LayerNorm/Add_1 (Eltwise, index:133): [[1, 6, 768]]
/encoder/layer.2/intermediate/dense/MatMul (MatMul, index:134): [[1, 6, 3072]]
Gelu_/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1 (Activation, index:135): [[1, 6, 3072]]
/encoder/layer.2/output/dense/MatMul (MatMul, index:136): [[1, 6, 768]]
/encoder/layer.2/output/dense/Add (Eltwise, index:137): [[1, 6, 768]]
/encoder/layer.2/output/Add (Eltwise, index:138): [[1, 6, 768]]
/encoder/layer.2/output/LayerNorm/ReduceMean (Reduce, index:139): [[1, 6, 1]]
/encoder/layer.2/output/LayerNorm/Sub (Eltwise, index:140): [[1, 6, 768]]
/encoder/layer.2/output/LayerNorm/Pow (Eltwise, index:141): [[1, 6, 768]]
/encoder/layer.2/output/LayerNorm/ReduceMean_1 (Reduce, index:142): [[1, 6, 1]]
/encoder/layer.2/output/LayerNorm/Add (Eltwise, index:143): [[1, 6, 1]]
/encoder/layer.2/output/LayerNorm/Sqrt (Eltwise, index:144): [[1, 6, 1]]
/encoder/layer.2/output/LayerNorm/Div (Eltwise, index:145): [[1, 6, 768]]
/encoder/layer.2/output/LayerNorm/Mul (Eltwise, index:146): [[1, 6, 768]]
/encoder/layer.2/output/LayerNorm/Add_1 (Eltwise, index:147): [[1, 6, 768]]
/encoder/layer.3/attention/self/query/MatMul (MatMul, index:148): [[1, 6, 768]]
/encoder/layer.3/attention/self/query/Add (Eltwise, index:149): [[1, 6, 768]]
/encoder/layer.3/attention/self/Reshape_2 (Reshape, index:150): [[1, 6, 12, 64]]
/encoder/layer.3/attention/self/Transpose_1 (Transpose, index:151): [[1, 12, 6, 64]]
/encoder/layer.3/attention/self/key/MatMul (MatMul, index:152): [[1, 6, 768]]
/encoder/layer.3/attention/self/key/Add (Eltwise, index:153): [[1, 6, 768]]
/encoder/layer.3/attention/self/Reshape (Reshape, index:154): [[1, 6, 12, 64]]
/encoder/layer.3/attention/self/Transpose_2 (Transpose, index:155): [[1, 12, 64, 6]]
/encoder/layer.3/attention/self/MatMul (MatMul, index:156): [[1, 12, 6, 6]]
/encoder/layer.3/attention/self/Div (Eltwise, index:157): [[1, 12, 6, 6]]
/encoder/layer.3/attention/self/Add (Eltwise, index:158): [[1, 12, 6, 6]]
/encoder/layer.3/attention/self/Softmax (Softmax, index:159): [[1, 12, 6, 6]]
/encoder/layer.3/attention/self/value/MatMul (MatMul, index:160): [[1, 6, 768]]
/encoder/layer.3/attention/self/value/Add (Eltwise, index:161): [[1, 6, 768]]
/encoder/layer.3/attention/self/Reshape_1 (Reshape, index:162): [[1, 6, 12, 64]]
/encoder/layer.3/attention/self/Transpose (Transpose, index:163): [[1, 12, 6, 64]]
/encoder/layer.3/attention/self/MatMul_1 (MatMul, index:164): [[1, 12, 6, 64]]
/encoder/layer.3/attention/self/Transpose_3 (Transpose, index:165): [[1, 6, 12, 64]]
/encoder/layer.3/attention/self/Reshape_3 (Reshape, index:166): [[1, 6, 768]]
/encoder/layer.3/attention/output/dense/MatMul (MatMul, index:167): [[1, 6, 768]]
/encoder/layer.3/attention/output/dense/Add (Eltwise, index:168): [[1, 6, 768]]
/encoder/layer.3/attention/output/Add (Eltwise, index:169): [[1, 6, 768]]
/encoder/layer.3/attention/output/LayerNorm/ReduceMean (Reduce, index:170): [[1, 6, 1]]
/encoder/layer.3/attention/output/LayerNorm/Sub (Eltwise, index:171): [[1, 6, 768]]
/encoder/layer.3/attention/output/LayerNorm/Pow (Eltwise, index:172): [[1, 6, 768]]
/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:173): [[1, 6, 1]]
/encoder/layer.3/attention/output/LayerNorm/Add (Eltwise, index:174): [[1, 6, 1]]
/encoder/layer.3/attention/output/LayerNorm/Sqrt (Eltwise, index:175): [[1, 6, 1]]
/encoder/layer.3/attention/output/LayerNorm/Div (Eltwise, index:176): [[1, 6, 768]]
/encoder/layer.3/attention/output/LayerNorm/Mul (Eltwise, index:177): [[1, 6, 768]]
/encoder/layer.3/attention/output/LayerNorm/Add_1 (Eltwise, index:178): [[1, 6, 768]]
/encoder/layer.3/intermediate/dense/MatMul (MatMul, index:179): [[1, 6, 3072]]
Gelu_/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1 (Activation, index:180): [[1, 6, 3072]]
/encoder/layer.3/output/dense/MatMul (MatMul, index:181): [[1, 6, 768]]
/encoder/layer.3/output/dense/Add (Eltwise, index:182): [[1, 6, 768]]
/encoder/layer.3/output/Add (Eltwise, index:183): [[1, 6, 768]]
/encoder/layer.3/output/LayerNorm/ReduceMean (Reduce, index:184): [[1, 6, 1]]
/encoder/layer.3/output/LayerNorm/Sub (Eltwise, index:185): [[1, 6, 768]]
/encoder/layer.3/output/LayerNorm/Pow (Eltwise, index:186): [[1, 6, 768]]
/encoder/layer.3/output/LayerNorm/ReduceMean_1 (Reduce, index:187): [[1, 6, 1]]
/encoder/layer.3/output/LayerNorm/Add (Eltwise, index:188): [[1, 6, 1]]
/encoder/layer.3/output/LayerNorm/Sqrt (Eltwise, index:189): [[1, 6, 1]]
/encoder/layer.3/output/LayerNorm/Div (Eltwise, index:190): [[1, 6, 768]]
/encoder/layer.3/output/LayerNorm/Mul (Eltwise, index:191): [[1, 6, 768]]
/encoder/layer.3/output/LayerNorm/Add_1 (Eltwise, index:192): [[1, 6, 768]]
/encoder/layer.4/attention/self/query/MatMul (MatMul, index:193): [[1, 6, 768]]
/encoder/layer.4/attention/self/query/Add (Eltwise, index:194): [[1, 6, 768]]
/encoder/layer.4/attention/self/Reshape_2 (Reshape, index:195): [[1, 6, 12, 64]]
/encoder/layer.4/attention/self/Transpose_1 (Transpose, index:196): [[1, 12, 6, 64]]
/encoder/layer.4/attention/self/key/MatMul (MatMul, index:197): [[1, 6, 768]]
/encoder/layer.4/attention/self/key/Add (Eltwise, index:198): [[1, 6, 768]]
/encoder/layer.4/attention/self/Reshape (Reshape, index:199): [[1, 6, 12, 64]]
/encoder/layer.4/attention/self/Transpose_2 (Transpose, index:200): [[1, 12, 64, 6]]
/encoder/layer.4/attention/self/MatMul (MatMul, index:201): [[1, 12, 6, 6]]
/encoder/layer.4/attention/self/Div (Eltwise, index:202): [[1, 12, 6, 6]]
/encoder/layer.4/attention/self/Add (Eltwise, index:203): [[1, 12, 6, 6]]
/encoder/layer.4/attention/self/Softmax (Softmax, index:204): [[1, 12, 6, 6]]
/encoder/layer.4/attention/self/value/MatMul (MatMul, index:205): [[1, 6, 768]]
/encoder/layer.4/attention/self/value/Add (Eltwise, index:206): [[1, 6, 768]]
/encoder/layer.4/attention/self/Reshape_1 (Reshape, index:207): [[1, 6, 12, 64]]
/encoder/layer.4/attention/self/Transpose (Transpose, index:208): [[1, 12, 6, 64]]
/encoder/layer.4/attention/self/MatMul_1 (MatMul, index:209): [[1, 12, 6, 64]]
/encoder/layer.4/attention/self/Transpose_3 (Transpose, index:210): [[1, 6, 12, 64]]
/encoder/layer.4/attention/self/Reshape_3 (Reshape, index:211): [[1, 6, 768]]
/encoder/layer.4/attention/output/dense/MatMul (MatMul, index:212): [[1, 6, 768]]
/encoder/layer.4/attention/output/dense/Add (Eltwise, index:213): [[1, 6, 768]]
/encoder/layer.4/attention/output/Add (Eltwise, index:214): [[1, 6, 768]]
/encoder/layer.4/attention/output/LayerNorm/ReduceMean (Reduce, index:215): [[1, 6, 1]]
/encoder/layer.4/attention/output/LayerNorm/Sub (Eltwise, index:216): [[1, 6, 768]]
/encoder/layer.4/attention/output/LayerNorm/Pow (Eltwise, index:217): [[1, 6, 768]]
/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:218): [[1, 6, 1]]
/encoder/layer.4/attention/output/LayerNorm/Add (Eltwise, index:219): [[1, 6, 1]]
/encoder/layer.4/attention/output/LayerNorm/Sqrt (Eltwise, index:220): [[1, 6, 1]]
/encoder/layer.4/attention/output/LayerNorm/Div (Eltwise, index:221): [[1, 6, 768]]
/encoder/layer.4/attention/output/LayerNorm/Mul (Eltwise, index:222): [[1, 6, 768]]
/encoder/layer.4/attention/output/LayerNorm/Add_1 (Eltwise, index:223): [[1, 6, 768]]
/encoder/layer.4/intermediate/dense/MatMul (MatMul, index:224): [[1, 6, 3072]]
Gelu_/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1 (Activation, index:225): [[1, 6, 3072]]
/encoder/layer.4/output/dense/MatMul (MatMul, index:226): [[1, 6, 768]]
/encoder/layer.4/output/dense/Add (Eltwise, index:227): [[1, 6, 768]]
/encoder/layer.4/output/Add (Eltwise, index:228): [[1, 6, 768]]
/encoder/layer.4/output/LayerNorm/ReduceMean (Reduce, index:229): [[1, 6, 1]]
/encoder/layer.4/output/LayerNorm/Sub (Eltwise, index:230): [[1, 6, 768]]
/encoder/layer.4/output/LayerNorm/Pow (Eltwise, index:231): [[1, 6, 768]]
/encoder/layer.4/output/LayerNorm/ReduceMean_1 (Reduce, index:232): [[1, 6, 1]]
/encoder/layer.4/output/LayerNorm/Add (Eltwise, index:233): [[1, 6, 1]]
/encoder/layer.4/output/LayerNorm/Sqrt (Eltwise, index:234): [[1, 6, 1]]
/encoder/layer.4/output/LayerNorm/Div (Eltwise, index:235): [[1, 6, 768]]
/encoder/layer.4/output/LayerNorm/Mul (Eltwise, index:236): [[1, 6, 768]]
/encoder/layer.4/output/LayerNorm/Add_1 (Eltwise, index:237): [[1, 6, 768]]
/encoder/layer.5/attention/self/query/MatMul (MatMul, index:238): [[1, 6, 768]]
/encoder/layer.5/attention/self/query/Add (Eltwise, index:239): [[1, 6, 768]]
/encoder/layer.5/attention/self/Reshape_2 (Reshape, index:240): [[1, 6, 12, 64]]
/encoder/layer.5/attention/self/Transpose_1 (Transpose, index:241): [[1, 12, 6, 64]]
/encoder/layer.5/attention/self/key/MatMul (MatMul, index:242): [[1, 6, 768]]
/encoder/layer.5/attention/self/key/Add (Eltwise, index:243): [[1, 6, 768]]
/encoder/layer.5/attention/self/Reshape (Reshape, index:244): [[1, 6, 12, 64]]
/encoder/layer.5/attention/self/Transpose_2 (Transpose, index:245): [[1, 12, 64, 6]]
/encoder/layer.5/attention/self/MatMul (MatMul, index:246): [[1, 12, 6, 6]]
/encoder/layer.5/attention/self/Div (Eltwise, index:247): [[1, 12, 6, 6]]
/encoder/layer.5/attention/self/Add (Eltwise, index:248): [[1, 12, 6, 6]]
/encoder/layer.5/attention/self/Softmax (Softmax, index:249): [[1, 12, 6, 6]]
/encoder/layer.5/attention/self/value/MatMul (MatMul, index:250): [[1, 6, 768]]
/encoder/layer.5/attention/self/value/Add (Eltwise, index:251): [[1, 6, 768]]
/encoder/layer.5/attention/self/Reshape_1 (Reshape, index:252): [[1, 6, 12, 64]]
/encoder/layer.5/attention/self/Transpose (Transpose, index:253): [[1, 12, 6, 64]]
/encoder/layer.5/attention/self/MatMul_1 (MatMul, index:254): [[1, 12, 6, 64]]
/encoder/layer.5/attention/self/Transpose_3 (Transpose, index:255): [[1, 6, 12, 64]]
/encoder/layer.5/attention/self/Reshape_3 (Reshape, index:256): [[1, 6, 768]]
/encoder/layer.5/attention/output/dense/MatMul (MatMul, index:257): [[1, 6, 768]]
/encoder/layer.5/attention/output/dense/Add (Eltwise, index:258): [[1, 6, 768]]
/encoder/layer.5/attention/output/Add (Eltwise, index:259): [[1, 6, 768]]
/encoder/layer.5/attention/output/LayerNorm/ReduceMean (Reduce, index:260): [[1, 6, 1]]
/encoder/layer.5/attention/output/LayerNorm/Sub (Eltwise, index:261): [[1, 6, 768]]
/encoder/layer.5/attention/output/LayerNorm/Pow (Eltwise, index:262): [[1, 6, 768]]
/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:263): [[1, 6, 1]]
/encoder/layer.5/attention/output/LayerNorm/Add (Eltwise, index:264): [[1, 6, 1]]
/encoder/layer.5/attention/output/LayerNorm/Sqrt (Eltwise, index:265): [[1, 6, 1]]
/encoder/layer.5/attention/output/LayerNorm/Div (Eltwise, index:266): [[1, 6, 768]]
/encoder/layer.5/attention/output/LayerNorm/Mul (Eltwise, index:267): [[1, 6, 768]]
/encoder/layer.5/attention/output/LayerNorm/Add_1 (Eltwise, index:268): [[1, 6, 768]]
/encoder/layer.5/intermediate/dense/MatMul (MatMul, index:269): [[1, 6, 3072]]
Gelu_/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1 (Activation, index:270): [[1, 6, 3072]]
/encoder/layer.5/output/dense/MatMul (MatMul, index:271): [[1, 6, 768]]
/encoder/layer.5/output/dense/Add (Eltwise, index:272): [[1, 6, 768]]
/encoder/layer.5/output/Add (Eltwise, index:273): [[1, 6, 768]]
/encoder/layer.5/output/LayerNorm/ReduceMean (Reduce, index:274): [[1, 6, 1]]
/encoder/layer.5/output/LayerNorm/Sub (Eltwise, index:275): [[1, 6, 768]]
/encoder/layer.5/output/LayerNorm/Pow (Eltwise, index:276): [[1, 6, 768]]
/encoder/layer.5/output/LayerNorm/ReduceMean_1 (Reduce, index:277): [[1, 6, 1]]
/encoder/layer.5/output/LayerNorm/Add (Eltwise, index:278): [[1, 6, 1]]
/encoder/layer.5/output/LayerNorm/Sqrt (Eltwise, index:279): [[1, 6, 1]]
/encoder/layer.5/output/LayerNorm/Div (Eltwise, index:280): [[1, 6, 768]]
/encoder/layer.5/output/LayerNorm/Mul (Eltwise, index:281): [[1, 6, 768]]
/encoder/layer.5/output/LayerNorm/Add_1 (Eltwise, index:282): [[1, 6, 768]]
/encoder/layer.6/attention/self/query/MatMul (MatMul, index:283): [[1, 6, 768]]
/encoder/layer.6/attention/self/query/Add (Eltwise, index:284): [[1, 6, 768]]
/encoder/layer.6/attention/self/Reshape_2 (Reshape, index:285): [[1, 6, 12, 64]]
/encoder/layer.6/attention/self/Transpose_1 (Transpose, index:286): [[1, 12, 6, 64]]
/encoder/layer.6/attention/self/key/MatMul (MatMul, index:287): [[1, 6, 768]]
/encoder/layer.6/attention/self/key/Add (Eltwise, index:288): [[1, 6, 768]]
/encoder/layer.6/attention/self/Reshape (Reshape, index:289): [[1, 6, 12, 64]]
/encoder/layer.6/attention/self/Transpose_2 (Transpose, index:290): [[1, 12, 64, 6]]
/encoder/layer.6/attention/self/MatMul (MatMul, index:291): [[1, 12, 6, 6]]
/encoder/layer.6/attention/self/Div (Eltwise, index:292): [[1, 12, 6, 6]]
/encoder/layer.6/attention/self/Add (Eltwise, index:293): [[1, 12, 6, 6]]
/encoder/layer.6/attention/self/Softmax (Softmax, index:294): [[1, 12, 6, 6]]
/encoder/layer.6/attention/self/value/MatMul (MatMul, index:295): [[1, 6, 768]]
/encoder/layer.6/attention/self/value/Add (Eltwise, index:296): [[1, 6, 768]]
/encoder/layer.6/attention/self/Reshape_1 (Reshape, index:297): [[1, 6, 12, 64]]
/encoder/layer.6/attention/self/Transpose (Transpose, index:298): [[1, 12, 6, 64]]
/encoder/layer.6/attention/self/MatMul_1 (MatMul, index:299): [[1, 12, 6, 64]]
/encoder/layer.6/attention/self/Transpose_3 (Transpose, index:300): [[1, 6, 12, 64]]
/encoder/layer.6/attention/self/Reshape_3 (Reshape, index:301): [[1, 6, 768]]
/encoder/layer.6/attention/output/dense/MatMul (MatMul, index:302): [[1, 6, 768]]
/encoder/layer.6/attention/output/dense/Add (Eltwise, index:303): [[1, 6, 768]]
/encoder/layer.6/attention/output/Add (Eltwise, index:304): [[1, 6, 768]]
/encoder/layer.6/attention/output/LayerNorm/ReduceMean (Reduce, index:305): [[1, 6, 1]]
/encoder/layer.6/attention/output/LayerNorm/Sub (Eltwise, index:306): [[1, 6, 768]]
/encoder/layer.6/attention/output/LayerNorm/Pow (Eltwise, index:307): [[1, 6, 768]]
/encoder/layer.6/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:308): [[1, 6, 1]]
/encoder/layer.6/attention/output/LayerNorm/Add (Eltwise, index:309): [[1, 6, 1]]
/encoder/layer.6/attention/output/LayerNorm/Sqrt (Eltwise, index:310): [[1, 6, 1]]
/encoder/layer.6/attention/output/LayerNorm/Div (Eltwise, index:311): [[1, 6, 768]]
/encoder/layer.6/attention/output/LayerNorm/Mul (Eltwise, index:312): [[1, 6, 768]]
/encoder/layer.6/attention/output/LayerNorm/Add_1 (Eltwise, index:313): [[1, 6, 768]]
/encoder/layer.6/intermediate/dense/MatMul (MatMul, index:314): [[1, 6, 3072]]
Gelu_/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1 (Activation, index:315): [[1, 6, 3072]]
/encoder/layer.6/output/dense/MatMul (MatMul, index:316): [[1, 6, 768]]
/encoder/layer.6/output/dense/Add (Eltwise, index:317): [[1, 6, 768]]
/encoder/layer.6/output/Add (Eltwise, index:318): [[1, 6, 768]]
/encoder/layer.6/output/LayerNorm/ReduceMean (Reduce, index:319): [[1, 6, 1]]
/encoder/layer.6/output/LayerNorm/Sub (Eltwise, index:320): [[1, 6, 768]]
/encoder/layer.6/output/LayerNorm/Pow (Eltwise, index:321): [[1, 6, 768]]
/encoder/layer.6/output/LayerNorm/ReduceMean_1 (Reduce, index:322): [[1, 6, 1]]
/encoder/layer.6/output/LayerNorm/Add (Eltwise, index:323): [[1, 6, 1]]
/encoder/layer.6/output/LayerNorm/Sqrt (Eltwise, index:324): [[1, 6, 1]]
/encoder/layer.6/output/LayerNorm/Div (Eltwise, index:325): [[1, 6, 768]]
/encoder/layer.6/output/LayerNorm/Mul (Eltwise, index:326): [[1, 6, 768]]
/encoder/layer.6/output/LayerNorm/Add_1 (Eltwise, index:327): [[1, 6, 768]]
/encoder/layer.7/attention/self/query/MatMul (MatMul, index:328): [[1, 6, 768]]
/encoder/layer.7/attention/self/query/Add (Eltwise, index:329): [[1, 6, 768]]
/encoder/layer.7/attention/self/Reshape_2 (Reshape, index:330): [[1, 6, 12, 64]]
/encoder/layer.7/attention/self/Transpose_1 (Transpose, index:331): [[1, 12, 6, 64]]
/encoder/layer.7/attention/self/key/MatMul (MatMul, index:332): [[1, 6, 768]]
/encoder/layer.7/attention/self/key/Add (Eltwise, index:333): [[1, 6, 768]]
/encoder/layer.7/attention/self/Reshape (Reshape, index:334): [[1, 6, 12, 64]]
/encoder/layer.7/attention/self/Transpose_2 (Transpose, index:335): [[1, 12, 64, 6]]
/encoder/layer.7/attention/self/MatMul (MatMul, index:336): [[1, 12, 6, 6]]
/encoder/layer.7/attention/self/Div (Eltwise, index:337): [[1, 12, 6, 6]]
/encoder/layer.7/attention/self/Add (Eltwise, index:338): [[1, 12, 6, 6]]
/encoder/layer.7/attention/self/Softmax (Softmax, index:339): [[1, 12, 6, 6]]
/encoder/layer.7/attention/self/value/MatMul (MatMul, index:340): [[1, 6, 768]]
/encoder/layer.7/attention/self/value/Add (Eltwise, index:341): [[1, 6, 768]]
/encoder/layer.7/attention/self/Reshape_1 (Reshape, index:342): [[1, 6, 12, 64]]
/encoder/layer.7/attention/self/Transpose (Transpose, index:343): [[1, 12, 6, 64]]
/encoder/layer.7/attention/self/MatMul_1 (MatMul, index:344): [[1, 12, 6, 64]]
/encoder/layer.7/attention/self/Transpose_3 (Transpose, index:345): [[1, 6, 12, 64]]
/encoder/layer.7/attention/self/Reshape_3 (Reshape, index:346): [[1, 6, 768]]
/encoder/layer.7/attention/output/dense/MatMul (MatMul, index:347): [[1, 6, 768]]
/encoder/layer.7/attention/output/dense/Add (Eltwise, index:348): [[1, 6, 768]]
/encoder/layer.7/attention/output/Add (Eltwise, index:349): [[1, 6, 768]]
/encoder/layer.7/attention/output/LayerNorm/ReduceMean (Reduce, index:350): [[1, 6, 1]]
/encoder/layer.7/attention/output/LayerNorm/Sub (Eltwise, index:351): [[1, 6, 768]]
/encoder/layer.7/attention/output/LayerNorm/Pow (Eltwise, index:352): [[1, 6, 768]]
/encoder/layer.7/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:353): [[1, 6, 1]]
/encoder/layer.7/attention/output/LayerNorm/Add (Eltwise, index:354): [[1, 6, 1]]
/encoder/layer.7/attention/output/LayerNorm/Sqrt (Eltwise, index:355): [[1, 6, 1]]
/encoder/layer.7/attention/output/LayerNorm/Div (Eltwise, index:356): [[1, 6, 768]]
/encoder/layer.7/attention/output/LayerNorm/Mul (Eltwise, index:357): [[1, 6, 768]]
/encoder/layer.7/attention/output/LayerNorm/Add_1 (Eltwise, index:358): [[1, 6, 768]]
/encoder/layer.7/intermediate/dense/MatMul (MatMul, index:359): [[1, 6, 3072]]
Gelu_/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1 (Activation, index:360): [[1, 6, 3072]]
/encoder/layer.7/output/dense/MatMul (MatMul, index:361): [[1, 6, 768]]
/encoder/layer.7/output/dense/Add (Eltwise, index:362): [[1, 6, 768]]
/encoder/layer.7/output/Add (Eltwise, index:363): [[1, 6, 768]]
/encoder/layer.7/output/LayerNorm/ReduceMean (Reduce, index:364): [[1, 6, 1]]
/encoder/layer.7/output/LayerNorm/Sub (Eltwise, index:365): [[1, 6, 768]]
/encoder/layer.7/output/LayerNorm/Pow (Eltwise, index:366): [[1, 6, 768]]
/encoder/layer.7/output/LayerNorm/ReduceMean_1 (Reduce, index:367): [[1, 6, 1]]
/encoder/layer.7/output/LayerNorm/Add (Eltwise, index:368): [[1, 6, 1]]
/encoder/layer.7/output/LayerNorm/Sqrt (Eltwise, index:369): [[1, 6, 1]]
/encoder/layer.7/output/LayerNorm/Div (Eltwise, index:370): [[1, 6, 768]]
/encoder/layer.7/output/LayerNorm/Mul (Eltwise, index:371): [[1, 6, 768]]
/encoder/layer.7/output/LayerNorm/Add_1 (Eltwise, index:372): [[1, 6, 768]]
/encoder/layer.8/attention/self/query/MatMul (MatMul, index:373): [[1, 6, 768]]
/encoder/layer.8/attention/self/query/Add (Eltwise, index:374): [[1, 6, 768]]
/encoder/layer.8/attention/self/Reshape_2 (Reshape, index:375): [[1, 6, 12, 64]]
/encoder/layer.8/attention/self/Transpose_1 (Transpose, index:376): [[1, 12, 6, 64]]
/encoder/layer.8/attention/self/key/MatMul (MatMul, index:377): [[1, 6, 768]]
/encoder/layer.8/attention/self/key/Add (Eltwise, index:378): [[1, 6, 768]]
/encoder/layer.8/attention/self/Reshape (Reshape, index:379): [[1, 6, 12, 64]]
/encoder/layer.8/attention/self/Transpose_2 (Transpose, index:380): [[1, 12, 64, 6]]
/encoder/layer.8/attention/self/MatMul (MatMul, index:381): [[1, 12, 6, 6]]
/encoder/layer.8/attention/self/Div (Eltwise, index:382): [[1, 12, 6, 6]]
/encoder/layer.8/attention/self/Add (Eltwise, index:383): [[1, 12, 6, 6]]
/encoder/layer.8/attention/self/Softmax (Softmax, index:384): [[1, 12, 6, 6]]
/encoder/layer.8/attention/self/value/MatMul (MatMul, index:385): [[1, 6, 768]]
/encoder/layer.8/attention/self/value/Add (Eltwise, index:386): [[1, 6, 768]]
/encoder/layer.8/attention/self/Reshape_1 (Reshape, index:387): [[1, 6, 12, 64]]
/encoder/layer.8/attention/self/Transpose (Transpose, index:388): [[1, 12, 6, 64]]
/encoder/layer.8/attention/self/MatMul_1 (MatMul, index:389): [[1, 12, 6, 64]]
/encoder/layer.8/attention/self/Transpose_3 (Transpose, index:390): [[1, 6, 12, 64]]
/encoder/layer.8/attention/self/Reshape_3 (Reshape, index:391): [[1, 6, 768]]
/encoder/layer.8/attention/output/dense/MatMul (MatMul, index:392): [[1, 6, 768]]
/encoder/layer.8/attention/output/dense/Add (Eltwise, index:393): [[1, 6, 768]]
/encoder/layer.8/attention/output/Add (Eltwise, index:394): [[1, 6, 768]]
/encoder/layer.8/attention/output/LayerNorm/ReduceMean (Reduce, index:395): [[1, 6, 1]]
/encoder/layer.8/attention/output/LayerNorm/Sub (Eltwise, index:396): [[1, 6, 768]]
/encoder/layer.8/attention/output/LayerNorm/Pow (Eltwise, index:397): [[1, 6, 768]]
/encoder/layer.8/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:398): [[1, 6, 1]]
/encoder/layer.8/attention/output/LayerNorm/Add (Eltwise, index:399): [[1, 6, 1]]
/encoder/layer.8/attention/output/LayerNorm/Sqrt (Eltwise, index:400): [[1, 6, 1]]
/encoder/layer.8/attention/output/LayerNorm/Div (Eltwise, index:401): [[1, 6, 768]]
/encoder/layer.8/attention/output/LayerNorm/Mul (Eltwise, index:402): [[1, 6, 768]]
/encoder/layer.8/attention/output/LayerNorm/Add_1 (Eltwise, index:403): [[1, 6, 768]]
/encoder/layer.8/intermediate/dense/MatMul (MatMul, index:404): [[1, 6, 3072]]
Gelu_/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1 (Activation, index:405): [[1, 6, 3072]]
/encoder/layer.8/output/dense/MatMul (MatMul, index:406): [[1, 6, 768]]
/encoder/layer.8/output/dense/Add (Eltwise, index:407): [[1, 6, 768]]
/encoder/layer.8/output/Add (Eltwise, index:408): [[1, 6, 768]]
/encoder/layer.8/output/LayerNorm/ReduceMean (Reduce, index:409): [[1, 6, 1]]
/encoder/layer.8/output/LayerNorm/Sub (Eltwise, index:410): [[1, 6, 768]]
/encoder/layer.8/output/LayerNorm/Pow (Eltwise, index:411): [[1, 6, 768]]
/encoder/layer.8/output/LayerNorm/ReduceMean_1 (Reduce, index:412): [[1, 6, 1]]
/encoder/layer.8/output/LayerNorm/Add (Eltwise, index:413): [[1, 6, 1]]
/encoder/layer.8/output/LayerNorm/Sqrt (Eltwise, index:414): [[1, 6, 1]]
/encoder/layer.8/output/LayerNorm/Div (Eltwise, index:415): [[1, 6, 768]]
/encoder/layer.8/output/LayerNorm/Mul (Eltwise, index:416): [[1, 6, 768]]
/encoder/layer.8/output/LayerNorm/Add_1 (Eltwise, index:417): [[1, 6, 768]]
/encoder/layer.9/attention/self/query/MatMul (MatMul, index:418): [[1, 6, 768]]
/encoder/layer.9/attention/self/query/Add (Eltwise, index:419): [[1, 6, 768]]
/encoder/layer.9/attention/self/Reshape_2 (Reshape, index:420): [[1, 6, 12, 64]]
/encoder/layer.9/attention/self/Transpose_1 (Transpose, index:421): [[1, 12, 6, 64]]
/encoder/layer.9/attention/self/key/MatMul (MatMul, index:422): [[1, 6, 768]]
/encoder/layer.9/attention/self/key/Add (Eltwise, index:423): [[1, 6, 768]]
/encoder/layer.9/attention/self/Reshape (Reshape, index:424): [[1, 6, 12, 64]]
/encoder/layer.9/attention/self/Transpose_2 (Transpose, index:425): [[1, 12, 64, 6]]
/encoder/layer.9/attention/self/MatMul (MatMul, index:426): [[1, 12, 6, 6]]
/encoder/layer.9/attention/self/Div (Eltwise, index:427): [[1, 12, 6, 6]]
/encoder/layer.9/attention/self/Add (Eltwise, index:428): [[1, 12, 6, 6]]
/encoder/layer.9/attention/self/Softmax (Softmax, index:429): [[1, 12, 6, 6]]
/encoder/layer.9/attention/self/value/MatMul (MatMul, index:430): [[1, 6, 768]]
/encoder/layer.9/attention/self/value/Add (Eltwise, index:431): [[1, 6, 768]]
/encoder/layer.9/attention/self/Reshape_1 (Reshape, index:432): [[1, 6, 12, 64]]
/encoder/layer.9/attention/self/Transpose (Transpose, index:433): [[1, 12, 6, 64]]
/encoder/layer.9/attention/self/MatMul_1 (MatMul, index:434): [[1, 12, 6, 64]]
/encoder/layer.9/attention/self/Transpose_3 (Transpose, index:435): [[1, 6, 12, 64]]
/encoder/layer.9/attention/self/Reshape_3 (Reshape, index:436): [[1, 6, 768]]
/encoder/layer.9/attention/output/dense/MatMul (MatMul, index:437): [[1, 6, 768]]
/encoder/layer.9/attention/output/dense/Add (Eltwise, index:438): [[1, 6, 768]]
/encoder/layer.9/attention/output/Add (Eltwise, index:439): [[1, 6, 768]]
/encoder/layer.9/attention/output/LayerNorm/ReduceMean (Reduce, index:440): [[1, 6, 1]]
/encoder/layer.9/attention/output/LayerNorm/Sub (Eltwise, index:441): [[1, 6, 768]]
/encoder/layer.9/attention/output/LayerNorm/Pow (Eltwise, index:442): [[1, 6, 768]]
/encoder/layer.9/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:443): [[1, 6, 1]]
/encoder/layer.9/attention/output/LayerNorm/Add (Eltwise, index:444): [[1, 6, 1]]
/encoder/layer.9/attention/output/LayerNorm/Sqrt (Eltwise, index:445): [[1, 6, 1]]
/encoder/layer.9/attention/output/LayerNorm/Div (Eltwise, index:446): [[1, 6, 768]]
/encoder/layer.9/attention/output/LayerNorm/Mul (Eltwise, index:447): [[1, 6, 768]]
/encoder/layer.9/attention/output/LayerNorm/Add_1 (Eltwise, index:448): [[1, 6, 768]]
/encoder/layer.9/intermediate/dense/MatMul (MatMul, index:449): [[1, 6, 3072]]
Gelu_/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1 (Activation, index:450): [[1, 6, 3072]]
/encoder/layer.9/output/dense/MatMul (MatMul, index:451): [[1, 6, 768]]
/encoder/layer.9/output/dense/Add (Eltwise, index:452): [[1, 6, 768]]
/encoder/layer.9/output/Add (Eltwise, index:453): [[1, 6, 768]]
/encoder/layer.9/output/LayerNorm/ReduceMean (Reduce, index:454): [[1, 6, 1]]
/encoder/layer.9/output/LayerNorm/Sub (Eltwise, index:455): [[1, 6, 768]]
/encoder/layer.9/output/LayerNorm/Pow (Eltwise, index:456): [[1, 6, 768]]
/encoder/layer.9/output/LayerNorm/ReduceMean_1 (Reduce, index:457): [[1, 6, 1]]
/encoder/layer.9/output/LayerNorm/Add (Eltwise, index:458): [[1, 6, 1]]
/encoder/layer.9/output/LayerNorm/Sqrt (Eltwise, index:459): [[1, 6, 1]]
/encoder/layer.9/output/LayerNorm/Div (Eltwise, index:460): [[1, 6, 768]]
/encoder/layer.9/output/LayerNorm/Mul (Eltwise, index:461): [[1, 6, 768]]
/encoder/layer.9/output/LayerNorm/Add_1 (Eltwise, index:462): [[1, 6, 768]]
/encoder/layer.10/attention/self/query/MatMul (MatMul, index:463): [[1, 6, 768]]
/encoder/layer.10/attention/self/query/Add (Eltwise, index:464): [[1, 6, 768]]
/encoder/layer.10/attention/self/Reshape_2 (Reshape, index:465): [[1, 6, 12, 64]]
/encoder/layer.10/attention/self/Transpose_1 (Transpose, index:466): [[1, 12, 6, 64]]
/encoder/layer.10/attention/self/key/MatMul (MatMul, index:467): [[1, 6, 768]]
/encoder/layer.10/attention/self/key/Add (Eltwise, index:468): [[1, 6, 768]]
/encoder/layer.10/attention/self/Reshape (Reshape, index:469): [[1, 6, 12, 64]]
/encoder/layer.10/attention/self/Transpose_2 (Transpose, index:470): [[1, 12, 64, 6]]
/encoder/layer.10/attention/self/MatMul (MatMul, index:471): [[1, 12, 6, 6]]
/encoder/layer.10/attention/self/Div (Eltwise, index:472): [[1, 12, 6, 6]]
/encoder/layer.10/attention/self/Add (Eltwise, index:473): [[1, 12, 6, 6]]
/encoder/layer.10/attention/self/Softmax (Softmax, index:474): [[1, 12, 6, 6]]
/encoder/layer.10/attention/self/value/MatMul (MatMul, index:475): [[1, 6, 768]]
/encoder/layer.10/attention/self/value/Add (Eltwise, index:476): [[1, 6, 768]]
/encoder/layer.10/attention/self/Reshape_1 (Reshape, index:477): [[1, 6, 12, 64]]
/encoder/layer.10/attention/self/Transpose (Transpose, index:478): [[1, 12, 6, 64]]
/encoder/layer.10/attention/self/MatMul_1 (MatMul, index:479): [[1, 12, 6, 64]]
/encoder/layer.10/attention/self/Transpose_3 (Transpose, index:480): [[1, 6, 12, 64]]
/encoder/layer.10/attention/self/Reshape_3 (Reshape, index:481): [[1, 6, 768]]
/encoder/layer.10/attention/output/dense/MatMul (MatMul, index:482): [[1, 6, 768]]
/encoder/layer.10/attention/output/dense/Add (Eltwise, index:483): [[1, 6, 768]]
/encoder/layer.10/attention/output/Add (Eltwise, index:484): [[1, 6, 768]]
/encoder/layer.10/attention/output/LayerNorm/ReduceMean (Reduce, index:485): [[1, 6, 1]]
/encoder/layer.10/attention/output/LayerNorm/Sub (Eltwise, index:486): [[1, 6, 768]]
/encoder/layer.10/attention/output/LayerNorm/Pow (Eltwise, index:487): [[1, 6, 768]]
/encoder/layer.10/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:488): [[1, 6, 1]]
/encoder/layer.10/attention/output/LayerNorm/Add (Eltwise, index:489): [[1, 6, 1]]
/encoder/layer.10/attention/output/LayerNorm/Sqrt (Eltwise, index:490): [[1, 6, 1]]
/encoder/layer.10/attention/output/LayerNorm/Div (Eltwise, index:491): [[1, 6, 768]]
/encoder/layer.10/attention/output/LayerNorm/Mul (Eltwise, index:492): [[1, 6, 768]]
/encoder/layer.10/attention/output/LayerNorm/Add_1 (Eltwise, index:493): [[1, 6, 768]]
/encoder/layer.10/intermediate/dense/MatMul (MatMul, index:494): [[1, 6, 3072]]
Gelu_/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1 (Activation, index:495): [[1, 6, 3072]]
/encoder/layer.10/output/dense/MatMul (MatMul, index:496): [[1, 6, 768]]
/encoder/layer.10/output/dense/Add (Eltwise, index:497): [[1, 6, 768]]
/encoder/layer.10/output/Add (Eltwise, index:498): [[1, 6, 768]]
/encoder/layer.10/output/LayerNorm/ReduceMean (Reduce, index:499): [[1, 6, 1]]
/encoder/layer.10/output/LayerNorm/Sub (Eltwise, index:500): [[1, 6, 768]]
/encoder/layer.10/output/LayerNorm/Pow (Eltwise, index:501): [[1, 6, 768]]
/encoder/layer.10/output/LayerNorm/ReduceMean_1 (Reduce, index:502): [[1, 6, 1]]
/encoder/layer.10/output/LayerNorm/Add (Eltwise, index:503): [[1, 6, 1]]
/encoder/layer.10/output/LayerNorm/Sqrt (Eltwise, index:504): [[1, 6, 1]]
/encoder/layer.10/output/LayerNorm/Div (Eltwise, index:505): [[1, 6, 768]]
/encoder/layer.10/output/LayerNorm/Mul (Eltwise, index:506): [[1, 6, 768]]
/encoder/layer.10/output/LayerNorm/Add_1 (Eltwise, index:507): [[1, 6, 768]]
/encoder/layer.11/attention/self/query/MatMul (MatMul, index:508): [[1, 6, 768]]
/encoder/layer.11/attention/self/query/Add (Eltwise, index:509): [[1, 6, 768]]
/encoder/layer.11/attention/self/Reshape_2 (Reshape, index:510): [[1, 6, 12, 64]]
/encoder/layer.11/attention/self/Transpose_1 (Transpose, index:511): [[1, 12, 6, 64]]
/encoder/layer.11/attention/self/key/MatMul (MatMul, index:512): [[1, 6, 768]]
/encoder/layer.11/attention/self/key/Add (Eltwise, index:513): [[1, 6, 768]]
/encoder/layer.11/attention/self/Reshape (Reshape, index:514): [[1, 6, 12, 64]]
/encoder/layer.11/attention/self/Transpose_2 (Transpose, index:515): [[1, 12, 64, 6]]
/encoder/layer.11/attention/self/MatMul (MatMul, index:516): [[1, 12, 6, 6]]
/encoder/layer.11/attention/self/Div (Eltwise, index:517): [[1, 12, 6, 6]]
/encoder/layer.11/attention/self/Add (Eltwise, index:518): [[1, 12, 6, 6]]
/encoder/layer.11/attention/self/Softmax (Softmax, index:519): [[1, 12, 6, 6]]
/encoder/layer.11/attention/self/value/MatMul (MatMul, index:520): [[1, 6, 768]]
/encoder/layer.11/attention/self/value/Add (Eltwise, index:521): [[1, 6, 768]]
/encoder/layer.11/attention/self/Reshape_1 (Reshape, index:522): [[1, 6, 12, 64]]
/encoder/layer.11/attention/self/Transpose (Transpose, index:523): [[1, 12, 6, 64]]
/encoder/layer.11/attention/self/MatMul_1 (MatMul, index:524): [[1, 12, 6, 64]]
/encoder/layer.11/attention/self/Transpose_3 (Transpose, index:525): [[1, 6, 12, 64]]
/encoder/layer.11/attention/self/Reshape_3 (Reshape, index:526): [[1, 6, 768]]
/encoder/layer.11/attention/output/dense/MatMul (MatMul, index:527): [[1, 6, 768]]
/encoder/layer.11/attention/output/dense/Add (Eltwise, index:528): [[1, 6, 768]]
/encoder/layer.11/attention/output/Add (Eltwise, index:529): [[1, 6, 768]]
/encoder/layer.11/attention/output/LayerNorm/ReduceMean (Reduce, index:530): [[1, 6, 1]]
/encoder/layer.11/attention/output/LayerNorm/Sub (Eltwise, index:531): [[1, 6, 768]]
/encoder/layer.11/attention/output/LayerNorm/Pow (Eltwise, index:532): [[1, 6, 768]]
/encoder/layer.11/attention/output/LayerNorm/ReduceMean_1 (Reduce, index:533): [[1, 6, 1]]
/encoder/layer.11/attention/output/LayerNorm/Add (Eltwise, index:534): [[1, 6, 1]]
/encoder/layer.11/attention/output/LayerNorm/Sqrt (Eltwise, index:535): [[1, 6, 1]]
/encoder/layer.11/attention/output/LayerNorm/Div (Eltwise, index:536): [[1, 6, 768]]
/encoder/layer.11/attention/output/LayerNorm/Mul (Eltwise, index:537): [[1, 6, 768]]
/encoder/layer.11/attention/output/LayerNorm/Add_1 (Eltwise, index:538): [[1, 6, 768]]
/encoder/layer.11/intermediate/dense/MatMul (MatMul, index:539): [[1, 6, 3072]]
Gelu_/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1 (Activation, index:540): [[1, 6, 3072]]
/encoder/layer.11/output/dense/MatMul (MatMul, index:541): [[1, 6, 768]]
/encoder/layer.11/output/dense/Add (Eltwise, index:542): [[1, 6, 768]]
/encoder/layer.11/output/Add (Eltwise, index:543): [[1, 6, 768]]
/encoder/layer.11/output/LayerNorm/ReduceMean (Reduce, index:544): [[1, 6, 1]]
/encoder/layer.11/output/LayerNorm/Sub (Eltwise, index:545): [[1, 6, 768]]
/encoder/layer.11/output/LayerNorm/Pow (Eltwise, index:546): [[1, 6, 768]]
/encoder/layer.11/output/LayerNorm/ReduceMean_1 (Reduce, index:547): [[1, 6, 1]]
/encoder/layer.11/output/LayerNorm/Add (Eltwise, index:548): [[1, 6, 1]]
/encoder/layer.11/output/LayerNorm/Sqrt (Eltwise, index:549): [[1, 6, 1]]
/encoder/layer.11/output/LayerNorm/Div (Eltwise, index:550): [[1, 6, 768]]
/encoder/layer.11/output/LayerNorm/Mul (Eltwise, index:551): [[1, 6, 768]]
mace_output_node_/encoder/layer.11/output/LayerNorm/Add_1 (Eltwise, index:552): [[1, 6, 768]]
last_hidden_state (Dequantize, index:): [[1, 6, 768]]
/pooler/Gather (Gather, index:553): [[1, 1, 768]]
/pooler/dense/Gemm (MatMul, index:554): [[1, 768]]
mace_output_node_/pooler/activation/Tanh (Activation, index:555): [[1, 768]]
pooler_output (Dequantize, index:): [[1, 768]]
Check quantize info
Op output mace_input_node_input_ids range: [-1.000000, 0.992188]
Op output mace_input_node_attention_mask range: [-1.000000, 0.992188]
Op output /embeddings/Add_output_0 range: [-1.009609, 0.684143]
Op output /embeddings/Add_1_output_0 range: [-1.958896, 1.416229]
Op output /embeddings/LayerNorm/ReduceMean_output_0 range: [-0.033998, 0.001533]
Op output /embeddings/LayerNorm/Sub_output_0 range: [-1.959769, 1.416860]
Op output /embeddings/LayerNorm/Pow_output_0 range: [0.000000, 3.840695]
Op output /embeddings/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 0.021077]
Op output /embeddings/LayerNorm/Add_output_0 range: [0.000000, 0.021077]
Op output /embeddings/LayerNorm/Sqrt_output_0 range: [0.000000, 0.145179]
Op output /embeddings/LayerNorm/Div_output_0 range: [-15.125532, 9.758408]
Op output /embeddings/LayerNorm/Mul_output_0 range: [-11.663344, 4.072914]
Op output /embeddings/LayerNorm/Add_1_output_0 range: [-10.860878, 4.273132]
Op output /encoder/layer.0/attention/self/query/MatMul_output_0 range: [-4.467246, 4.502421]
Op output /encoder/layer.0/attention/self/query/Add_output_0 range: [-4.619343, 4.441676]
Op output /encoder/layer.0/attention/self/Reshape_2_output_0 range: [-4.619343, 4.441676]
Op output /encoder/layer.0/attention/self/Transpose_1_output_0 range: [-4.619343, 4.441676]
Op output /encoder/layer.0/attention/self/key/MatMul_output_0 range: [-5.175213, 4.822358]
Op output /encoder/layer.0/attention/self/key/Add_output_0 range: [-5.178979, 4.750642]
Op output /encoder/layer.0/attention/self/Reshape_output_0 range: [-5.178979, 4.750642]
Op output /encoder/layer.0/attention/self/Transpose_2_output_0 range: [-5.178979, 4.750642]
Op output /encoder/layer.0/attention/self/MatMul_output_0 range: [-33.655487, 83.908203]
Op output /encoder/layer.0/attention/self/Div_output_0 range: [-4.206936, 10.488525]
Op output mace_input_node_token_type_ids range: [-1.000000, 0.992188]
Op output /Sub_output_0 range: [0.000000, 1.000000]
Op output /Mul_output_0 range: [-340282001837565597733306976381245063168.000000, 0.000000]
Op output /encoder/layer.0/attention/self/Add_output_0 range: [-340282346638528859811704183484516925440.000000, 0.000000]
Op output /encoder/layer.0/attention/self/Softmax_output_0 range: [0.000000, 1.000000]
Op output /encoder/layer.0/attention/self/value/MatMul_output_0 range: [-2.635584, 2.574291]
Op output /encoder/layer.0/attention/self/value/Add_output_0 range: [-2.583836, 2.563650]
Op output /encoder/layer.0/attention/self/Reshape_1_output_0 range: [-2.583836, 2.563650]
Op output /encoder/layer.0/attention/self/Transpose_output_0 range: [-2.583836, 2.563650]
Op output /encoder/layer.0/attention/self/MatMul_1_output_0 range: [-1.083122, 1.547317]
Op output /encoder/layer.0/attention/self/Transpose_3_output_0 range: [-1.083122, 1.547317]
Op output /encoder/layer.0/attention/self/Reshape_3_output_0 range: [-1.083122, 1.547317]
Op output /encoder/layer.0/attention/output/dense/MatMul_output_0 range: [-1.315363, 1.225679]
Op output /encoder/layer.0/attention/output/dense/Add_output_0 range: [-1.430755, 1.194011]
Op output /encoder/layer.0/attention/output/Add_output_0 range: [-11.960162, 4.262398]
Op output /encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0 range: [-0.033571, 0.017083]
Op output /encoder/layer.0/attention/output/LayerNorm/Sub_output_0 range: [-11.982623, 4.270403]
Op output /encoder/layer.0/attention/output/LayerNorm/Pow_output_0 range: [0.000000, 142.243576]
Op output /encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 0.471695]
Op output /encoder/layer.0/attention/output/LayerNorm/Add_output_0 range: [0.000000, 0.471695]
Op output /encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0 range: [0.000000, 0.686800]
Op output /encoder/layer.0/attention/output/LayerNorm/Div_output_0 range: [-19.612503, 6.989562]
Op output /encoder/layer.0/attention/output/LayerNorm/Mul_output_0 range: [-58.518047, 7.218085]
Op output /encoder/layer.0/attention/output/LayerNorm/Add_1_output_0 range: [-62.722702, 6.516644]
Op output /encoder/layer.0/intermediate/dense/MatMul_output_0 range: [-16.903728, 8.907354]
Op output /encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0 range: [-0.175930, 8.796521]
Op output /encoder/layer.0/output/dense/MatMul_output_0 range: [-14.181871, 2.407015]
Op output /encoder/layer.0/output/dense/Add_output_0 range: [-14.142332, 2.249917]
Op output /encoder/layer.0/output/Add_output_0 range: [-61.768147, 7.314649]
Op output /encoder/layer.0/output/LayerNorm/ReduceMean_output_0 range: [-0.081435, 0.000000]
Op output /encoder/layer.0/output/LayerNorm/Sub_output_0 range: [-61.686710, 7.305005]
Op output /encoder/layer.0/output/LayerNorm/Pow_output_0 range: [0.000000, 3805.250244]
Op output /encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 5.845746]
Op output /encoder/layer.0/output/LayerNorm/Add_output_0 range: [0.000000, 5.845746]
Op output /encoder/layer.0/output/LayerNorm/Sqrt_output_0 range: [0.000000, 2.417798]
Op output /encoder/layer.0/output/LayerNorm/Div_output_0 range: [-25.513594, 3.021347]
Op output /encoder/layer.0/output/LayerNorm/Mul_output_0 range: [-8.763743, 2.084580]
Op output /encoder/layer.0/output/LayerNorm/Add_1_output_0 range: [-10.089624, 2.162062]
Op output /encoder/layer.1/attention/self/query/MatMul_output_0 range: [-4.818451, 4.419932]
Op output /encoder/layer.1/attention/self/query/Add_output_0 range: [-4.852503, 4.968039]
Op output /encoder/layer.1/attention/self/Reshape_2_output_0 range: [-4.852503, 4.968039]
Op output /encoder/layer.1/attention/self/Transpose_1_output_0 range: [-4.852503, 4.968039]
Op output /encoder/layer.1/attention/self/key/MatMul_output_0 range: [-5.324080, 5.200264]
Op output /encoder/layer.1/attention/self/key/Add_output_0 range: [-5.282986, 5.241713]
Op output /encoder/layer.1/attention/self/Reshape_output_0 range: [-5.282986, 5.241713]
Op output /encoder/layer.1/attention/self/Transpose_2_output_0 range: [-5.282986, 5.241713]
Op output /encoder/layer.1/attention/self/MatMul_output_0 range: [-38.796078, 93.110588]
Op output /encoder/layer.1/attention/self/Div_output_0 range: [-4.849510, 11.638824]
Op output /encoder/layer.1/attention/self/Add_output_0 range: [-340282346638528859811704183484516925440.000000, 0.000000]
Op output /encoder/layer.1/attention/self/Softmax_output_0 range: [0.000000, 1.000000]
Op output /encoder/layer.1/attention/self/value/MatMul_output_0 range: [-2.245283, 2.733388]
Op output /encoder/layer.1/attention/self/value/Add_output_0 range: [-2.223331, 2.793920]
Op output /encoder/layer.1/attention/self/Reshape_1_output_0 range: [-2.223331, 2.793920]
Op output /encoder/layer.1/attention/self/Transpose_output_0 range: [-2.223331, 2.793920]
Op output /encoder/layer.1/attention/self/MatMul_1_output_0 range: [-1.391079, 1.516504]
Op output /encoder/layer.1/attention/self/Transpose_3_output_0 range: [-1.391079, 1.516504]
Op output /encoder/layer.1/attention/self/Reshape_3_output_0 range: [-1.391079, 1.516504]
Op output /encoder/layer.1/attention/output/dense/MatMul_output_0 range: [-0.851282, 1.235996]
Op output /encoder/layer.1/attention/output/dense/Add_output_0 range: [-0.774997, 1.181678]
Op output /encoder/layer.1/attention/output/Add_output_0 range: [-10.538882, 2.258332]
Op output /encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0 range: [-0.020435, 0.000000]
Op output /encoder/layer.1/attention/output/LayerNorm/Sub_output_0 range: [-10.549093, 2.260520]
Op output /encoder/layer.1/attention/output/LayerNorm/Pow_output_0 range: [0.000000, 110.776443]
Op output /encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 0.564334]
Op output /encoder/layer.1/attention/output/LayerNorm/Add_output_0 range: [0.000000, 0.564334]
Op output /encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0 range: [0.000000, 0.751222]
Op output /encoder/layer.1/attention/output/LayerNorm/Div_output_0 range: [-20.764248, 3.863116]
Op output /encoder/layer.1/attention/output/LayerNorm/Mul_output_0 range: [-63.009518, 3.111581]
Op output /encoder/layer.1/attention/output/LayerNorm/Add_1_output_0 range: [-65.472107, 3.517097]
Op output /encoder/layer.1/intermediate/dense/MatMul_output_0 range: [-14.671885, 8.141107]
Op output /encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0 range: [-0.191660, 7.953907]
Op output /encoder/layer.1/output/dense/MatMul_output_0 range: [-15.098243, 2.643932]
Op output /encoder/layer.1/output/dense/Add_output_0 range: [-15.116614, 2.325633]
Op output /encoder/layer.1/output/Add_output_0 range: [-68.820938, 3.398565]
Op output /encoder/layer.1/output/LayerNorm/ReduceMean_output_0 range: [-0.093467, 0.000000]
Op output /encoder/layer.1/output/LayerNorm/Sub_output_0 range: [-68.727470, 3.691972]
Op output /encoder/layer.1/output/LayerNorm/Pow_output_0 range: [0.000000, 4723.465332]
Op output /encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 6.782264]
Op output /encoder/layer.1/output/LayerNorm/Add_output_0 range: [0.000000, 6.782264]
Op output /encoder/layer.1/output/LayerNorm/Sqrt_output_0 range: [0.000000, 2.604278]
Op output /encoder/layer.1/output/LayerNorm/Div_output_0 range: [-26.390223, 2.741841]
Op output /encoder/layer.1/output/LayerNorm/Mul_output_0 range: [-10.553708, 2.140611]
Op output /encoder/layer.1/output/LayerNorm/Add_1_output_0 range: [-11.231475, 2.027905]
Op output /encoder/layer.2/attention/self/query/MatMul_output_0 range: [-5.733317, 4.860856]
Op output /encoder/layer.2/attention/self/query/Add_output_0 range: [-6.534132, 4.956928]
Op output /encoder/layer.2/attention/self/Reshape_2_output_0 range: [-6.534132, 4.956928]
Op output /encoder/layer.2/attention/self/Transpose_1_output_0 range: [-6.534132, 4.956928]
Op output /encoder/layer.2/attention/self/key/MatMul_output_0 range: [-6.311193, 5.350794]
Op output /encoder/layer.2/attention/self/key/Add_output_0 range: [-6.304707, 5.345295]
Op output /encoder/layer.2/attention/self/Reshape_output_0 range: [-6.304707, 5.345295]
Op output /encoder/layer.2/attention/self/Transpose_2_output_0 range: [-6.304707, 5.345295]
Op output /encoder/layer.2/attention/self/MatMul_output_0 range: [-34.285885, 113.898872]
Op output /encoder/layer.2/attention/self/Div_output_0 range: [-4.285736, 14.237360]
Op output /encoder/layer.2/attention/self/Add_output_0 range: [-340282346638528859811704183484516925440.000000, 0.000000]
Op output /encoder/layer.2/attention/self/Softmax_output_0 range: [0.000000, 1.000000]
Op output /encoder/layer.2/attention/self/value/MatMul_output_0 range: [-2.255232, 2.382543]
Op output /encoder/layer.2/attention/self/value/Add_output_0 range: [-2.275852, 2.404328]
Op output /encoder/layer.2/attention/self/Reshape_1_output_0 range: [-2.275852, 2.404328]
Op output /encoder/layer.2/attention/self/Transpose_output_0 range: [-2.275852, 2.404328]
Op output /encoder/layer.2/attention/self/MatMul_1_output_0 range: [-0.827428, 1.182040]
Op output /encoder/layer.2/attention/self/Transpose_3_output_0 range: [-0.827428, 1.182040]
Op output /encoder/layer.2/attention/self/Reshape_3_output_0 range: [-0.827428, 1.182040]
Op output /encoder/layer.2/attention/output/dense/MatMul_output_0 range: [-0.875769, 0.855402]
Op output /encoder/layer.2/attention/output/dense/Add_output_0 range: [-0.702128, 0.718845]
Op output /encoder/layer.2/attention/output/Add_output_0 range: [-11.660506, 2.234022]
Op output /encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0 range: [-0.017519, 0.000000]
Op output /encoder/layer.2/attention/output/LayerNorm/Sub_output_0 range: [-11.649036, 2.231825]
Op output /encoder/layer.2/attention/output/LayerNorm/Pow_output_0 range: [0.000000, 135.700043]
Op output /encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 0.638664]
Op output /encoder/layer.2/attention/output/LayerNorm/Add_output_0 range: [0.000000, 0.638664]
Op output /encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0 range: [0.000000, 0.799165]
Op output /encoder/layer.2/attention/output/LayerNorm/Div_output_0 range: [-22.625628, 2.790826]
Op output /encoder/layer.2/attention/output/LayerNorm/Mul_output_0 range: [-51.669430, 2.551577]
Op output /encoder/layer.2/attention/output/LayerNorm/Add_1_output_0 range: [-53.687969, 2.651258]
Op output /encoder/layer.2/intermediate/dense/MatMul_output_0 range: [-19.787821, 53.341080]
Op output /encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0 range: [-0.208905, 53.061798]
Op output /encoder/layer.2/output/dense/MatMul_output_0 range: [-214.082352, 3.411671]
Op output /encoder/layer.2/output/dense/Add_output_0 range: [-214.140839, 3.412603]
Op output /encoder/layer.2/output/Add_output_0 range: [-218.363129, 3.479891]
Op output /encoder/layer.2/output/LayerNorm/ReduceMean_output_0 range: [-0.309756, 0.000000]
Op output /encoder/layer.2/output/LayerNorm/Sub_output_0 range: [-218.053375, 3.474954]
Op output /encoder/layer.2/output/LayerNorm/Pow_output_0 range: [0.000000, 47547.273438]
Op output /encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 65.710602]
Op output /encoder/layer.2/output/LayerNorm/Add_output_0 range: [0.000000, 65.710602]
Op output /encoder/layer.2/output/LayerNorm/Sqrt_output_0 range: [0.000000, 8.106208]
Op output /encoder/layer.2/output/LayerNorm/Div_output_0 range: [-26.899553, 2.414062]
Op output /encoder/layer.2/output/LayerNorm/Mul_output_0 range: [-14.776430, 2.120385]
Op output /encoder/layer.2/output/LayerNorm/Add_1_output_0 range: [-14.657798, 2.028535]
Op output /encoder/layer.3/attention/self/query/MatMul_output_0 range: [-5.193159, 4.198724]
Op output /encoder/layer.3/attention/self/query/Add_output_0 range: [-5.312323, 4.575577]
Op output /encoder/layer.3/attention/self/Reshape_2_output_0 range: [-5.312323, 4.575577]
Op output /encoder/layer.3/attention/self/Transpose_1_output_0 range: [-5.312323, 4.575577]
Op output /encoder/layer.3/attention/self/key/MatMul_output_0 range: [-5.071262, 5.705170]
Op output /encoder/layer.3/attention/self/key/Add_output_0 range: [-5.060175, 5.692697]
Op output /encoder/layer.3/attention/self/Reshape_output_0 range: [-5.060175, 5.692697]
Op output /encoder/layer.3/attention/self/Transpose_2_output_0 range: [-5.060175, 5.692697]
Op output /encoder/layer.3/attention/self/MatMul_output_0 range: [-12.592158, 94.441185]
Op output /encoder/layer.3/attention/self/Div_output_0 range: [-1.574020, 11.805148]
Op output /encoder/layer.3/attention/self/Add_output_0 range: [-340282346638528859811704183484516925440.000000, 0.000000]
Op output /encoder/layer.3/attention/self/Softmax_output_0 range: [0.000000, 1.000000]
Op output /encoder/layer.3/attention/self/value/MatMul_output_0 range: [-2.220177, 2.345510]
Op output /encoder/layer.3/attention/self/value/Add_output_0 range: [-2.215790, 2.340875]
Op output /encoder/layer.3/attention/self/Reshape_1_output_0 range: [-2.215790, 2.340875]
Op output /encoder/layer.3/attention/self/Transpose_output_0 range: [-2.215790, 2.340875]
Op output /encoder/layer.3/attention/self/MatMul_1_output_0 range: [-0.870853, 0.850601]
Op output /encoder/layer.3/attention/self/Transpose_3_output_0 range: [-0.870853, 0.850601]
Op output /encoder/layer.3/attention/self/Reshape_3_output_0 range: [-0.870853, 0.850601]
Op output /encoder/layer.3/attention/output/dense/MatMul_output_0 range: [-0.818350, 0.563632]
Op output /encoder/layer.3/attention/output/dense/Add_output_0 range: [-0.848479, 0.556470]
Op output /encoder/layer.3/attention/output/Add_output_0 range: [-14.725736, 1.963431]
Op output /encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0 range: [-0.018814, 0.000000]
Op output /encoder/layer.3/attention/output/LayerNorm/Sub_output_0 range: [-14.710757, 2.035864]
Op output /encoder/layer.3/attention/output/LayerNorm/Pow_output_0 range: [0.000000, 216.406372]
Op output /encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 0.573193]
Op output /encoder/layer.3/attention/output/LayerNorm/Add_output_0 range: [0.000000, 0.573193]
Op output /encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0 range: [0.000000, 0.757095]
Op output /encoder/layer.3/attention/output/LayerNorm/Div_output_0 range: [-25.583183, 2.657993]
Op output /encoder/layer.3/attention/output/LayerNorm/Mul_output_0 range: [-89.208862, 2.517992]
Op output /encoder/layer.3/attention/output/LayerNorm/Add_1_output_0 range: [-90.078568, 2.542540]
Op output /encoder/layer.3/intermediate/dense/MatMul_output_0 range: [-57.988136, 5.748824]
Op output /encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0 range: [-0.173566, 5.358838]
Op output /encoder/layer.3/output/dense/MatMul_output_0 range: [-57.054493, 3.565906]
Op output /encoder/layer.3/output/dense/Add_output_0 range: [-57.238319, 3.074786]
Op output /encoder/layer.3/output/Add_output_0 range: [-147.316895, 2.946338]
Op output /encoder/layer.3/output/LayerNorm/ReduceMean_output_0 range: [-0.178270, 0.000000]
Op output /encoder/layer.3/output/LayerNorm/Sub_output_0 range: [-147.138626, 2.942773]
Op output /encoder/layer.3/output/LayerNorm/Pow_output_0 range: [0.000000, 21649.775391]
Op output /encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 28.444326]
Op output /encoder/layer.3/output/LayerNorm/Add_output_0 range: [0.000000, 28.444326]
Op output /encoder/layer.3/output/LayerNorm/Sqrt_output_0 range: [0.000000, 5.333322]
Op output /encoder/layer.3/output/LayerNorm/Div_output_0 range: [-27.588551, 2.998755]
Op output /encoder/layer.3/output/LayerNorm/Mul_output_0 range: [-14.041587, 2.383205]
Op output /encoder/layer.3/output/LayerNorm/Add_1_output_0 range: [-13.987506, 2.225285]
Op output /encoder/layer.4/attention/self/query/MatMul_output_0 range: [-5.487629, 4.230047]
Op output /encoder/layer.4/attention/self/query/Add_output_0 range: [-6.009500, 4.415143]
Op output /encoder/layer.4/attention/self/Reshape_2_output_0 range: [-6.009500, 4.415143]
Op output /encoder/layer.4/attention/self/Transpose_1_output_0 range: [-6.009500, 4.415143]
Op output /encoder/layer.4/attention/self/key/MatMul_output_0 range: [-5.087086, 4.048174]
Op output /encoder/layer.4/attention/self/key/Add_output_0 range: [-5.090903, 4.051211]
Op output /encoder/layer.4/attention/self/Reshape_output_0 range: [-5.090903, 4.051211]
Op output /encoder/layer.4/attention/self/Transpose_2_output_0 range: [-5.090903, 4.051211]
Op output /encoder/layer.4/attention/self/MatMul_output_0 range: [-29.210669, 74.243782]
Op output /encoder/layer.4/attention/self/Div_output_0 range: [-3.651334, 9.280473]
Op output /encoder/layer.4/attention/self/Add_output_0 range: [-340282346638528859811704183484516925440.000000, 0.000000]
Op output /encoder/layer.4/attention/self/Softmax_output_0 range: [0.000000, 1.000000]
Op output /encoder/layer.4/attention/self/value/MatMul_output_0 range: [-2.262988, 3.339555]
Op output /encoder/layer.4/attention/self/value/Add_output_0 range: [-2.297803, 3.390933]
Op output /encoder/layer.4/attention/self/Reshape_1_output_0 range: [-2.297803, 3.390933]
Op output /encoder/layer.4/attention/self/Transpose_output_0 range: [-2.297803, 3.390933]
Op output /encoder/layer.4/attention/self/MatMul_1_output_0 range: [-1.037586, 0.893687]
Op output /encoder/layer.4/attention/self/Transpose_3_output_0 range: [-1.037586, 0.893687]
Op output /encoder/layer.4/attention/self/Reshape_3_output_0 range: [-1.037586, 0.893687]
Op output /encoder/layer.4/attention/output/dense/MatMul_output_0 range: [-1.292382, 0.806710]
Op output /encoder/layer.4/attention/output/dense/Add_output_0 range: [-0.771374, 0.741706]
Op output /encoder/layer.4/attention/output/Add_output_0 range: [-14.738082, 2.344695]
Op output /encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0 range: [-0.026189, 0.000000]
Op output /encoder/layer.4/attention/output/LayerNorm/Sub_output_0 range: [-14.713473, 2.340780]
Op output /encoder/layer.4/attention/output/LayerNorm/Pow_output_0 range: [0.000000, 216.486298]
Op output /encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 0.644000]
Op output /encoder/layer.4/attention/output/LayerNorm/Add_output_0 range: [0.000000, 0.644000]
Op output /encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0 range: [0.000000, 0.802496]
Op output /encoder/layer.4/attention/output/LayerNorm/Div_output_0 range: [-23.836288, 2.940159]
Op output /encoder/layer.4/attention/output/LayerNorm/Mul_output_0 range: [-89.097862, 2.514859]
Op output /encoder/layer.4/attention/output/LayerNorm/Add_1_output_0 range: [-90.189201, 2.545663]
Op output /encoder/layer.4/intermediate/dense/MatMul_output_0 range: [-54.872486, 7.041160]
Op output /encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0 range: [-0.185170, 6.560309]
Op output /encoder/layer.4/output/dense/MatMul_output_0 range: [-44.787708, 4.228882]
Op output /encoder/layer.4/output/dense/Add_output_0 range: [-44.885410, 3.820035]
Op output /encoder/layer.4/output/Add_output_0 range: [-135.066788, 3.254622]
Op output /encoder/layer.4/output/LayerNorm/ReduceMean_output_0 range: [-0.168794, 0.000000]
Op output /encoder/layer.4/output/LayerNorm/Sub_output_0 range: [-134.897995, 3.250554]
Op output /encoder/layer.4/output/LayerNorm/Pow_output_0 range: [0.000000, 18197.468750]
Op output /encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 23.954878]
Op output /encoder/layer.4/output/LayerNorm/Add_output_0 range: [0.000000, 23.954878]
Op output /encoder/layer.4/output/LayerNorm/Sqrt_output_0 range: [0.000000, 4.894372]
Op output /encoder/layer.4/output/LayerNorm/Div_output_0 range: [-27.561859, 2.732426]
Op output /encoder/layer.4/output/LayerNorm/Mul_output_0 range: [-15.062826, 2.239069]
Op output /encoder/layer.4/output/LayerNorm/Add_1_output_0 range: [-14.862793, 2.132777]
Op output /encoder/layer.5/attention/self/query/MatMul_output_0 range: [-6.223220, 4.286191]
Op output /encoder/layer.5/attention/self/query/Add_output_0 range: [-6.578584, 4.605009]
Op output /encoder/layer.5/attention/self/Reshape_2_output_0 range: [-6.578584, 4.605009]
Op output /encoder/layer.5/attention/self/Transpose_1_output_0 range: [-6.578584, 4.605009]
Op output /encoder/layer.5/attention/self/key/MatMul_output_0 range: [-3.966173, 3.754240]
Op output /encoder/layer.5/attention/self/key/Add_output_0 range: [-4.005904, 3.732774]
Op output /encoder/layer.5/attention/self/Reshape_output_0 range: [-4.005904, 3.732774]
Op output /encoder/layer.5/attention/self/Transpose_2_output_0 range: [-4.005904, 3.732774]
Op output /encoder/layer.5/attention/self/MatMul_output_0 range: [-17.961876, 66.858093]
Op output /encoder/layer.5/attention/self/Div_output_0 range: [-2.245234, 8.357262]
Op output /encoder/layer.5/attention/self/Add_output_0 range: [-340282346638528859811704183484516925440.000000, 0.000000]
Op output /encoder/layer.5/attention/self/Softmax_output_0 range: [0.000000, 1.000000]
Op output /encoder/layer.5/attention/self/value/MatMul_output_0 range: [-2.130383, 2.512759]
Op output /encoder/layer.5/attention/self/value/Add_output_0 range: [-2.128851, 2.550951]
Op output /encoder/layer.5/attention/self/Reshape_1_output_0 range: [-2.128851, 2.550951]
Op output /encoder/layer.5/attention/self/Transpose_output_0 range: [-2.128851, 2.550951]
Op output /encoder/layer.5/attention/self/MatMul_1_output_0 range: [-1.027803, 0.830990]
Op output /encoder/layer.5/attention/self/Transpose_3_output_0 range: [-1.027803, 0.830990]
Op output /encoder/layer.5/attention/self/Reshape_3_output_0 range: [-1.027803, 0.830990]
Op output /encoder/layer.5/attention/output/dense/MatMul_output_0 range: [-1.016987, 0.835382]
Op output /encoder/layer.5/attention/output/dense/Add_output_0 range: [-0.960399, 0.776493]
Op output /encoder/layer.5/attention/output/Add_output_0 range: [-15.107950, 2.324300]
Op output /encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0 range: [-0.025829, 0.000000]
Op output /encoder/layer.5/attention/output/LayerNorm/Sub_output_0 range: [-15.083124, 2.399588]
Op output /encoder/layer.5/attention/output/LayerNorm/Pow_output_0 range: [0.000000, 227.500641]
Op output /encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 0.688404]
Op output /encoder/layer.5/attention/output/LayerNorm/Add_output_0 range: [0.000000, 0.688404]
Op output /encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0 range: [0.000000, 0.829701]
Op output /encoder/layer.5/attention/output/LayerNorm/Div_output_0 range: [-21.739353, 3.008571]
Op output /encoder/layer.5/attention/output/LayerNorm/Mul_output_0 range: [-73.823212, 2.700849]
Op output /encoder/layer.5/attention/output/LayerNorm/Add_1_output_0 range: [-75.218971, 3.070162]
Op output /encoder/layer.5/intermediate/dense/MatMul_output_0 range: [-41.738449, 3.360299]
Op output /encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0 range: [-0.172451, 2.968617]
Op output /encoder/layer.5/output/dense/MatMul_output_0 range: [-17.995325, 3.447702]
Op output /encoder/layer.5/output/dense/Add_output_0 range: [-18.268337, 2.906326]
Op output /encoder/layer.5/output/Add_output_0 range: [-93.487305, 3.420267]
Op output /encoder/layer.5/output/LayerNorm/ReduceMean_output_0 range: [-0.111764, 0.000000]
Op output /encoder/layer.5/output/LayerNorm/Sub_output_0 range: [-93.375542, 3.416178]
Op output /encoder/layer.5/output/LayerNorm/Pow_output_0 range: [0.000000, 8718.992188]
Op output /encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 11.644313]
Op output /encoder/layer.5/output/LayerNorm/Add_output_0 range: [0.000000, 11.644313]
Op output /encoder/layer.5/output/LayerNorm/Sqrt_output_0 range: [0.000000, 3.412376]
Op output /encoder/layer.5/output/LayerNorm/Div_output_0 range: [-27.363787, 2.842991]
Op output /encoder/layer.5/output/LayerNorm/Mul_output_0 range: [-15.620423, 2.321955]
Op output /encoder/layer.5/output/LayerNorm/Add_1_output_0 range: [-15.217549, 2.262068]
Op output /encoder/layer.6/attention/self/query/MatMul_output_0 range: [-6.939736, 5.349380]
Op output /encoder/layer.6/attention/self/query/Add_output_0 range: [-7.396748, 5.701660]
Op output /encoder/layer.6/attention/self/Reshape_2_output_0 range: [-7.396748, 5.701660]
Op output /encoder/layer.6/attention/self/Transpose_1_output_0 range: [-7.396748, 5.701660]
Op output /encoder/layer.6/attention/self/key/MatMul_output_0 range: [-4.441094, 3.648041]
Op output /encoder/layer.6/attention/self/key/Add_output_0 range: [-4.429317, 3.696409]
Op output /encoder/layer.6/attention/self/Reshape_output_0 range: [-4.429317, 3.696409]
Op output /encoder/layer.6/attention/self/Transpose_2_output_0 range: [-4.429317, 3.696409]
Op output /encoder/layer.6/attention/self/MatMul_output_0 range: [-14.985177, 71.860733]
Op output /encoder/layer.6/attention/self/Div_output_0 range: [-1.873147, 8.982592]
Op output /encoder/layer.6/attention/self/Add_output_0 range: [-340282346638528859811704183484516925440.000000, 0.000000]
Op output /encoder/layer.6/attention/self/Softmax_output_0 range: [0.000000, 1.000000]
Op output /encoder/layer.6/attention/self/value/MatMul_output_0 range: [-2.405538, 2.386745]
Op output /encoder/layer.6/attention/self/value/Add_output_0 range: [-2.414096, 2.395236]
Op output /encoder/layer.6/attention/self/Reshape_1_output_0 range: [-2.414096, 2.395236]
Op output /encoder/layer.6/attention/self/Transpose_output_0 range: [-2.414096, 2.395236]
Op output /encoder/layer.6/attention/self/MatMul_1_output_0 range: [-1.255689, 1.326575]
Op output /encoder/layer.6/attention/self/Transpose_3_output_0 range: [-1.255689, 1.326575]
Op output /encoder/layer.6/attention/self/Reshape_3_output_0 range: [-1.255689, 1.326575]
Op output /encoder/layer.6/attention/output/dense/MatMul_output_0 range: [-1.081714, 1.472333]
Op output /encoder/layer.6/attention/output/dense/Add_output_0 range: [-1.010648, 1.420628]
Op output /encoder/layer.6/attention/output/Add_output_0 range: [-15.293551, 2.845312]
Op output /encoder/layer.6/attention/output/LayerNorm/ReduceMean_output_0 range: [-0.021750, 0.000000]
Op output /encoder/layer.6/attention/output/LayerNorm/Sub_output_0 range: [-15.273210, 2.841527]
Op output /encoder/layer.6/attention/output/LayerNorm/Pow_output_0 range: [0.000000, 233.270935]
Op output /encoder/layer.6/attention/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 0.763991]
Op output /encoder/layer.6/attention/output/LayerNorm/Add_output_0 range: [0.000000, 0.763991]
Op output /encoder/layer.6/attention/output/LayerNorm/Sqrt_output_0 range: [0.000000, 0.874066]
Op output /encoder/layer.6/attention/output/LayerNorm/Div_output_0 range: [-21.131073, 3.250934]
Op output /encoder/layer.6/attention/output/LayerNorm/Mul_output_0 range: [-70.667183, 2.884375]
Op output /encoder/layer.6/attention/output/LayerNorm/Add_1_output_0 range: [-72.669609, 2.966106]
Op output /encoder/layer.6/intermediate/dense/MatMul_output_0 range: [-20.386309, 4.019835]
Op output /encoder/layer.6/intermediate/intermediate_act_fn/Mul_1_output_0 range: [-0.174090, 3.861632]
Op output /encoder/layer.6/output/dense/MatMul_output_0 range: [-15.711932, 2.582783]
Op output /encoder/layer.6/output/dense/Add_output_0 range: [-16.261730, 2.086682]
Op output /encoder/layer.6/output/Add_output_0 range: [-89.248009, 3.265171]
Op output /encoder/layer.6/output/LayerNorm/ReduceMean_output_0 range: [-0.110949, 0.000000]
Op output /encoder/layer.6/output/LayerNorm/Sub_output_0 range: [-88.820389, 3.249527]
Op output /encoder/layer.6/output/LayerNorm/Pow_output_0 range: [0.000000, 7889.061523]
Op output /encoder/layer.6/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 10.584941]
Op output /encoder/layer.6/output/LayerNorm/Add_output_0 range: [0.000000, 10.584941]
Op output /encoder/layer.6/output/LayerNorm/Sqrt_output_0 range: [0.000000, 3.253451]
Op output /encoder/layer.6/output/LayerNorm/Div_output_0 range: [-27.372034, 2.975221]
Op output /encoder/layer.6/output/LayerNorm/Mul_output_0 range: [-14.605625, 2.400925]
Op output /encoder/layer.6/output/LayerNorm/Add_1_output_0 range: [-13.820922, 2.271932]
Op output /encoder/layer.7/attention/self/query/MatMul_output_0 range: [-5.666729, 4.729069]
Op output /encoder/layer.7/attention/self/query/Add_output_0 range: [-6.547894, 5.294042]
Op output /encoder/layer.7/attention/self/Reshape_2_output_0 range: [-6.547894, 5.294042]
Op output /encoder/layer.7/attention/self/Transpose_1_output_0 range: [-6.547894, 5.294042]
Op output /encoder/layer.7/attention/self/key/MatMul_output_0 range: [-5.524045, 4.757936]
Op output /encoder/layer.7/attention/self/key/Add_output_0 range: [-5.506471, 4.742800]
Op output /encoder/layer.7/attention/self/Reshape_output_0 range: [-5.506471, 4.742800]
Op output /encoder/layer.7/attention/self/Transpose_2_output_0 range: [-5.506471, 4.742800]
Op output /encoder/layer.7/attention/self/MatMul_output_0 range: [-22.587952, 64.683678]
Op output /encoder/layer.7/attention/self/Div_output_0 range: [-2.823494, 8.085460]
Op output /encoder/layer.7/attention/self/Add_output_0 range: [-340282346638528859811704183484516925440.000000, 0.000000]
Op output /encoder/layer.7/attention/self/Softmax_output_0 range: [0.000000, 1.000000]
Op output /encoder/layer.7/attention/self/value/MatMul_output_0 range: [-2.633378, 2.129114]
Op output /encoder/layer.7/attention/self/value/Add_output_0 range: [-2.661628, 2.151955]
Op output /encoder/layer.7/attention/self/Reshape_1_output_0 range: [-2.661628, 2.151955]
Op output /encoder/layer.7/attention/self/Transpose_output_0 range: [-2.661628, 2.151955]
Op output /encoder/layer.7/attention/self/MatMul_1_output_0 range: [-1.045869, 0.944404]
Op output /encoder/layer.7/attention/self/Transpose_3_output_0 range: [-1.045869, 0.944404]
Op output /encoder/layer.7/attention/self/Reshape_3_output_0 range: [-1.045869, 0.944404]
Op output /encoder/layer.7/attention/output/dense/MatMul_output_0 range: [-2.792183, 1.163410]
Op output /encoder/layer.7/attention/output/dense/Add_output_0 range: [-1.411435, 1.087981]
Op output /encoder/layer.7/attention/output/Add_output_0 range: [-15.229883, 2.584888]
Op output /encoder/layer.7/attention/output/LayerNorm/ReduceMean_output_0 range: [-0.027914, 0.000000]
Op output /encoder/layer.7/attention/output/LayerNorm/Sub_output_0 range: [-15.203845, 2.580469]
Op output /encoder/layer.7/attention/output/LayerNorm/Pow_output_0 range: [0.000000, 231.156906]
Op output /encoder/layer.7/attention/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 0.816240]
Op output /encoder/layer.7/attention/output/LayerNorm/Add_output_0 range: [0.000000, 0.816240]
Op output /encoder/layer.7/attention/output/LayerNorm/Sqrt_output_0 range: [0.000000, 0.903460]
Op output /encoder/layer.7/attention/output/LayerNorm/Div_output_0 range: [-19.699358, 2.928283]
Op output /encoder/layer.7/attention/output/LayerNorm/Mul_output_0 range: [-66.235390, 2.703485]
Op output /encoder/layer.7/attention/output/LayerNorm/Add_1_output_0 range: [-68.283325, 2.787075]
Op output /encoder/layer.7/intermediate/dense/MatMul_output_0 range: [-13.034563, 4.010635]
Op output /encoder/layer.7/intermediate/intermediate_act_fn/Mul_1_output_0 range: [-0.175655, 3.896351]
Op output /encoder/layer.7/output/dense/MatMul_output_0 range: [-1.228692, 3.666878]
Op output /encoder/layer.7/output/dense/Add_output_0 range: [-1.265824, 2.926191]
Op output /encoder/layer.7/output/Add_output_0 range: [-69.080399, 3.710931]
Op output /encoder/layer.7/output/LayerNorm/ReduceMean_output_0 range: [-0.092779, 0.000000]
Op output /encoder/layer.7/output/LayerNorm/Sub_output_0 range: [-68.987617, 3.705946]
Op output /encoder/layer.7/output/LayerNorm/Pow_output_0 range: [0.000000, 4759.291504]
Op output /encoder/layer.7/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 6.515646]
Op output /encoder/layer.7/output/LayerNorm/Add_output_0 range: [0.000000, 6.515646]
Op output /encoder/layer.7/output/LayerNorm/Sqrt_output_0 range: [0.000000, 2.552576]
Op output /encoder/layer.7/output/LayerNorm/Div_output_0 range: [-27.026663, 3.333685]
Op output /encoder/layer.7/output/LayerNorm/Mul_output_0 range: [-16.393364, 2.608035]
Op output /encoder/layer.7/output/LayerNorm/Add_1_output_0 range: [-15.434492, 2.537177]
Op output /encoder/layer.8/attention/self/query/MatMul_output_0 range: [-4.925142, 4.963923]
Op output /encoder/layer.8/attention/self/query/Add_output_0 range: [-5.619127, 5.488450]
Op output /encoder/layer.8/attention/self/Reshape_2_output_0 range: [-5.619127, 5.488450]
Op output /encoder/layer.8/attention/self/Transpose_1_output_0 range: [-5.619127, 5.488450]
Op output /encoder/layer.8/attention/self/key/MatMul_output_0 range: [-4.242727, 4.276134]
Op output /encoder/layer.8/attention/self/key/Add_output_0 range: [-4.195870, 4.295772]
Op output /encoder/layer.8/attention/self/Reshape_output_0 range: [-4.195870, 4.295772]
Op output /encoder/layer.8/attention/self/Transpose_2_output_0 range: [-4.195870, 4.295772]
Op output /encoder/layer.8/attention/self/MatMul_output_0 range: [-22.869791, 64.171951]
Op output /encoder/layer.8/attention/self/Div_output_0 range: [-2.858724, 8.021494]
Op output /encoder/layer.8/attention/self/Add_output_0 range: [-340282346638528859811704183484516925440.000000, 0.000000]
Op output /encoder/layer.8/attention/self/Softmax_output_0 range: [0.000000, 1.000000]
Op output /encoder/layer.8/attention/self/value/MatMul_output_0 range: [-2.646688, 2.752556]
Op output /encoder/layer.8/attention/self/value/Add_output_0 range: [-2.649737, 2.755727]
Op output /encoder/layer.8/attention/self/Reshape_1_output_0 range: [-2.649737, 2.755727]
Op output /encoder/layer.8/attention/self/Transpose_output_0 range: [-2.649737, 2.755727]
Op output /encoder/layer.8/attention/self/MatMul_1_output_0 range: [-1.668129, 1.306507]
Op output /encoder/layer.8/attention/self/Transpose_3_output_0 range: [-1.668129, 1.306507]
Op output /encoder/layer.8/attention/self/Reshape_3_output_0 range: [-1.668129, 1.306507]
Op output /encoder/layer.8/attention/output/dense/MatMul_output_0 range: [-3.040500, 1.441162]
Op output /encoder/layer.8/attention/output/dense/Add_output_0 range: [-1.829075, 1.387574]
Op output /encoder/layer.8/attention/output/Add_output_0 range: [-17.259064, 2.837106]
Op output /encoder/layer.8/attention/output/LayerNorm/ReduceMean_output_0 range: [-0.036065, 0.000000]
Op output /encoder/layer.8/attention/output/LayerNorm/Sub_output_0 range: [-17.223238, 2.923210]
Op output /encoder/layer.8/attention/output/LayerNorm/Pow_output_0 range: [0.000000, 296.639923]
Op output /encoder/layer.8/attention/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 0.908583]
Op output /encoder/layer.8/attention/output/LayerNorm/Add_output_0 range: [0.000000, 0.908583]
Op output /encoder/layer.8/attention/output/LayerNorm/Sqrt_output_0 range: [0.000000, 0.953196]
Op output /encoder/layer.8/attention/output/LayerNorm/Div_output_0 range: [-18.068930, 3.164145]
Op output /encoder/layer.8/attention/output/LayerNorm/Mul_output_0 range: [-55.821655, 2.278435]
Op output /encoder/layer.8/attention/output/LayerNorm/Add_1_output_0 range: [-57.567192, 2.595242]
Op output /encoder/layer.8/intermediate/dense/MatMul_output_0 range: [-17.358839, 3.422870]
Op output /encoder/layer.8/intermediate/intermediate_act_fn/Mul_1_output_0 range: [-0.179853, 3.348024]
Op output /encoder/layer.8/output/dense/MatMul_output_0 range: [-1.354735, 4.308500]
Op output /encoder/layer.8/output/dense/Add_output_0 range: [-1.327083, 3.577353]
Op output /encoder/layer.8/output/Add_output_0 range: [-54.870232, 2.709641]
Op output /encoder/layer.8/output/LayerNorm/ReduceMean_output_0 range: [-0.080121, 0.000000]
Op output /encoder/layer.8/output/LayerNorm/Sub_output_0 range: [-54.618057, 2.697188]
Op output /encoder/layer.8/output/LayerNorm/Pow_output_0 range: [0.000000, 2983.132080]
Op output /encoder/layer.8/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 4.376297]
Op output /encoder/layer.8/output/LayerNorm/Add_output_0 range: [0.000000, 4.376297]
Op output /encoder/layer.8/output/LayerNorm/Sqrt_output_0 range: [0.000000, 2.091960]
Op output /encoder/layer.8/output/LayerNorm/Div_output_0 range: [-26.108555, 2.837886]
Op output /encoder/layer.8/output/LayerNorm/Mul_output_0 range: [-16.512980, 2.369576]
Op output /encoder/layer.8/output/LayerNorm/Add_1_output_0 range: [-16.383835, 2.351044]
Op output /encoder/layer.9/attention/self/query/MatMul_output_0 range: [-5.516152, 4.903246]
Op output /encoder/layer.9/attention/self/query/Add_output_0 range: [-6.272272, 5.317796]
Op output /encoder/layer.9/attention/self/Reshape_2_output_0 range: [-6.272272, 5.317796]
Op output /encoder/layer.9/attention/self/Transpose_1_output_0 range: [-6.272272, 5.317796]
Op output /encoder/layer.9/attention/self/key/MatMul_output_0 range: [-3.930455, 3.720431]
Op output /encoder/layer.9/attention/self/key/Add_output_0 range: [-3.897485, 3.747582]
Op output /encoder/layer.9/attention/self/Reshape_output_0 range: [-3.897485, 3.747582]
Op output /encoder/layer.9/attention/self/Transpose_2_output_0 range: [-3.897485, 3.747582]
Op output /encoder/layer.9/attention/self/MatMul_output_0 range: [-34.506725, 53.485424]
Op output /encoder/layer.9/attention/self/Div_output_0 range: [-4.313341, 6.685678]
Op output /encoder/layer.9/attention/self/Add_output_0 range: [-340282346638528859811704183484516925440.000000, 0.000000]
Op output /encoder/layer.9/attention/self/Softmax_output_0 range: [0.000000, 1.000000]
Op output /encoder/layer.9/attention/self/value/MatMul_output_0 range: [-2.474238, 3.261496]
Op output /encoder/layer.9/attention/self/value/Add_output_0 range: [-2.486738, 3.384727]
Op output /encoder/layer.9/attention/self/Reshape_1_output_0 range: [-2.486738, 3.384727]
Op output /encoder/layer.9/attention/self/Transpose_output_0 range: [-2.486738, 3.384727]
Op output /encoder/layer.9/attention/self/MatMul_1_output_0 range: [-1.440435, 2.024762]
Op output /encoder/layer.9/attention/self/Transpose_3_output_0 range: [-1.440435, 2.024762]
Op output /encoder/layer.9/attention/self/Reshape_3_output_0 range: [-1.440435, 2.024762]
Op output /encoder/layer.9/attention/output/dense/MatMul_output_0 range: [-1.340971, 1.394610]
Op output /encoder/layer.9/attention/output/dense/Add_output_0 range: [-1.364001, 1.353345]
Op output /encoder/layer.9/attention/output/Add_output_0 range: [-15.958657, 3.057500]
Op output /encoder/layer.9/attention/output/LayerNorm/ReduceMean_output_0 range: [-0.034341, 0.000000]
Op output /encoder/layer.9/attention/output/LayerNorm/Sub_output_0 range: [-15.937003, 3.053351]
Op output /encoder/layer.9/attention/output/LayerNorm/Pow_output_0 range: [0.000000, 253.583847]
Op output /encoder/layer.9/attention/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 0.924778]
Op output /encoder/layer.9/attention/output/LayerNorm/Add_output_0 range: [0.000000, 0.924778]
Op output /encoder/layer.9/attention/output/LayerNorm/Sqrt_output_0 range: [0.000000, 0.961654]
Op output /encoder/layer.9/attention/output/LayerNorm/Div_output_0 range: [-16.575630, 3.268434]
Op output /encoder/layer.9/attention/output/LayerNorm/Mul_output_0 range: [-29.064861, 2.608385]
Op output /encoder/layer.9/attention/output/LayerNorm/Add_1_output_0 range: [-30.548380, 2.741521]
Op output /encoder/layer.9/intermediate/dense/MatMul_output_0 range: [-16.720535, 2.837889]
Op output /encoder/layer.9/intermediate/intermediate_act_fn/Mul_1_output_0 range: [-0.173880, 2.597326]
Op output /encoder/layer.9/output/dense/MatMul_output_0 range: [-15.842361, 10.220878]
Op output /encoder/layer.9/output/dense/Add_output_0 range: [-16.567158, 10.513773]
Op output /encoder/layer.9/output/Add_output_0 range: [-37.348770, 12.514771]
Op output /encoder/layer.9/output/LayerNorm/ReduceMean_output_0 range: [-0.087656, 0.000000]
Op output /encoder/layer.9/output/LayerNorm/Sub_output_0 range: [-37.261112, 12.485399]
Op output /encoder/layer.9/output/LayerNorm/Pow_output_0 range: [0.000000, 1388.390503]
Op output /encoder/layer.9/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 3.287399]
Op output /encoder/layer.9/output/LayerNorm/Add_output_0 range: [0.000000, 3.287399]
Op output /encoder/layer.9/output/LayerNorm/Sqrt_output_0 range: [0.000000, 1.813119]
Op output /encoder/layer.9/output/LayerNorm/Div_output_0 range: [-20.550842, 6.886146]
Op output /encoder/layer.9/output/LayerNorm/Mul_output_0 range: [-16.281189, 2.590189]
Op output /encoder/layer.9/output/LayerNorm/Add_1_output_0 range: [-16.696091, 2.481851]
Op output /encoder/layer.10/attention/self/query/MatMul_output_0 range: [-5.251027, 3.857897]
Op output /encoder/layer.10/attention/self/query/Add_output_0 range: [-5.523057, 4.057756]
Op output /encoder/layer.10/attention/self/Reshape_2_output_0 range: [-5.523057, 4.057756]
Op output /encoder/layer.10/attention/self/Transpose_1_output_0 range: [-5.523057, 4.057756]
Op output /encoder/layer.10/attention/self/key/MatMul_output_0 range: [-3.809628, 4.285831]
Op output /encoder/layer.10/attention/self/key/Add_output_0 range: [-3.823267, 4.301176]
Op output /encoder/layer.10/attention/self/Reshape_output_0 range: [-3.823267, 4.301176]
Op output /encoder/layer.10/attention/self/Transpose_2_output_0 range: [-3.823267, 4.301176]
Op output /encoder/layer.10/attention/self/MatMul_output_0 range: [-62.296597, 34.567013]
Op output /encoder/layer.10/attention/self/Div_output_0 range: [-7.787075, 4.320877]
Op output /encoder/layer.10/attention/self/Add_output_0 range: [-340282346638528859811704183484516925440.000000, 0.000000]
Op output /encoder/layer.10/attention/self/Softmax_output_0 range: [0.000000, 1.000000]
Op output /encoder/layer.10/attention/self/value/MatMul_output_0 range: [-2.616056, 2.148903]
Op output /encoder/layer.10/attention/self/value/Add_output_0 range: [-2.655301, 2.323388]
Op output /encoder/layer.10/attention/self/Reshape_1_output_0 range: [-2.655301, 2.323388]
Op output /encoder/layer.10/attention/self/Transpose_output_0 range: [-2.655301, 2.323388]
Op output /encoder/layer.10/attention/self/MatMul_1_output_0 range: [-1.590464, 1.789272]
Op output /encoder/layer.10/attention/self/Transpose_3_output_0 range: [-1.590464, 1.789272]
Op output /encoder/layer.10/attention/self/Reshape_3_output_0 range: [-1.590464, 1.789272]
Op output /encoder/layer.10/attention/output/dense/MatMul_output_0 range: [-1.416080, 1.427230]
Op output /encoder/layer.10/attention/output/dense/Add_output_0 range: [-1.385424, 1.396333]
Op output /encoder/layer.10/attention/output/Add_output_0 range: [-16.451429, 3.060731]
Op output /encoder/layer.10/attention/output/LayerNorm/ReduceMean_output_0 range: [-0.032557, 0.000000]
Op output /encoder/layer.10/attention/output/LayerNorm/Sub_output_0 range: [-16.398897, 3.050958]
Op output /encoder/layer.10/attention/output/LayerNorm/Pow_output_0 range: [0.000000, 268.923828]
Op output /encoder/layer.10/attention/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 1.076128]
Op output /encoder/layer.10/attention/output/LayerNorm/Add_output_0 range: [0.000000, 1.076128]
Op output /encoder/layer.10/attention/output/LayerNorm/Sqrt_output_0 range: [0.000000, 1.037366]
Op output /encoder/layer.10/attention/output/LayerNorm/Div_output_0 range: [-15.808212, 3.117112]
Op output /encoder/layer.10/attention/output/LayerNorm/Mul_output_0 range: [-27.427156, 3.795722]
Op output /encoder/layer.10/attention/output/LayerNorm/Add_1_output_0 range: [-29.316040, 4.510160]
Op output /encoder/layer.10/intermediate/dense/MatMul_output_0 range: [-9.386729, 28.607176]
Op output /encoder/layer.10/intermediate/intermediate_act_fn/Mul_1_output_0 range: [-0.225929, 28.580050]
Op output /encoder/layer.10/output/dense/MatMul_output_0 range: [-200.235153, 5.651799]
Op output /encoder/layer.10/output/dense/Add_output_0 range: [-201.402130, 5.684738]
Op output /encoder/layer.10/output/Add_output_0 range: [-205.850800, 10.165472]
Op output /encoder/layer.10/output/LayerNorm/ReduceMean_output_0 range: [-0.381340, 0.000000]
Op output /encoder/layer.10/output/LayerNorm/Sub_output_0 range: [-205.469467, 10.146641]
Op output /encoder/layer.10/output/LayerNorm/Pow_output_0 range: [0.000000, 42217.703125]
Op output /encoder/layer.10/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 61.622417]
Op output /encoder/layer.10/output/LayerNorm/Add_output_0 range: [0.000000, 61.622417]
Op output /encoder/layer.10/output/LayerNorm/Sqrt_output_0 range: [0.000000, 7.849995]
Op output /encoder/layer.10/output/LayerNorm/Div_output_0 range: [-26.174473, 2.971774]
Op output /encoder/layer.10/output/LayerNorm/Mul_output_0 range: [-15.962826, 2.372853]
Op output /encoder/layer.10/output/LayerNorm/Add_1_output_0 range: [-16.628946, 2.301327]
Op output /encoder/layer.11/attention/self/query/MatMul_output_0 range: [-3.634738, 3.440515]
Op output /encoder/layer.11/attention/self/query/Add_output_0 range: [-3.609627, 3.695570]
Op output /encoder/layer.11/attention/self/Reshape_2_output_0 range: [-3.609627, 3.695570]
Op output /encoder/layer.11/attention/self/Transpose_1_output_0 range: [-3.609627, 3.695570]
Op output /encoder/layer.11/attention/self/key/MatMul_output_0 range: [-3.602204, 3.518432]
Op output /encoder/layer.11/attention/self/key/Add_output_0 range: [-3.598513, 3.514827]
Op output /encoder/layer.11/attention/self/Reshape_output_0 range: [-3.598513, 3.514827]
Op output /encoder/layer.11/attention/self/Transpose_2_output_0 range: [-3.598513, 3.514827]
Op output /encoder/layer.11/attention/self/MatMul_output_0 range: [-30.808794, 30.092310]
Op output /encoder/layer.11/attention/self/Div_output_0 range: [-3.851099, 3.761539]
Op output /encoder/layer.11/attention/self/Add_output_0 range: [-340282346638528859811704183484516925440.000000, 0.000000]
Op output /encoder/layer.11/attention/self/Softmax_output_0 range: [0.000000, 1.000000]
Op output /encoder/layer.11/attention/self/value/MatMul_output_0 range: [-2.495355, 2.636222]
Op output /encoder/layer.11/attention/self/value/Add_output_0 range: [-2.466600, 2.605844]
Op output /encoder/layer.11/attention/self/Reshape_1_output_0 range: [-2.466600, 2.605844]
Op output /encoder/layer.11/attention/self/Transpose_output_0 range: [-2.466600, 2.605844]
Op output /encoder/layer.11/attention/self/MatMul_1_output_0 range: [-1.773597, 1.759741]
Op output /encoder/layer.11/attention/self/Transpose_3_output_0 range: [-1.773597, 1.759741]
Op output /encoder/layer.11/attention/self/Reshape_3_output_0 range: [-1.773597, 1.759741]
Op output /encoder/layer.11/attention/output/dense/MatMul_output_0 range: [-1.680908, 1.775798]
Op output /encoder/layer.11/attention/output/dense/Add_output_0 range: [-1.645294, 1.822061]
Op output /encoder/layer.11/attention/output/Add_output_0 range: [-18.157925, 3.081850]
Op output /encoder/layer.11/attention/output/LayerNorm/ReduceMean_output_0 range: [-0.036354, 0.000000]
Op output /encoder/layer.11/attention/output/LayerNorm/Sub_output_0 range: [-18.122561, 3.075848]
Op output /encoder/layer.11/attention/output/LayerNorm/Pow_output_0 range: [0.000000, 328.427185]
Op output /encoder/layer.11/attention/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 1.424995]
Op output /encoder/layer.11/attention/output/LayerNorm/Add_output_0 range: [0.000000, 1.424995]
Op output /encoder/layer.11/attention/output/LayerNorm/Sqrt_output_0 range: [0.000000, 1.193731]
Op output /encoder/layer.11/attention/output/LayerNorm/Div_output_0 range: [-15.181438, 2.993523]
Op output /encoder/layer.11/attention/output/LayerNorm/Mul_output_0 range: [-24.438690, 2.539085]
Op output /encoder/layer.11/attention/output/LayerNorm/Add_1_output_0 range: [-26.694799, 2.395687]
Op output /encoder/layer.11/intermediate/dense/MatMul_output_0 range: [-3.884284, 4.039655]
Op output /encoder/layer.11/intermediate/intermediate_act_fn/Mul_1_output_0 range: [-0.169971, 3.770266]
Op output /encoder/layer.11/output/dense/MatMul_output_0 range: [-7.612702, 3.673571]
Op output /encoder/layer.11/output/dense/Add_output_0 range: [-7.802905, 3.502440]
Op output /encoder/layer.11/output/Add_output_0 range: [-26.966583, 3.595544]
Op output /encoder/layer.11/output/LayerNorm/ReduceMean_output_0 range: [-0.068163, 0.000000]
Op output /encoder/layer.11/output/LayerNorm/Sub_output_0 range: [-26.898420, 3.586456]
Op output /encoder/layer.11/output/LayerNorm/Pow_output_0 range: [0.000000, 723.525024]
Op output /encoder/layer.11/output/LayerNorm/ReduceMean_1_output_0 range: [0.000000, 1.796406]
Op output /encoder/layer.11/output/LayerNorm/Add_output_0 range: [0.000000, 1.796406]
Op output /encoder/layer.11/output/LayerNorm/Sqrt_output_0 range: [0.000000, 1.340301]
Op output /encoder/layer.11/output/LayerNorm/Div_output_0 range: [-20.068947, 3.087530]
Op output /encoder/layer.11/output/LayerNorm/Mul_output_0 range: [-5.471169, 1.871716]
Op output mace_output_node_last_hidden_state range: [-5.260189, 1.912796]
Op output /pooler/Gather_output_0 range: [-5.245616, 1.154537]
Op output /pooler/dense/Gemm_output_0 range: [-2.946464, 3.112797]
Op output mace_output_node_pooler_output range: [-1.000000, 0.992188]
Convert mace graph to hexagon.
[input: "input_ids"
output: "mace_input_node_input_ids:0"
name: "mace_input_node_input_ids"
type: "Quantize"
arg {
  name: "T"
  i: 2
}
arg {
  name: "data_format"
  i: 0
}
arg {
  name: "find_range_every_time"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.0078125
  zero_point: 128
  minval: -1.0
  maxval: 0.9921875
}
, input: "attention_mask"
output: "mace_input_node_attention_mask:0"
name: "mace_input_node_attention_mask"
type: "Quantize"
arg {
  name: "T"
  i: 2
}
arg {
  name: "data_format"
  i: 0
}
arg {
  name: "find_range_every_time"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.0078125
  zero_point: 128
  minval: -1.0
  maxval: 0.9921875
}
, input: "mace_input_node_input_ids"
input: "mace_input_node_attention_mask"
output: "/embeddings/Add_output_0:0"
name: "/embeddings/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.006642164662480354
  zero_point: 152
  minval: -1.0096089839935303
  maxval: 0.6841429471969604
}
, input: "/embeddings/Add_output_0"
input: "/embeddings/position_embeddings/Gather_output_0"
output: "/embeddings/Add_1_output_0:0"
name: "/embeddings/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.013235785067081451
  zero_point: 148
  minval: -1.9588961601257324
  maxval: 1.416229009628296
}
, input: "/embeddings/Add_1_output_0"
output: "/embeddings/LayerNorm/ReduceMean_output_0:0"
name: "/embeddings/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0001393360726069659
  zero_point: 244
  minval: -0.033998001366853714
  maxval: 0.0015326967695727944
}
, input: "/embeddings/Add_1_output_0"
input: "/embeddings/LayerNorm/ReduceMean_output_0"
output: "/embeddings/LayerNorm/Sub_output_0:0"
name: "/embeddings/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.013241682201623917
  zero_point: 148
  minval: -1.9597690105438232
  maxval: 1.4168599843978882
}
, input: "/embeddings/LayerNorm/Sub_output_0"
output: "/embeddings/LayerNorm/Pow_output_0:0"
name: "/embeddings/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.015061548911035061
  zero_point: 0
  minval: 0.0
  maxval: 3.8406949043273926
}
, input: "/embeddings/LayerNorm/Pow_output_0"
output: "/embeddings/LayerNorm/ReduceMean_1_output_0:0"
name: "/embeddings/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 8.265490032499656e-05
  zero_point: 0
  minval: 0.0
  maxval: 0.021076999604701996
}
, input: "/embeddings/LayerNorm/ReduceMean_1_output_0"
output: "/embeddings/LayerNorm/Add_output_0:0"
name: "/embeddings/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 8.265490032499656e-05
  zero_point: 0
  minval: 0.0
  maxval: 0.021076999604701996
}
, input: "/embeddings/LayerNorm/Add_output_0"
output: "/embeddings/LayerNorm/Sqrt_output_0:0"
name: "/embeddings/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0005693294224329293
  zero_point: 0
  minval: 0.0
  maxval: 0.14517900347709656
}
, input: "/embeddings/LayerNorm/Sub_output_0"
input: "/embeddings/LayerNorm/Sqrt_output_0"
output: "/embeddings/LayerNorm/Div_output_0:0"
name: "/embeddings/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.0975840762257576
  zero_point: 155
  minval: -15.125532150268555
  maxval: 9.758407592773438
}
, input: "/embeddings/LayerNorm/Div_output_0"
input: "embeddings.LayerNorm.weight"
output: "/embeddings/LayerNorm/Mul_output_0:0"
name: "/embeddings/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.061710815876722336
  zero_point: 189
  minval: -11.663344383239746
  maxval: 4.072913646697998
}
, input: "/embeddings/LayerNorm/Mul_output_0"
input: "embeddings.LayerNorm.bias"
output: "/embeddings/LayerNorm/Add_1_output_0:0"
name: "/embeddings/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.05934906005859375
  zero_point: 183
  minval: -10.860877990722656
  maxval: 4.27313232421875
}
, input: "/embeddings/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1325"
output: "/encoder/layer.0/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03517516702413559
  zero_point: 127
  minval: -4.467246055603027
  maxval: 4.5024213790893555
}
, input: "encoder.layer.0.attention.self.query.bias"
input: "/encoder/layer.0/attention/self/query/MatMul_output_0"
output: "/encoder/layer.0/attention/self/query/Add_output_0:0"
name: "/encoder/layer.0/attention/self/query/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03553340956568718
  zero_point: 130
  minval: -4.619342803955078
  maxval: 4.441676139831543
}
, input: "/encoder/layer.0/attention/self/query/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.0/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.0/attention/self/Reshape_2"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.03553340956568718
  zero_point: 130
  minval: -4.619342803955078
  maxval: 4.441676139831543
}
, input: "/encoder/layer.0/attention/self/Reshape_2_output_0"
output: "/encoder/layer.0/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.0/attention/self/Transpose_1"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.03553340956568718
  zero_point: 130
  minval: -4.619342803955078
  maxval: 4.441676139831543
}
, input: "/embeddings/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1326"
output: "/encoder/layer.0/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03920615836977959
  zero_point: 132
  minval: -5.175212860107422
  maxval: 4.822357654571533
}
, input: "encoder.layer.0.attention.self.key.bias"
input: "/encoder/layer.0/attention/self/key/MatMul_output_0"
output: "/encoder/layer.0/attention/self/key/Add_output_0:0"
name: "/encoder/layer.0/attention/self/key/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.038939692080020905
  zero_point: 133
  minval: -5.17897891998291
  maxval: 4.7506422996521
}
, input: "/encoder/layer.0/attention/self/key/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.0/attention/self/Reshape_output_0:0"
name: "/encoder/layer.0/attention/self/Reshape"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.038939692080020905
  zero_point: 133
  minval: -5.17897891998291
  maxval: 4.7506422996521
}
, input: "/encoder/layer.0/attention/self/Reshape_output_0"
output: "/encoder/layer.0/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.0/attention/self/Transpose_2"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
quantize_info {
  scale: 0.038939692080020905
  zero_point: 133
  minval: -5.17897891998291
  maxval: 4.7506422996521
}
, input: "/encoder/layer.0/attention/self/Transpose_1_output_0"
input: "/encoder/layer.0/attention/self/Transpose_2_output_0"
output: "/encoder/layer.0/attention/self/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.4610340893268585
  zero_point: 73
  minval: -33.655487060546875
  maxval: 83.908203125
}
, input: "/encoder/layer.0/attention/self/MatMul_output_0"
output: "/encoder/layer.0/attention/self/Div_output_0:0"
name: "/encoder/layer.0/attention/self/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.05762925744056702
  zero_point: 73
  minval: -4.206935882568359
  maxval: 10.488525390625
}
, input: "token_type_ids"
output: "mace_input_node_token_type_ids:0"
name: "mace_input_node_token_type_ids"
type: "Quantize"
arg {
  name: "T"
  i: 2
}
arg {
  name: "data_format"
  i: 0
}
arg {
  name: "find_range_every_time"
  i: 1
}
output_shape {
  dims: 1
  dims: 1
  dims: 1
  dims: 6
}
quantize_info {
  scale: 0.0078125
  zero_point: 128
  minval: -1.0
  maxval: 0.9921875
}
, input: "mace_input_node_token_type_ids"
output: "/Sub_output_0:0"
name: "/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
arg {
  name: "scalar_input"
  f: 1.0
}
arg {
  name: "scalar_input_index"
  i: 0
}
output_shape {
  dims: 1
  dims: 1
  dims: 1
  dims: 6
}
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
, input: "/Sub_output_0"
output: "/Mul_output_0:0"
name: "/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: -3.4028234663852886e+38
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 1
  dims: 1
  dims: 6
}
quantize_info {
  scale: 1.334439148946129e+36
  zero_point: 255
  minval: -3.402820018375656e+38
  maxval: 0.0
}
, input: "/encoder/layer.0/attention/self/Div_output_0"
input: "/Mul_output_0"
output: "/encoder/layer.0/attention/self/Add_output_0:0"
name: "/encoder/layer.0/attention/self/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
, input: "/encoder/layer.0/attention/self/Add_output_0"
output: "/encoder/layer.0/attention/self/Softmax_output_0:0"
name: "/encoder/layer.0/attention/self/Softmax"
type: "Softmax"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
, input: "/embeddings/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1332"
output: "/encoder/layer.0/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.020430883392691612
  zero_point: 129
  minval: -2.6355841159820557
  maxval: 2.574291467666626
}
, input: "encoder.layer.0.attention.self.value.bias"
input: "/encoder/layer.0/attention/self/value/MatMul_output_0"
output: "/encoder/layer.0/attention/self/value/Add_output_0:0"
name: "/encoder/layer.0/attention/self/value/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.02018621936440468
  zero_point: 128
  minval: -2.583836078643799
  maxval: 2.563649892807007
}
, input: "/encoder/layer.0/attention/self/value/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.0/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.0/attention/self/Reshape_1"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.02018621936440468
  zero_point: 128
  minval: -2.583836078643799
  maxval: 2.563649892807007
}
, input: "/encoder/layer.0/attention/self/Reshape_1_output_0"
output: "/encoder/layer.0/attention/self/Transpose_output_0:0"
name: "/encoder/layer.0/attention/self/Transpose"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.02018621936440468
  zero_point: 128
  minval: -2.583836078643799
  maxval: 2.563649892807007
}
, input: "/encoder/layer.0/attention/self/Softmax_output_0"
input: "/encoder/layer.0/attention/self/Transpose_output_0"
output: "/encoder/layer.0/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.0/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.010315447114408016
  zero_point: 105
  minval: -1.0831218957901
  maxval: 1.5473170280456543
}
, input: "/encoder/layer.0/attention/self/MatMul_1_output_0"
output: "/encoder/layer.0/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.0/attention/self/Transpose_3"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.010315447114408016
  zero_point: 105
  minval: -1.0831218957901
  maxval: 1.5473170280456543
}
, input: "/encoder/layer.0/attention/self/Transpose_3_output_0"
input: "/encoder/layer.0/attention/self/Constant_4_output_0"
output: "/encoder/layer.0/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.0/attention/self/Reshape_3"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.010315447114408016
  zero_point: 105
  minval: -1.0831218957901
  maxval: 1.5473170280456543
}
, input: "/encoder/layer.0/attention/self/Reshape_3_output_0"
input: "onnx::MatMul_1347"
output: "/encoder/layer.0/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.0/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.009964870288968086
  zero_point: 132
  minval: -1.315362811088562
  maxval: 1.2256790399551392
}
, input: "encoder.layer.0.attention.output.dense.bias"
input: "/encoder/layer.0/attention/output/dense/MatMul_output_0"
output: "/encoder/layer.0/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.0/attention/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.010293197818100452
  zero_point: 139
  minval: -1.430754542350769
  maxval: 1.1940109729766846
}
, input: "/encoder/layer.0/attention/output/dense/Add_output_0"
input: "/embeddings/LayerNorm/Add_1_output_0"
output: "/encoder/layer.0/attention/output/Add_output_0:0"
name: "/encoder/layer.0/attention/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06361788511276245
  zero_point: 188
  minval: -11.960162162780762
  maxval: 4.2623982429504395
}
, input: "/encoder/layer.0/attention/output/Add_output_0"
output: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0001986449642572552
  zero_point: 169
  minval: -0.03357100114226341
  maxval: 0.017083467915654182
}
, input: "/encoder/layer.0/attention/output/Add_output_0"
input: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.0/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06373735517263412
  zero_point: 188
  minval: -11.982623100280762
  maxval: 4.270402908325195
}
, input: "/encoder/layer.0/attention/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.0/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.5578179359436035
  zero_point: 0
  minval: 0.0
  maxval: 142.2435760498047
}
, input: "/encoder/layer.0/attention/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0018497842829674482
  zero_point: 0
  minval: 0.0
  maxval: 0.4716950058937073
}
, input: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.0/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0018497842829674482
  zero_point: 0
  minval: 0.0
  maxval: 0.4716950058937073
}
, input: "/encoder/layer.0/attention/output/LayerNorm/Add_output_0"
output: "/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0026933334302157164
  zero_point: 0
  minval: 0.0
  maxval: 0.6868000030517578
}
, input: "/encoder/layer.0/attention/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.0/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.10432182252407074
  zero_point: 188
  minval: -19.612503051757812
  maxval: 6.989562034606934
}
, input: "/encoder/layer.0/attention/output/LayerNorm/Div_output_0"
input: "encoder.layer.0.attention.output.LayerNorm.weight"
output: "/encoder/layer.0/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.257788747549057
  zero_point: 227
  minval: -58.51804733276367
  maxval: 7.218085289001465
}
, input: "/encoder/layer.0/attention/output/LayerNorm/Mul_output_0"
input: "encoder.layer.0.attention.output.LayerNorm.bias"
output: "/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.27152684330940247
  zero_point: 231
  minval: -62.72270202636719
  maxval: 6.516644477844238
}
, input: "/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1348"
output: "/encoder/layer.0/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.0/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.10121992975473404
  zero_point: 167
  minval: -16.903728485107422
  maxval: 8.907354354858398
}
, input: "/encoder/layer.0/intermediate/dense/MatMul_output_0"
output: "/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1"
type: "Activation"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.03518608585000038
  zero_point: 5
  minval: -0.1759304255247116
  maxval: 8.796521186828613
}
, input: "/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0"
input: "onnx::MatMul_1349"
output: "/encoder/layer.0/output/dense/MatMul_output_0:0"
name: "/encoder/layer.0/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06505445390939713
  zero_point: 218
  minval: -14.18187141418457
  maxval: 2.407014846801758
}
, input: "encoder.layer.0.output.dense.bias"
input: "/encoder/layer.0/output/dense/MatMul_output_0"
output: "/encoder/layer.0/output/dense/Add_output_0:0"
name: "/encoder/layer.0/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.0642833262681961
  zero_point: 220
  minval: -14.142332077026367
  maxval: 2.2499165534973145
}
, input: "/encoder/layer.0/output/dense/Add_output_0"
input: "/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.0/output/Add_output_0:0"
name: "/encoder/layer.0/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.27091291546821594
  zero_point: 228
  minval: -61.76814651489258
  maxval: 7.3146491050720215
}
, input: "/encoder/layer.0/output/Add_output_0"
output: "/encoder/layer.0/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.00031935295555740595
  zero_point: 255
  minval: -0.08143500238656998
  maxval: 0.0
}
, input: "/encoder/layer.0/output/Add_output_0"
input: "/encoder/layer.0/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.0/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.2705557346343994
  zero_point: 228
  minval: -61.686710357666016
  maxval: 7.305005073547363
}
, input: "/encoder/layer.0/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.0/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 14.922550201416016
  zero_point: 0
  minval: 0.0
  maxval: 3805.250244140625
}
, input: "/encoder/layer.0/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.02292449399828911
  zero_point: 0
  minval: 0.0
  maxval: 5.845746040344238
}
, input: "/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.0/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.02292449399828911
  zero_point: 0
  minval: 0.0
  maxval: 5.845746040344238
}
, input: "/encoder/layer.0/output/LayerNorm/Add_output_0"
output: "/encoder/layer.0/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.009481560438871384
  zero_point: 0
  minval: 0.0
  maxval: 2.4177980422973633
}
, input: "/encoder/layer.0/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.0/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.0/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.11190173029899597
  zero_point: 228
  minval: -25.513593673706055
  maxval: 3.0213465690612793
}
, input: "/encoder/layer.0/output/LayerNorm/Div_output_0"
input: "encoder.layer.0.output.LayerNorm.weight"
output: "/encoder/layer.0/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04254244267940521
  zero_point: 206
  minval: -8.76374340057373
  maxval: 2.0845797061920166
}
, input: "/encoder/layer.0/output/LayerNorm/Mul_output_0"
input: "encoder.layer.0.output.LayerNorm.bias"
output: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04804582893848419
  zero_point: 210
  minval: -10.089624404907227
  maxval: 2.162062168121338
}
, input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1350"
output: "/encoder/layer.1/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.036228954792022705
  zero_point: 133
  minval: -4.818450927734375
  maxval: 4.4199323654174805
}
, input: "encoder.layer.1.attention.self.query.bias"
input: "/encoder/layer.1/attention/self/query/MatMul_output_0"
output: "/encoder/layer.1/attention/self/query/Add_output_0:0"
name: "/encoder/layer.1/attention/self/query/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03851192817091942
  zero_point: 126
  minval: -4.852502822875977
  maxval: 4.968038558959961
}
, input: "/encoder/layer.1/attention/self/query/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.1/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.1/attention/self/Reshape_2"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.03851192817091942
  zero_point: 126
  minval: -4.852502822875977
  maxval: 4.968038558959961
}
, input: "/encoder/layer.1/attention/self/Reshape_2_output_0"
output: "/encoder/layer.1/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.1/attention/self/Transpose_1"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.03851192817091942
  zero_point: 126
  minval: -4.852502822875977
  maxval: 4.968038558959961
}
, input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1351"
output: "/encoder/layer.1/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.041271936148405075
  zero_point: 129
  minval: -5.324079990386963
  maxval: 5.200263977050781
}
, input: "encoder.layer.1.attention.self.key.bias"
input: "/encoder/layer.1/attention/self/key/MatMul_output_0"
output: "/encoder/layer.1/attention/self/key/Add_output_0:0"
name: "/encoder/layer.1/attention/self/key/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.0412733294069767
  zero_point: 128
  minval: -5.282986164093018
  maxval: 5.24171257019043
}
, input: "/encoder/layer.1/attention/self/key/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.1/attention/self/Reshape_output_0:0"
name: "/encoder/layer.1/attention/self/Reshape"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.0412733294069767
  zero_point: 128
  minval: -5.282986164093018
  maxval: 5.24171257019043
}
, input: "/encoder/layer.1/attention/self/Reshape_output_0"
output: "/encoder/layer.1/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.1/attention/self/Transpose_2"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
quantize_info {
  scale: 0.0412733294069767
  zero_point: 128
  minval: -5.282986164093018
  maxval: 5.24171257019043
}
, input: "/encoder/layer.1/attention/self/Transpose_1_output_0"
input: "/encoder/layer.1/attention/self/Transpose_2_output_0"
output: "/encoder/layer.1/attention/self/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.5172810554504395
  zero_point: 75
  minval: -38.796077728271484
  maxval: 93.11058807373047
}
, input: "/encoder/layer.1/attention/self/MatMul_output_0"
output: "/encoder/layer.1/attention/self/Div_output_0:0"
name: "/encoder/layer.1/attention/self/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.06466013193130493
  zero_point: 75
  minval: -4.849510192871094
  maxval: 11.638824462890625
}
, input: "/encoder/layer.1/attention/self/Div_output_0"
input: "/Mul_output_0"
output: "/encoder/layer.1/attention/self/Add_output_0:0"
name: "/encoder/layer.1/attention/self/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
, input: "/encoder/layer.1/attention/self/Add_output_0"
output: "/encoder/layer.1/attention/self/Softmax_output_0:0"
name: "/encoder/layer.1/attention/self/Softmax"
type: "Softmax"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
, input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1357"
output: "/encoder/layer.1/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.01952419988811016
  zero_point: 115
  minval: -2.2452828884124756
  maxval: 2.7333879470825195
}
, input: "encoder.layer.1.attention.self.value.bias"
input: "/encoder/layer.1/attention/self/value/MatMul_output_0"
output: "/encoder/layer.1/attention/self/value/Add_output_0:0"
name: "/encoder/layer.1/attention/self/value/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.019675493240356445
  zero_point: 113
  minval: -2.2233307361602783
  maxval: 2.7939200401306152
}
, input: "/encoder/layer.1/attention/self/value/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.1/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.1/attention/self/Reshape_1"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.019675493240356445
  zero_point: 113
  minval: -2.2233307361602783
  maxval: 2.7939200401306152
}
, input: "/encoder/layer.1/attention/self/Reshape_1_output_0"
output: "/encoder/layer.1/attention/self/Transpose_output_0:0"
name: "/encoder/layer.1/attention/self/Transpose"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.019675493240356445
  zero_point: 113
  minval: -2.2233307361602783
  maxval: 2.7939200401306152
}
, input: "/encoder/layer.1/attention/self/Softmax_output_0"
input: "/encoder/layer.1/attention/self/Transpose_output_0"
output: "/encoder/layer.1/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.1/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.011402285657823086
  zero_point: 122
  minval: -1.3910788297653198
  maxval: 1.5165040493011475
}
, input: "/encoder/layer.1/attention/self/MatMul_1_output_0"
output: "/encoder/layer.1/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.1/attention/self/Transpose_3"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.011402285657823086
  zero_point: 122
  minval: -1.3910788297653198
  maxval: 1.5165040493011475
}
, input: "/encoder/layer.1/attention/self/Transpose_3_output_0"
input: "/encoder/layer.0/attention/self/Constant_4_output_0"
output: "/encoder/layer.1/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.1/attention/self/Reshape_3"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.011402285657823086
  zero_point: 122
  minval: -1.3910788297653198
  maxval: 1.5165040493011475
}
, input: "/encoder/layer.1/attention/self/Reshape_3_output_0"
input: "onnx::MatMul_1372"
output: "/encoder/layer.1/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.1/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.008185404352843761
  zero_point: 104
  minval: -0.851282000541687
  maxval: 1.2359960079193115
}
, input: "encoder.layer.1.attention.output.dense.bias"
input: "/encoder/layer.1/attention/output/dense/MatMul_output_0"
output: "/encoder/layer.1/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.1/attention/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.0076732337474823
  zero_point: 101
  minval: -0.7749966382980347
  maxval: 1.181678056716919
}
, input: "/encoder/layer.1/attention/output/dense/Add_output_0"
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.1/attention/output/Add_output_0:0"
name: "/encoder/layer.1/attention/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.050185151398181915
  zero_point: 210
  minval: -10.5388822555542
  maxval: 2.258331775665283
}
, input: "/encoder/layer.1/attention/output/Add_output_0"
output: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 8.013725164346397e-05
  zero_point: 255
  minval: -0.020434999838471413
  maxval: 0.0
}
, input: "/encoder/layer.1/attention/output/Add_output_0"
input: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.1/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.05023377761244774
  zero_point: 210
  minval: -10.549093246459961
  maxval: 2.2605199813842773
}
, input: "/encoder/layer.1/attention/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.1/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.4344174265861511
  zero_point: 0
  minval: 0.0
  maxval: 110.77644348144531
}
, input: "/encoder/layer.1/attention/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.002213074592873454
  zero_point: 0
  minval: 0.0
  maxval: 0.564333975315094
}
, input: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.1/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.002213074592873454
  zero_point: 0
  minval: 0.0
  maxval: 0.564333975315094
}
, input: "/encoder/layer.1/attention/output/LayerNorm/Add_output_0"
output: "/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.002945968648418784
  zero_point: 0
  minval: 0.0
  maxval: 0.7512220144271851
}
, input: "/encoder/layer.1/attention/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.1/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.09657789766788483
  zero_point: 215
  minval: -20.76424789428711
  maxval: 3.8631160259246826
}
, input: "/encoder/layer.1/attention/output/LayerNorm/Div_output_0"
input: "encoder.layer.1.attention.output.LayerNorm.weight"
output: "/encoder/layer.1/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.2592984139919281
  zero_point: 243
  minval: -63.009517669677734
  maxval: 3.1115810871124268
}
, input: "/encoder/layer.1/attention/output/LayerNorm/Mul_output_0"
input: "encoder.layer.1.attention.output.LayerNorm.bias"
output: "/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.2705458998680115
  zero_point: 242
  minval: -65.47210693359375
  maxval: 3.517096757888794
}
, input: "/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1373"
output: "/encoder/layer.1/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.1/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.08946271240711212
  zero_point: 164
  minval: -14.671884536743164
  maxval: 8.141106605529785
}
, input: "/encoder/layer.1/intermediate/dense/MatMul_output_0"
output: "/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1"
type: "Activation"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.03194340318441391
  zero_point: 6
  minval: -0.19166040420532227
  maxval: 7.953907012939453
}
, input: "/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0"
input: "onnx::MatMul_1374"
output: "/encoder/layer.1/output/dense/MatMul_output_0:0"
name: "/encoder/layer.1/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.069577157497406
  zero_point: 217
  minval: -15.09824275970459
  maxval: 2.6439318656921387
}
, input: "encoder.layer.1.output.dense.bias"
input: "/encoder/layer.1/output/dense/MatMul_output_0"
output: "/encoder/layer.1/output/dense/Add_output_0:0"
name: "/encoder/layer.1/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06840097159147263
  zero_point: 221
  minval: -15.11661434173584
  maxval: 2.3256328105926514
}
, input: "/encoder/layer.1/output/dense/Add_output_0"
input: "/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.1/output/Add_output_0:0"
name: "/encoder/layer.1/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.28321373462677
  zero_point: 243
  minval: -68.82093811035156
  maxval: 3.3985648155212402
}
, input: "/encoder/layer.1/output/Add_output_0"
output: "/encoder/layer.1/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0003665372496470809
  zero_point: 255
  minval: -0.09346699714660645
  maxval: 0.0
}
, input: "/encoder/layer.1/output/Add_output_0"
input: "/encoder/layer.1/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.1/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.2839978039264679
  zero_point: 242
  minval: -68.72747039794922
  maxval: 3.69197154045105
}
, input: "/encoder/layer.1/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.1/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 18.523393630981445
  zero_point: 0
  minval: 0.0
  maxval: 4723.46533203125
}
, input: "/encoder/layer.1/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.02659711427986622
  zero_point: 0
  minval: 0.0
  maxval: 6.782264232635498
}
, input: "/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.1/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.02659711427986622
  zero_point: 0
  minval: 0.0
  maxval: 6.782264232635498
}
, input: "/encoder/layer.1/output/LayerNorm/Add_output_0"
output: "/encoder/layer.1/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.010212854482233524
  zero_point: 0
  minval: 0.0
  maxval: 2.604278087615967
}
, input: "/encoder/layer.1/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.1/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.1/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.11424338817596436
  zero_point: 231
  minval: -26.390222549438477
  maxval: 2.7418413162231445
}
, input: "/encoder/layer.1/output/LayerNorm/Div_output_0"
input: "encoder.layer.1.output.LayerNorm.weight"
output: "/encoder/layer.1/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.049781642854213715
  zero_point: 212
  minval: -10.55370807647705
  maxval: 2.140610694885254
}
, input: "/encoder/layer.1/output/LayerNorm/Mul_output_0"
input: "encoder.layer.1.output.LayerNorm.bias"
output: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.05199756845831871
  zero_point: 216
  minval: -11.231474876403809
  maxval: 2.027905225753784
}
, input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1375"
output: "/encoder/layer.2/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04154577851295471
  zero_point: 138
  minval: -5.7333173751831055
  maxval: 4.860856056213379
}
, input: "encoder.layer.2.attention.self.query.bias"
input: "/encoder/layer.2/attention/self/query/MatMul_output_0"
output: "/encoder/layer.2/attention/self/query/Add_output_0:0"
name: "/encoder/layer.2/attention/self/query/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04506297782063484
  zero_point: 145
  minval: -6.53413200378418
  maxval: 4.95692777633667
}
, input: "/encoder/layer.2/attention/self/query/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.2/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.2/attention/self/Reshape_2"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.04506297782063484
  zero_point: 145
  minval: -6.53413200378418
  maxval: 4.95692777633667
}
, input: "/encoder/layer.2/attention/self/Reshape_2_output_0"
output: "/encoder/layer.2/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.2/attention/self/Transpose_1"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.04506297782063484
  zero_point: 145
  minval: -6.53413200378418
  maxval: 4.95692777633667
}
, input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1376"
output: "/encoder/layer.2/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04573328047990799
  zero_point: 138
  minval: -6.311192989349365
  maxval: 5.350793838500977
}
, input: "encoder.layer.2.attention.self.key.bias"
input: "/encoder/layer.2/attention/self/key/MatMul_output_0"
output: "/encoder/layer.2/attention/self/key/Add_output_0:0"
name: "/encoder/layer.2/attention/self/key/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.045686282217502594
  zero_point: 138
  minval: -6.304707050323486
  maxval: 5.345294952392578
}
, input: "/encoder/layer.2/attention/self/key/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.2/attention/self/Reshape_output_0:0"
name: "/encoder/layer.2/attention/self/Reshape"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.045686282217502594
  zero_point: 138
  minval: -6.304707050323486
  maxval: 5.345294952392578
}
, input: "/encoder/layer.2/attention/self/Reshape_output_0"
output: "/encoder/layer.2/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.2/attention/self/Transpose_2"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
quantize_info {
  scale: 0.045686282217502594
  zero_point: 138
  minval: -6.304707050323486
  maxval: 5.345294952392578
}
, input: "/encoder/layer.2/attention/self/Transpose_1_output_0"
input: "/encoder/layer.2/attention/self/Transpose_2_output_0"
output: "/encoder/layer.2/attention/self/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.5811166763305664
  zero_point: 59
  minval: -34.285884857177734
  maxval: 113.89887237548828
}
, input: "/encoder/layer.2/attention/self/MatMul_output_0"
output: "/encoder/layer.2/attention/self/Div_output_0:0"
name: "/encoder/layer.2/attention/self/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.0726395919919014
  zero_point: 59
  minval: -4.285736083984375
  maxval: 14.237360000610352
}
, input: "/encoder/layer.2/attention/self/Div_output_0"
input: "/Mul_output_0"
output: "/encoder/layer.2/attention/self/Add_output_0:0"
name: "/encoder/layer.2/attention/self/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
, input: "/encoder/layer.2/attention/self/Add_output_0"
output: "/encoder/layer.2/attention/self/Softmax_output_0:0"
name: "/encoder/layer.2/attention/self/Softmax"
type: "Softmax"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
, input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1382"
output: "/encoder/layer.2/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.018187351524829865
  zero_point: 124
  minval: -2.2552316188812256
  maxval: 2.3825430870056152
}
, input: "encoder.layer.2.attention.self.value.bias"
input: "/encoder/layer.2/attention/self/value/MatMul_output_0"
output: "/encoder/layer.2/attention/self/value/Add_output_0:0"
name: "/encoder/layer.2/attention/self/value/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.018353644758462906
  zero_point: 124
  minval: -2.2758519649505615
  maxval: 2.404327630996704
}
, input: "/encoder/layer.2/attention/self/value/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.2/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.2/attention/self/Reshape_1"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.018353644758462906
  zero_point: 124
  minval: -2.2758519649505615
  maxval: 2.404327630996704
}
, input: "/encoder/layer.2/attention/self/Reshape_1_output_0"
output: "/encoder/layer.2/attention/self/Transpose_output_0:0"
name: "/encoder/layer.2/attention/self/Transpose"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.018353644758462906
  zero_point: 124
  minval: -2.2758519649505615
  maxval: 2.404327630996704
}
, input: "/encoder/layer.2/attention/self/Softmax_output_0"
input: "/encoder/layer.2/attention/self/Transpose_output_0"
output: "/encoder/layer.2/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.2/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.00788026675581932
  zero_point: 105
  minval: -0.8274279832839966
  maxval: 1.1820399761199951
}
, input: "/encoder/layer.2/attention/self/MatMul_1_output_0"
output: "/encoder/layer.2/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.2/attention/self/Transpose_3"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.00788026675581932
  zero_point: 105
  minval: -0.8274279832839966
  maxval: 1.1820399761199951
}
, input: "/encoder/layer.2/attention/self/Transpose_3_output_0"
input: "/encoder/layer.0/attention/self/Constant_4_output_0"
output: "/encoder/layer.2/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.2/attention/self/Reshape_3"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.00788026675581932
  zero_point: 105
  minval: -0.8274279832839966
  maxval: 1.1820399761199951
}
, input: "/encoder/layer.2/attention/self/Reshape_3_output_0"
input: "onnx::MatMul_1397"
output: "/encoder/layer.2/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.2/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.006788904778659344
  zero_point: 129
  minval: -0.8757687211036682
  maxval: 0.8554019927978516
}
, input: "encoder.layer.2.attention.output.dense.bias"
input: "/encoder/layer.2/attention/output/dense/MatMul_output_0"
output: "/encoder/layer.2/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.2/attention/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.0055724442936480045
  zero_point: 126
  minval: -0.702127993106842
  maxval: 0.7188453078269958
}
, input: "/encoder/layer.2/attention/output/dense/Add_output_0"
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.2/attention/output/Add_output_0:0"
name: "/encoder/layer.2/attention/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.054488345980644226
  zero_point: 214
  minval: -11.660506248474121
  maxval: 2.2340221405029297
}
, input: "/encoder/layer.2/attention/output/Add_output_0"
output: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 6.870196375530213e-05
  zero_point: 255
  minval: -0.01751900091767311
  maxval: 0.0
}
, input: "/encoder/layer.2/attention/output/Add_output_0"
input: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.2/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.054434746503829956
  zero_point: 214
  minval: -11.649036407470703
  maxval: 2.2318246364593506
}
, input: "/encoder/layer.2/attention/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.2/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.5321570038795471
  zero_point: 0
  minval: 0.0
  maxval: 135.70004272460938
}
, input: "/encoder/layer.2/attention/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0025045648217201233
  zero_point: 0
  minval: 0.0
  maxval: 0.6386640071868896
}
, input: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.2/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0025045648217201233
  zero_point: 0
  minval: 0.0
  maxval: 0.6386640071868896
}
, input: "/encoder/layer.2/attention/output/LayerNorm/Add_output_0"
output: "/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0031339803244918585
  zero_point: 0
  minval: 0.0
  maxval: 0.7991650104522705
}
, input: "/encoder/layer.2/attention/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.2/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.09967236965894699
  zero_point: 227
  minval: -22.625627517700195
  maxval: 2.7908263206481934
}
, input: "/encoder/layer.2/attention/output/LayerNorm/Div_output_0"
input: "encoder.layer.2.attention.output.LayerNorm.weight"
output: "/encoder/layer.2/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.21263140439987183
  zero_point: 243
  minval: -51.669429779052734
  maxval: 2.551576852798462
}
, input: "/encoder/layer.2/attention/output/LayerNorm/Mul_output_0"
input: "encoder.layer.2.attention.output.LayerNorm.bias"
output: "/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.22093814611434937
  zero_point: 243
  minval: -53.68796920776367
  maxval: 2.6512577533721924
}
, input: "/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1398"
output: "/encoder/layer.2/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.2/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.2867799997329712
  zero_point: 69
  minval: -19.78782081604004
  maxval: 53.34107971191406
}
, input: "/encoder/layer.2/intermediate/dense/MatMul_output_0"
output: "/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1"
type: "Activation"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.2089047133922577
  zero_point: 1
  minval: -0.2089047133922577
  maxval: 53.061798095703125
}
, input: "/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0"
input: "onnx::MatMul_1399"
output: "/encoder/layer.2/output/dense/MatMul_output_0:0"
name: "/encoder/layer.2/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.8529177308082581
  zero_point: 251
  minval: -214.0823516845703
  maxval: 3.4116709232330322
}
, input: "encoder.layer.2.output.dense.bias"
input: "/encoder/layer.2/output/dense/MatMul_output_0"
output: "/encoder/layer.2/output/dense/Add_output_0:0"
name: "/encoder/layer.2/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.8531507253646851
  zero_point: 251
  minval: -214.14083862304688
  maxval: 3.4126029014587402
}
, input: "/encoder/layer.2/output/dense/Add_output_0"
input: "/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.2/output/Add_output_0:0"
name: "/encoder/layer.2/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.8699726462364197
  zero_point: 251
  minval: -218.36312866210938
  maxval: 3.4798905849456787
}
, input: "/encoder/layer.2/output/Add_output_0"
output: "/encoder/layer.2/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0012147293891757727
  zero_point: 255
  minval: -0.30975601077079773
  maxval: 0.0
}
, input: "/encoder/layer.2/output/Add_output_0"
input: "/encoder/layer.2/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.2/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.8687385320663452
  zero_point: 251
  minval: -218.05337524414062
  maxval: 3.474954128265381
}
, input: "/encoder/layer.2/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.2/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 186.45989990234375
  zero_point: 0
  minval: 0.0
  maxval: 47547.2734375
}
, input: "/encoder/layer.2/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.25768864154815674
  zero_point: 0
  minval: 0.0
  maxval: 65.71060180664062
}
, input: "/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.2/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.25768864154815674
  zero_point: 0
  minval: 0.0
  maxval: 65.71060180664062
}
, input: "/encoder/layer.2/output/LayerNorm/Add_output_0"
output: "/encoder/layer.2/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.03178904950618744
  zero_point: 0
  minval: 0.0
  maxval: 8.106207847595215
}
, input: "/encoder/layer.2/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.2/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.2/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.1149553582072258
  zero_point: 234
  minval: -26.899553298950195
  maxval: 2.4140625
}
, input: "/encoder/layer.2/output/LayerNorm/Div_output_0"
input: "encoder.layer.2.output.LayerNorm.weight"
output: "/encoder/layer.2/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06626202166080475
  zero_point: 223
  minval: -14.776430130004883
  maxval: 2.120384693145752
}
, input: "/encoder/layer.2/output/LayerNorm/Mul_output_0"
input: "encoder.layer.2.output.LayerNorm.bias"
output: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06543660163879395
  zero_point: 224
  minval: -14.657797813415527
  maxval: 2.0285346508026123
}
, input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1400"
output: "/encoder/layer.3/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03683091327548027
  zero_point: 141
  minval: -5.1931586265563965
  maxval: 4.198723793029785
}
, input: "encoder.layer.3.attention.self.query.bias"
input: "/encoder/layer.3/attention/self/query/MatMul_output_0"
output: "/encoder/layer.3/attention/self/query/Add_output_0:0"
name: "/encoder/layer.3/attention/self/query/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.038776081055402756
  zero_point: 137
  minval: -5.312323093414307
  maxval: 4.575577259063721
}
, input: "/encoder/layer.3/attention/self/query/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.3/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.3/attention/self/Reshape_2"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.038776081055402756
  zero_point: 137
  minval: -5.312323093414307
  maxval: 4.575577259063721
}
, input: "/encoder/layer.3/attention/self/Reshape_2_output_0"
output: "/encoder/layer.3/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.3/attention/self/Transpose_1"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.038776081055402756
  zero_point: 137
  minval: -5.312323093414307
  maxval: 4.575577259063721
}
, input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1401"
output: "/encoder/layer.3/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04226052016019821
  zero_point: 120
  minval: -5.071262359619141
  maxval: 5.705170154571533
}
, input: "encoder.layer.3.attention.self.key.bias"
input: "/encoder/layer.3/attention/self/key/MatMul_output_0"
output: "/encoder/layer.3/attention/self/key/Add_output_0:0"
name: "/encoder/layer.3/attention/self/key/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04216812551021576
  zero_point: 120
  minval: -5.060174942016602
  maxval: 5.692697048187256
}
, input: "/encoder/layer.3/attention/self/key/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.3/attention/self/Reshape_output_0:0"
name: "/encoder/layer.3/attention/self/Reshape"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.04216812551021576
  zero_point: 120
  minval: -5.060174942016602
  maxval: 5.692697048187256
}
, input: "/encoder/layer.3/attention/self/Reshape_output_0"
output: "/encoder/layer.3/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.3/attention/self/Transpose_2"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
quantize_info {
  scale: 0.04216812551021576
  zero_point: 120
  minval: -5.060174942016602
  maxval: 5.692697048187256
}
, input: "/encoder/layer.3/attention/self/Transpose_1_output_0"
input: "/encoder/layer.3/attention/self/Transpose_2_output_0"
output: "/encoder/layer.3/attention/self/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.4197385907173157
  zero_point: 30
  minval: -12.592158317565918
  maxval: 94.4411849975586
}
, input: "/encoder/layer.3/attention/self/MatMul_output_0"
output: "/encoder/layer.3/attention/self/Div_output_0:0"
name: "/encoder/layer.3/attention/self/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.05246732383966446
  zero_point: 30
  minval: -1.5740197896957397
  maxval: 11.805148124694824
}
, input: "/encoder/layer.3/attention/self/Div_output_0"
input: "/Mul_output_0"
output: "/encoder/layer.3/attention/self/Add_output_0:0"
name: "/encoder/layer.3/attention/self/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
, input: "/encoder/layer.3/attention/self/Add_output_0"
output: "/encoder/layer.3/attention/self/Softmax_output_0:0"
name: "/encoder/layer.3/attention/self/Softmax"
type: "Softmax"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
, input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1407"
output: "/encoder/layer.3/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.017904654145240784
  zero_point: 124
  minval: -2.220176935195923
  maxval: 2.3455095291137695
}
, input: "encoder.layer.3.attention.self.value.bias"
input: "/encoder/layer.3/attention/self/value/MatMul_output_0"
output: "/encoder/layer.3/attention/self/value/Add_output_0:0"
name: "/encoder/layer.3/attention/self/value/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.01786927506327629
  zero_point: 124
  minval: -2.215790033340454
  maxval: 2.3408749103546143
}
, input: "/encoder/layer.3/attention/self/value/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.3/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.3/attention/self/Reshape_1"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.01786927506327629
  zero_point: 124
  minval: -2.215790033340454
  maxval: 2.3408749103546143
}
, input: "/encoder/layer.3/attention/self/Reshape_1_output_0"
output: "/encoder/layer.3/attention/self/Transpose_output_0:0"
name: "/encoder/layer.3/attention/self/Transpose"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.01786927506327629
  zero_point: 124
  minval: -2.215790033340454
  maxval: 2.3408749103546143
}
, input: "/encoder/layer.3/attention/self/Softmax_output_0"
input: "/encoder/layer.3/attention/self/Transpose_output_0"
output: "/encoder/layer.3/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.3/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.0067507983185350895
  zero_point: 129
  minval: -0.8708530068397522
  maxval: 0.8506006002426147
}
, input: "/encoder/layer.3/attention/self/MatMul_1_output_0"
output: "/encoder/layer.3/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.3/attention/self/Transpose_3"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.0067507983185350895
  zero_point: 129
  minval: -0.8708530068397522
  maxval: 0.8506006002426147
}
, input: "/encoder/layer.3/attention/self/Transpose_3_output_0"
input: "/encoder/layer.0/attention/self/Constant_4_output_0"
output: "/encoder/layer.3/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.3/attention/self/Reshape_3"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.0067507983185350895
  zero_point: 129
  minval: -0.8708530068397522
  maxval: 0.8506006002426147
}
, input: "/encoder/layer.3/attention/self/Reshape_3_output_0"
input: "onnx::MatMul_1422"
output: "/encoder/layer.3/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.3/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.005419538356363773
  zero_point: 151
  minval: -0.8183503150939941
  maxval: 0.5636320114135742
}
, input: "encoder.layer.3.attention.output.dense.bias"
input: "/encoder/layer.3/attention/output/dense/MatMul_output_0"
output: "/encoder/layer.3/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.3/attention/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.005509603768587112
  zero_point: 154
  minval: -0.8484790325164795
  maxval: 0.5564699769020081
}
, input: "/encoder/layer.3/attention/output/dense/Add_output_0"
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.3/attention/output/Add_output_0:0"
name: "/encoder/layer.3/attention/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06544771790504456
  zero_point: 225
  minval: -14.725735664367676
  maxval: 1.963431477546692
}
, input: "/encoder/layer.3/attention/output/Add_output_0"
output: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 7.37803929951042e-05
  zero_point: 255
  minval: -0.018813999369740486
  maxval: 0.0
}
, input: "/encoder/layer.3/attention/output/Add_output_0"
input: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.3/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06567302346229553
  zero_point: 224
  minval: -14.7107572555542
  maxval: 2.0358636379241943
}
, input: "/encoder/layer.3/attention/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.3/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.8486524224281311
  zero_point: 0
  minval: 0.0
  maxval: 216.4063720703125
}
, input: "/encoder/layer.3/attention/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0022478157188743353
  zero_point: 0
  minval: 0.0
  maxval: 0.5731930136680603
}
, input: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.3/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0022478157188743353
  zero_point: 0
  minval: 0.0
  maxval: 0.5731930136680603
}
, input: "/encoder/layer.3/attention/output/LayerNorm/Add_output_0"
output: "/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0029690000228583813
  zero_point: 0
  minval: 0.0
  maxval: 0.7570949792861938
}
, input: "/encoder/layer.3/attention/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.3/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.11074970662593842
  zero_point: 231
  minval: -25.58318328857422
  maxval: 2.6579930782318115
}
, input: "/encoder/layer.3/attention/output/LayerNorm/Div_output_0"
input: "encoder.layer.3.attention.output.LayerNorm.weight"
output: "/encoder/layer.3/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.3597131669521332
  zero_point: 248
  minval: -89.2088623046875
  maxval: 2.5179920196533203
}
, input: "/encoder/layer.3/attention/output/LayerNorm/Mul_output_0"
input: "encoder.layer.3.attention.output.LayerNorm.bias"
output: "/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.3632200360298157
  zero_point: 248
  minval: -90.07856750488281
  maxval: 2.5425403118133545
}
, input: "/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1423"
output: "/encoder/layer.3/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.3/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.2499488741159439
  zero_point: 232
  minval: -57.988136291503906
  maxval: 5.748824119567871
}
, input: "/encoder/layer.3/intermediate/dense/MatMul_output_0"
output: "/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1"
type: "Activation"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.02169569954276085
  zero_point: 8
  minval: -0.1735655963420868
  maxval: 5.358838081359863
}
, input: "/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0"
input: "onnx::MatMul_1424"
output: "/encoder/layer.3/output/dense/MatMul_output_0:0"
name: "/encoder/layer.3/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.2377270609140396
  zero_point: 240
  minval: -57.05449295043945
  maxval: 3.565905809402466
}
, input: "encoder.layer.3.output.dense.bias"
input: "/encoder/layer.3/output/dense/MatMul_output_0"
output: "/encoder/layer.3/output/dense/Add_output_0:0"
name: "/encoder/layer.3/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.23652197420597076
  zero_point: 242
  minval: -57.238319396972656
  maxval: 3.0747857093811035
}
, input: "/encoder/layer.3/output/dense/Add_output_0"
input: "/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.3/output/Add_output_0:0"
name: "/encoder/layer.3/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.5892675518989563
  zero_point: 250
  minval: -147.31689453125
  maxval: 2.946337938308716
}
, input: "/encoder/layer.3/output/Add_output_0"
output: "/encoder/layer.3/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0006990980473347008
  zero_point: 255
  minval: -0.17826999723911285
  maxval: 0.0
}
, input: "/encoder/layer.3/output/Add_output_0"
input: "/encoder/layer.3/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.3/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.5885545015335083
  zero_point: 250
  minval: -147.1386260986328
  maxval: 2.942772626876831
}
, input: "/encoder/layer.3/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.3/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 84.90107727050781
  zero_point: 0
  minval: 0.0
  maxval: 21649.775390625
}
, input: "/encoder/layer.3/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.11154637485742569
  zero_point: 0
  minval: 0.0
  maxval: 28.444326400756836
}
, input: "/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.3/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.11154637485742569
  zero_point: 0
  minval: 0.0
  maxval: 28.444326400756836
}
, input: "/encoder/layer.3/output/LayerNorm/Add_output_0"
output: "/encoder/layer.3/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.020914988592267036
  zero_point: 0
  minval: 0.0
  maxval: 5.333322048187256
}
, input: "/encoder/layer.3/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.3/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.3/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.11995021998882294
  zero_point: 230
  minval: -27.588550567626953
  maxval: 2.99875545501709
}
, input: "/encoder/layer.3/output/LayerNorm/Div_output_0"
input: "encoder.layer.3.output.LayerNorm.weight"
output: "/encoder/layer.3/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06441094726324081
  zero_point: 218
  minval: -14.041586875915527
  maxval: 2.3832051753997803
}
, input: "/encoder/layer.3/output/LayerNorm/Mul_output_0"
input: "encoder.layer.3.output.LayerNorm.bias"
output: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06357957422733307
  zero_point: 220
  minval: -13.987505912780762
  maxval: 2.225285053253174
}
, input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1425"
output: "/encoder/layer.4/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03810853511095047
  zero_point: 144
  minval: -5.487628936767578
  maxval: 4.230047225952148
}
, input: "encoder.layer.4.attention.self.query.bias"
input: "/encoder/layer.4/attention/self/query/MatMul_output_0"
output: "/encoder/layer.4/attention/self/query/Add_output_0:0"
name: "/encoder/layer.4/attention/self/query/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.0408809520304203
  zero_point: 147
  minval: -6.009500026702881
  maxval: 4.415143013000488
}
, input: "/encoder/layer.4/attention/self/query/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.4/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.4/attention/self/Reshape_2"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.0408809520304203
  zero_point: 147
  minval: -6.009500026702881
  maxval: 4.415143013000488
}
, input: "/encoder/layer.4/attention/self/Reshape_2_output_0"
output: "/encoder/layer.4/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.4/attention/self/Transpose_1"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.0408809520304203
  zero_point: 147
  minval: -6.009500026702881
  maxval: 4.415143013000488
}
, input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1426"
output: "/encoder/layer.4/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.035824548453092575
  zero_point: 142
  minval: -5.087086200714111
  maxval: 4.048173904418945
}
, input: "encoder.layer.4.attention.self.key.bias"
input: "/encoder/layer.4/attention/self/key/MatMul_output_0"
output: "/encoder/layer.4/attention/self/key/Add_output_0:0"
name: "/encoder/layer.4/attention/self/key/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.035851430147886276
  zero_point: 142
  minval: -5.090902805328369
  maxval: 4.051211357116699
}
, input: "/encoder/layer.4/attention/self/key/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.4/attention/self/Reshape_output_0:0"
name: "/encoder/layer.4/attention/self/Reshape"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.035851430147886276
  zero_point: 142
  minval: -5.090902805328369
  maxval: 4.051211357116699
}
, input: "/encoder/layer.4/attention/self/Reshape_output_0"
output: "/encoder/layer.4/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.4/attention/self/Transpose_2"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
quantize_info {
  scale: 0.035851430147886276
  zero_point: 142
  minval: -5.090902805328369
  maxval: 4.051211357116699
}
, input: "/encoder/layer.4/attention/self/Transpose_1_output_0"
input: "/encoder/layer.4/attention/self/Transpose_2_output_0"
output: "/encoder/layer.4/attention/self/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.40570372343063354
  zero_point: 72
  minval: -29.210668563842773
  maxval: 74.24378204345703
}
, input: "/encoder/layer.4/attention/self/MatMul_output_0"
output: "/encoder/layer.4/attention/self/Div_output_0:0"
name: "/encoder/layer.4/attention/self/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.05071296542882919
  zero_point: 72
  minval: -3.6513335704803467
  maxval: 9.280472755432129
}
, input: "/encoder/layer.4/attention/self/Div_output_0"
input: "/Mul_output_0"
output: "/encoder/layer.4/attention/self/Add_output_0:0"
name: "/encoder/layer.4/attention/self/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
, input: "/encoder/layer.4/attention/self/Add_output_0"
output: "/encoder/layer.4/attention/self/Softmax_output_0:0"
name: "/encoder/layer.4/attention/self/Softmax"
type: "Softmax"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
, input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1432"
output: "/encoder/layer.4/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.021970756351947784
  zero_point: 103
  minval: -2.2629880905151367
  maxval: 3.339555025100708
}
, input: "encoder.layer.4.attention.self.value.bias"
input: "/encoder/layer.4/attention/self/value/MatMul_output_0"
output: "/encoder/layer.4/attention/self/value/Add_output_0:0"
name: "/encoder/layer.4/attention/self/value/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.022308770567178726
  zero_point: 103
  minval: -2.2978034019470215
  maxval: 3.390933036804199
}
, input: "/encoder/layer.4/attention/self/value/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.4/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.4/attention/self/Reshape_1"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.022308770567178726
  zero_point: 103
  minval: -2.2978034019470215
  maxval: 3.390933036804199
}
, input: "/encoder/layer.4/attention/self/Reshape_1_output_0"
output: "/encoder/layer.4/attention/self/Transpose_output_0:0"
name: "/encoder/layer.4/attention/self/Transpose"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.022308770567178726
  zero_point: 103
  minval: -2.2978034019470215
  maxval: 3.390933036804199
}
, input: "/encoder/layer.4/attention/self/Softmax_output_0"
input: "/encoder/layer.4/attention/self/Transpose_output_0"
output: "/encoder/layer.4/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.4/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.007573618553578854
  zero_point: 137
  minval: -1.037585735321045
  maxval: 0.8936870098114014
}
, input: "/encoder/layer.4/attention/self/MatMul_1_output_0"
output: "/encoder/layer.4/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.4/attention/self/Transpose_3"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.007573618553578854
  zero_point: 137
  minval: -1.037585735321045
  maxval: 0.8936870098114014
}
, input: "/encoder/layer.4/attention/self/Transpose_3_output_0"
input: "/encoder/layer.0/attention/self/Constant_4_output_0"
output: "/encoder/layer.4/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.4/attention/self/Reshape_3"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.007573618553578854
  zero_point: 137
  minval: -1.037585735321045
  maxval: 0.8936870098114014
}
, input: "/encoder/layer.4/attention/self/Reshape_3_output_0"
input: "onnx::MatMul_1447"
output: "/encoder/layer.4/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.4/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.008231732062995434
  zero_point: 157
  minval: -1.292382001876831
  maxval: 0.8067097663879395
}
, input: "encoder.layer.4.attention.output.dense.bias"
input: "/encoder/layer.4/attention/output/dense/MatMul_output_0"
output: "/encoder/layer.4/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.4/attention/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.005933646112680435
  zero_point: 130
  minval: -0.771373987197876
  maxval: 0.7417057752609253
}
, input: "/encoder/layer.4/attention/output/dense/Add_output_0"
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.4/attention/output/Add_output_0:0"
name: "/encoder/layer.4/attention/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06699128448963165
  zero_point: 220
  minval: -14.738081932067871
  maxval: 2.3446948528289795
}
, input: "/encoder/layer.4/attention/output/Add_output_0"
output: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0001027019607136026
  zero_point: 255
  minval: -0.02618899941444397
  maxval: 0.0
}
, input: "/encoder/layer.4/attention/output/Add_output_0"
input: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.4/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06687942147254944
  zero_point: 220
  minval: -14.713473320007324
  maxval: 2.3407797813415527
}
, input: "/encoder/layer.4/attention/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.4/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.8489658832550049
  zero_point: 0
  minval: 0.0
  maxval: 216.48629760742188
}
, input: "/encoder/layer.4/attention/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.002525490242987871
  zero_point: 0
  minval: 0.0
  maxval: 0.6439999938011169
}
, input: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.4/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.002525490242987871
  zero_point: 0
  minval: 0.0
  maxval: 0.6439999938011169
}
, input: "/encoder/layer.4/attention/output/LayerNorm/Add_output_0"
output: "/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.003147043054923415
  zero_point: 0
  minval: 0.0
  maxval: 0.8024960160255432
}
, input: "/encoder/layer.4/attention/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.4/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.1050056740641594
  zero_point: 227
  minval: -23.836288452148438
  maxval: 2.9401588439941406
}
, input: "/encoder/layer.4/attention/output/LayerNorm/Div_output_0"
input: "encoder.layer.4.attention.output.LayerNorm.weight"
output: "/encoder/layer.4/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.3592655658721924
  zero_point: 248
  minval: -89.09786224365234
  maxval: 2.5148589611053467
}
, input: "/encoder/layer.4/attention/output/LayerNorm/Mul_output_0"
input: "encoder.layer.4.attention.output.LayerNorm.bias"
output: "/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.3636661469936371
  zero_point: 248
  minval: -90.18920135498047
  maxval: 2.5456628799438477
}
, input: "/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1448"
output: "/encoder/layer.4/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.4/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.2427986115217209
  zero_point: 226
  minval: -54.87248611450195
  maxval: 7.041159629821777
}
, input: "/encoder/layer.4/intermediate/dense/MatMul_output_0"
output: "/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1"
type: "Activation"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.02645285800099373
  zero_point: 7
  minval: -0.1851700097322464
  maxval: 6.560308933258057
}
, input: "/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0"
input: "onnx::MatMul_1449"
output: "/encoder/layer.4/output/dense/MatMul_output_0:0"
name: "/encoder/layer.4/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.19222192466259003
  zero_point: 233
  minval: -44.7877082824707
  maxval: 4.228882312774658
}
, input: "encoder.layer.4.output.dense.bias"
input: "/encoder/layer.4/output/dense/MatMul_output_0"
output: "/encoder/layer.4/output/dense/Add_output_0:0"
name: "/encoder/layer.4/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.1910017430782318
  zero_point: 235
  minval: -44.88541030883789
  maxval: 3.820034980773926
}
, input: "/encoder/layer.4/output/dense/Add_output_0"
input: "/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.4/output/Add_output_0:0"
name: "/encoder/layer.4/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.5424368977546692
  zero_point: 249
  minval: -135.06678771972656
  maxval: 3.2546215057373047
}
, input: "/encoder/layer.4/output/Add_output_0"
output: "/encoder/layer.4/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0006619372288696468
  zero_point: 255
  minval: -0.16879400610923767
  maxval: 0.0
}
, input: "/encoder/layer.4/output/Add_output_0"
input: "/encoder/layer.4/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.4/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.5417590141296387
  zero_point: 249
  minval: -134.8979949951172
  maxval: 3.250554084777832
}
, input: "/encoder/layer.4/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.4/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 71.36262512207031
  zero_point: 0
  minval: 0.0
  maxval: 18197.46875
}
, input: "/encoder/layer.4/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.09394069761037827
  zero_point: 0
  minval: 0.0
  maxval: 23.954877853393555
}
, input: "/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.4/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.09394069761037827
  zero_point: 0
  minval: 0.0
  maxval: 23.954877853393555
}
, input: "/encoder/layer.4/output/LayerNorm/Add_output_0"
output: "/encoder/layer.4/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0191936157643795
  zero_point: 0
  minval: 0.0
  maxval: 4.89437198638916
}
, input: "/encoder/layer.4/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.4/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.4/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.11880111694335938
  zero_point: 232
  minval: -27.561859130859375
  maxval: 2.7324256896972656
}
, input: "/encoder/layer.4/output/LayerNorm/Div_output_0"
input: "encoder.layer.4.output.LayerNorm.weight"
output: "/encoder/layer.4/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06785056740045547
  zero_point: 222
  minval: -15.062826156616211
  maxval: 2.2390687465667725
}
, input: "/encoder/layer.4/output/LayerNorm/Mul_output_0"
input: "encoder.layer.4.output.LayerNorm.bias"
output: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06664929538965225
  zero_point: 223
  minval: -14.86279296875
  maxval: 2.132777452468872
}
, input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1450"
output: "/encoder/layer.5/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04121337831020355
  zero_point: 151
  minval: -6.223219871520996
  maxval: 4.286191463470459
}
, input: "encoder.layer.5.attention.self.query.bias"
input: "/encoder/layer.5/attention/self/query/MatMul_output_0"
output: "/encoder/layer.5/attention/self/query/Add_output_0:0"
name: "/encoder/layer.5/attention/self/query/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04385722801089287
  zero_point: 150
  minval: -6.57858419418335
  maxval: 4.605009078979492
}
, input: "/encoder/layer.5/attention/self/query/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.5/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.5/attention/self/Reshape_2"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.04385722801089287
  zero_point: 150
  minval: -6.57858419418335
  maxval: 4.605009078979492
}
, input: "/encoder/layer.5/attention/self/Reshape_2_output_0"
output: "/encoder/layer.5/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.5/attention/self/Transpose_1"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.04385722801089287
  zero_point: 150
  minval: -6.57858419418335
  maxval: 4.605009078979492
}
, input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1451"
output: "/encoder/layer.5/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03027612902224064
  zero_point: 131
  minval: -3.966172933578491
  maxval: 3.754240036010742
}
, input: "encoder.layer.5.attention.self.key.bias"
input: "/encoder/layer.5/attention/self/key/MatMul_output_0"
output: "/encoder/layer.5/attention/self/key/Add_output_0:0"
name: "/encoder/layer.5/attention/self/key/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.030347755178809166
  zero_point: 132
  minval: -4.005903720855713
  maxval: 3.732774019241333
}
, input: "/encoder/layer.5/attention/self/key/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.5/attention/self/Reshape_output_0:0"
name: "/encoder/layer.5/attention/self/Reshape"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.030347755178809166
  zero_point: 132
  minval: -4.005903720855713
  maxval: 3.732774019241333
}
, input: "/encoder/layer.5/attention/self/Reshape_output_0"
output: "/encoder/layer.5/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.5/attention/self/Transpose_2"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
quantize_info {
  scale: 0.030347755178809166
  zero_point: 132
  minval: -4.005903720855713
  maxval: 3.732774019241333
}
, input: "/encoder/layer.5/attention/self/Transpose_1_output_0"
input: "/encoder/layer.5/attention/self/Transpose_2_output_0"
output: "/encoder/layer.5/attention/self/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.3326273262500763
  zero_point: 54
  minval: -17.961875915527344
  maxval: 66.85809326171875
}
, input: "/encoder/layer.5/attention/self/MatMul_output_0"
output: "/encoder/layer.5/attention/self/Div_output_0:0"
name: "/encoder/layer.5/attention/self/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.041578419506549835
  zero_point: 54
  minval: -2.245234489440918
  maxval: 8.357261657714844
}
, input: "/encoder/layer.5/attention/self/Div_output_0"
input: "/Mul_output_0"
output: "/encoder/layer.5/attention/self/Add_output_0:0"
name: "/encoder/layer.5/attention/self/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
, input: "/encoder/layer.5/attention/self/Add_output_0"
output: "/encoder/layer.5/attention/self/Softmax_output_0:0"
name: "/encoder/layer.5/attention/self/Softmax"
type: "Softmax"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
, input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1457"
output: "/encoder/layer.5/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.018208399415016174
  zero_point: 117
  minval: -2.130382537841797
  maxval: 2.51275897026062
}
, input: "encoder.layer.5.attention.self.value.bias"
input: "/encoder/layer.5/attention/self/value/MatMul_output_0"
output: "/encoder/layer.5/attention/self/value/Add_output_0:0"
name: "/encoder/layer.5/attention/self/value/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.018352163955569267
  zero_point: 116
  minval: -2.1288509368896484
  maxval: 2.550950765609741
}
, input: "/encoder/layer.5/attention/self/value/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.5/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.5/attention/self/Reshape_1"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.018352163955569267
  zero_point: 116
  minval: -2.1288509368896484
  maxval: 2.550950765609741
}
, input: "/encoder/layer.5/attention/self/Reshape_1_output_0"
output: "/encoder/layer.5/attention/self/Transpose_output_0:0"
name: "/encoder/layer.5/attention/self/Transpose"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.018352163955569267
  zero_point: 116
  minval: -2.1288509368896484
  maxval: 2.550950765609741
}
, input: "/encoder/layer.5/attention/self/Softmax_output_0"
input: "/encoder/layer.5/attention/self/Transpose_output_0"
output: "/encoder/layer.5/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.5/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.007289385888725519
  zero_point: 141
  minval: -1.0278034210205078
  maxval: 0.8309900164604187
}
, input: "/encoder/layer.5/attention/self/MatMul_1_output_0"
output: "/encoder/layer.5/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.5/attention/self/Transpose_3"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.007289385888725519
  zero_point: 141
  minval: -1.0278034210205078
  maxval: 0.8309900164604187
}
, input: "/encoder/layer.5/attention/self/Transpose_3_output_0"
input: "/encoder/layer.0/attention/self/Constant_4_output_0"
output: "/encoder/layer.5/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.5/attention/self/Reshape_3"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.007289385888725519
  zero_point: 141
  minval: -1.0278034210205078
  maxval: 0.8309900164604187
}
, input: "/encoder/layer.5/attention/self/Reshape_3_output_0"
input: "onnx::MatMul_1472"
output: "/encoder/layer.5/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.5/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.007264192681759596
  zero_point: 140
  minval: -1.0169869661331177
  maxval: 0.8353821635246277
}
, input: "encoder.layer.5.attention.output.dense.bias"
input: "/encoder/layer.5/attention/output/dense/MatMul_output_0"
output: "/encoder/layer.5/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.5/attention/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.006811340339481831
  zero_point: 141
  minval: -0.9603989720344543
  maxval: 0.7764928340911865
}
, input: "/encoder/layer.5/attention/output/dense/Add_output_0"
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.5/attention/output/Add_output_0:0"
name: "/encoder/layer.5/attention/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06836176663637161
  zero_point: 221
  minval: -15.107950210571289
  maxval: 2.3243000507354736
}
, input: "/encoder/layer.5/attention/output/Add_output_0"
output: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.00010129019938176498
  zero_point: 255
  minval: -0.025829000398516655
  maxval: 0.0
}
, input: "/encoder/layer.5/attention/output/Add_output_0"
input: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.5/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06855965405702591
  zero_point: 220
  minval: -15.083124160766602
  maxval: 2.399587869644165
}
, input: "/encoder/layer.5/attention/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.5/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.8921594023704529
  zero_point: 0
  minval: 0.0
  maxval: 227.50064086914062
}
, input: "/encoder/layer.5/attention/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0026996235828846693
  zero_point: 0
  minval: 0.0
  maxval: 0.6884040236473083
}
, input: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.5/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0026996235828846693
  zero_point: 0
  minval: 0.0
  maxval: 0.6884040236473083
}
, input: "/encoder/layer.5/attention/output/LayerNorm/Add_output_0"
output: "/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0032537293154746294
  zero_point: 0
  minval: 0.0
  maxval: 0.8297010064125061
}
, input: "/encoder/layer.5/attention/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.5/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.09705068171024323
  zero_point: 224
  minval: -21.73935317993164
  maxval: 3.008571147918701
}
, input: "/encoder/layer.5/attention/output/LayerNorm/Div_output_0"
input: "encoder.layer.5.attention.output.LayerNorm.weight"
output: "/encoder/layer.5/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.3000943660736084
  zero_point: 246
  minval: -73.82321166992188
  maxval: 2.7008492946624756
}
, input: "/encoder/layer.5/attention/output/LayerNorm/Mul_output_0"
input: "encoder.layer.5.attention.output.LayerNorm.bias"
output: "/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.30701619386672974
  zero_point: 245
  minval: -75.2189712524414
  maxval: 3.070162057876587
}
, input: "/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1473"
output: "/encoder/layer.5/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.5/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.1768578439950943
  zero_point: 236
  minval: -41.73844909667969
  maxval: 3.3602991104125977
}
, input: "/encoder/layer.5/intermediate/dense/MatMul_output_0"
output: "/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1"
type: "Activation"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.01231791265308857
  zero_point: 14
  minval: -0.17245078086853027
  maxval: 2.9686169624328613
}
, input: "/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0"
input: "onnx::MatMul_1474"
output: "/encoder/layer.5/output/dense/MatMul_output_0:0"
name: "/encoder/layer.5/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.08409030735492706
  zero_point: 214
  minval: -17.995325088500977
  maxval: 3.447702407836914
}
, input: "encoder.layer.5.output.dense.bias"
input: "/encoder/layer.5/output/dense/MatMul_output_0"
output: "/encoder/layer.5/output/dense/Add_output_0:0"
name: "/encoder/layer.5/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.08303789794445038
  zero_point: 220
  minval: -18.26833724975586
  maxval: 2.9063262939453125
}
, input: "/encoder/layer.5/output/dense/Add_output_0"
input: "/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.5/output/Add_output_0:0"
name: "/encoder/layer.5/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.38002970814704895
  zero_point: 246
  minval: -93.4873046875
  maxval: 3.420267343521118
}
, input: "/encoder/layer.5/output/Add_output_0"
output: "/encoder/layer.5/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.00043829018250107765
  zero_point: 255
  minval: -0.11176399886608124
  maxval: 0.0
}
, input: "/encoder/layer.5/output/Add_output_0"
input: "/encoder/layer.5/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.5/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.37957537174224854
  zero_point: 246
  minval: -93.37554168701172
  maxval: 3.4161784648895264
}
, input: "/encoder/layer.5/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.5/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 34.1921272277832
  zero_point: 0
  minval: 0.0
  maxval: 8718.9921875
}
, input: "/encoder/layer.5/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.045663971453905106
  zero_point: 0
  minval: 0.0
  maxval: 11.644312858581543
}
, input: "/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.5/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.045663971453905106
  zero_point: 0
  minval: 0.0
  maxval: 11.644312858581543
}
, input: "/encoder/layer.5/output/LayerNorm/Add_output_0"
output: "/encoder/layer.5/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.013381866738200188
  zero_point: 0
  minval: 0.0
  maxval: 3.4123759269714355
}
, input: "/encoder/layer.5/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.5/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.5/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.11845795065164566
  zero_point: 231
  minval: -27.363786697387695
  maxval: 2.8429908752441406
}
, input: "/encoder/layer.5/output/LayerNorm/Div_output_0"
input: "encoder.layer.5.output.LayerNorm.weight"
output: "/encoder/layer.5/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07036226242780685
  zero_point: 222
  minval: -15.620423316955566
  maxval: 2.3219547271728516
}
, input: "/encoder/layer.5/output/LayerNorm/Mul_output_0"
input: "encoder.layer.5.output.LayerNorm.bias"
output: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06854751706123352
  zero_point: 222
  minval: -15.217549324035645
  maxval: 2.262068033218384
}
, input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1475"
output: "/encoder/layer.6/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04819261282682419
  zero_point: 144
  minval: -6.939736366271973
  maxval: 5.349380016326904
}
, input: "encoder.layer.6.attention.self.query.bias"
input: "/encoder/layer.6/attention/self/query/MatMul_output_0"
output: "/encoder/layer.6/attention/self/query/Add_output_0:0"
name: "/encoder/layer.6/attention/self/query/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.051366306841373444
  zero_point: 144
  minval: -7.396748065948486
  maxval: 5.701659679412842
}
, input: "/encoder/layer.6/attention/self/query/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.6/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.6/attention/self/Reshape_2"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.051366306841373444
  zero_point: 144
  minval: -7.396748065948486
  maxval: 5.701659679412842
}
, input: "/encoder/layer.6/attention/self/Reshape_2_output_0"
output: "/encoder/layer.6/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.6/attention/self/Transpose_1"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.051366306841373444
  zero_point: 144
  minval: -7.396748065948486
  maxval: 5.701659679412842
}
, input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1476"
output: "/encoder/layer.6/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03172209858894348
  zero_point: 140
  minval: -4.441093921661377
  maxval: 3.6480414867401123
}
, input: "encoder.layer.6.attention.self.key.bias"
input: "/encoder/layer.6/attention/self/key/MatMul_output_0"
output: "/encoder/layer.6/attention/self/key/Add_output_0:0"
name: "/encoder/layer.6/attention/self/key/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.031865593045949936
  zero_point: 139
  minval: -4.429317474365234
  maxval: 3.696408987045288
}
, input: "/encoder/layer.6/attention/self/key/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.6/attention/self/Reshape_output_0:0"
name: "/encoder/layer.6/attention/self/Reshape"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.031865593045949936
  zero_point: 139
  minval: -4.429317474365234
  maxval: 3.696408987045288
}
, input: "/encoder/layer.6/attention/self/Reshape_output_0"
output: "/encoder/layer.6/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.6/attention/self/Transpose_2"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
quantize_info {
  scale: 0.031865593045949936
  zero_point: 139
  minval: -4.429317474365234
  maxval: 3.696408987045288
}
, input: "/encoder/layer.6/attention/self/Transpose_1_output_0"
input: "/encoder/layer.6/attention/self/Transpose_2_output_0"
output: "/encoder/layer.6/attention/self/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.34057220816612244
  zero_point: 44
  minval: -14.985177040100098
  maxval: 71.86073303222656
}
, input: "/encoder/layer.6/attention/self/MatMul_output_0"
output: "/encoder/layer.6/attention/self/Div_output_0:0"
name: "/encoder/layer.6/attention/self/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.042571522295475006
  zero_point: 44
  minval: -1.8731470108032227
  maxval: 8.98259162902832
}
, input: "/encoder/layer.6/attention/self/Div_output_0"
input: "/Mul_output_0"
output: "/encoder/layer.6/attention/self/Add_output_0:0"
name: "/encoder/layer.6/attention/self/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
, input: "/encoder/layer.6/attention/self/Add_output_0"
output: "/encoder/layer.6/attention/self/Softmax_output_0:0"
name: "/encoder/layer.6/attention/self/Softmax"
type: "Softmax"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
, input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1482"
output: "/encoder/layer.6/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.018793268129229546
  zero_point: 128
  minval: -2.405538320541382
  maxval: 2.386744976043701
}
, input: "encoder.layer.6.attention.self.value.bias"
input: "/encoder/layer.6/attention/self/value/MatMul_output_0"
output: "/encoder/layer.6/attention/self/value/Add_output_0:0"
name: "/encoder/layer.6/attention/self/value/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.01886012591421604
  zero_point: 128
  minval: -2.4140961170196533
  maxval: 2.395236015319824
}
, input: "/encoder/layer.6/attention/self/value/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.6/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.6/attention/self/Reshape_1"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.01886012591421604
  zero_point: 128
  minval: -2.4140961170196533
  maxval: 2.395236015319824
}
, input: "/encoder/layer.6/attention/self/Reshape_1_output_0"
output: "/encoder/layer.6/attention/self/Transpose_output_0:0"
name: "/encoder/layer.6/attention/self/Transpose"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.01886012591421604
  zero_point: 128
  minval: -2.4140961170196533
  maxval: 2.395236015319824
}
, input: "/encoder/layer.6/attention/self/Softmax_output_0"
input: "/encoder/layer.6/attention/self/Transpose_output_0"
output: "/encoder/layer.6/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.6/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.010126526467502117
  zero_point: 124
  minval: -1.255689263343811
  maxval: 1.3265750408172607
}
, input: "/encoder/layer.6/attention/self/MatMul_1_output_0"
output: "/encoder/layer.6/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.6/attention/self/Transpose_3"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.010126526467502117
  zero_point: 124
  minval: -1.255689263343811
  maxval: 1.3265750408172607
}
, input: "/encoder/layer.6/attention/self/Transpose_3_output_0"
input: "/encoder/layer.0/attention/self/Constant_4_output_0"
output: "/encoder/layer.6/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.6/attention/self/Reshape_3"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.010126526467502117
  zero_point: 124
  minval: -1.255689263343811
  maxval: 1.3265750408172607
}
, input: "/encoder/layer.6/attention/self/Reshape_3_output_0"
input: "onnx::MatMul_1497"
output: "/encoder/layer.6/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.6/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.010015870444476604
  zero_point: 108
  minval: -1.0817140340805054
  maxval: 1.4723329544067383
}
, input: "encoder.layer.6.attention.output.dense.bias"
input: "/encoder/layer.6/attention/output/dense/MatMul_output_0"
output: "/encoder/layer.6/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.6/attention/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.009534415788948536
  zero_point: 106
  minval: -1.0106481313705444
  maxval: 1.4206279516220093
}
, input: "/encoder/layer.6/attention/output/dense/Add_output_0"
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.6/attention/output/Add_output_0:0"
name: "/encoder/layer.6/attention/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07113279402256012
  zero_point: 215
  minval: -15.293551445007324
  maxval: 2.8453118801116943
}
, input: "/encoder/layer.6/attention/output/Add_output_0"
output: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 8.529411570634693e-05
  zero_point: 255
  minval: -0.02174999937415123
  maxval: 0.0
}
, input: "/encoder/layer.6/attention/output/Add_output_0"
input: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.6/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07103818655014038
  zero_point: 215
  minval: -15.273209571838379
  maxval: 2.8415274620056152
}
, input: "/encoder/layer.6/attention/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.6/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.914788007736206
  zero_point: 0
  minval: 0.0
  maxval: 233.27093505859375
}
, input: "/encoder/layer.6/attention/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0029960430692881346
  zero_point: 0
  minval: 0.0
  maxval: 0.7639909982681274
}
, input: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.6/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0029960430692881346
  zero_point: 0
  minval: 0.0
  maxval: 0.7639909982681274
}
, input: "/encoder/layer.6/attention/output/LayerNorm/Add_output_0"
output: "/encoder/layer.6/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0034277099184691906
  zero_point: 0
  minval: 0.0
  maxval: 0.8740659952163696
}
, input: "/encoder/layer.6/attention/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.6/attention/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.6/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.09561571478843689
  zero_point: 221
  minval: -21.131072998046875
  maxval: 3.250934362411499
}
, input: "/encoder/layer.6/attention/output/LayerNorm/Div_output_0"
input: "encoder.layer.6.attention.output.LayerNorm.weight"
output: "/encoder/layer.6/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.28843748569488525
  zero_point: 245
  minval: -70.66718292236328
  maxval: 2.8843748569488525
}
, input: "/encoder/layer.6/attention/output/LayerNorm/Mul_output_0"
input: "encoder.layer.6.attention.output.LayerNorm.bias"
output: "/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.29661065340042114
  zero_point: 245
  minval: -72.66960906982422
  maxval: 2.966106414794922
}
, input: "/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1498"
output: "/encoder/layer.6/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.6/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.0957103744149208
  zero_point: 213
  minval: -20.386308670043945
  maxval: 4.019835472106934
}
, input: "/encoder/layer.6/intermediate/dense/MatMul_output_0"
output: "/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1"
type: "Activation"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.015826361253857613
  zero_point: 11
  minval: -0.1740899682044983
  maxval: 3.8616321086883545
}
, input: "/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1_output_0"
input: "onnx::MatMul_1499"
output: "/encoder/layer.6/output/dense/MatMul_output_0:0"
name: "/encoder/layer.6/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07174398005008698
  zero_point: 219
  minval: -15.711932182312012
  maxval: 2.5827834606170654
}
, input: "encoder.layer.6.output.dense.bias"
input: "/encoder/layer.6/output/dense/MatMul_output_0"
output: "/encoder/layer.6/output/dense/Add_output_0:0"
name: "/encoder/layer.6/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07195455580949783
  zero_point: 226
  minval: -16.261730194091797
  maxval: 2.086682081222534
}
, input: "/encoder/layer.6/output/dense/Add_output_0"
input: "/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.6/output/Add_output_0:0"
name: "/encoder/layer.6/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.3627967834472656
  zero_point: 246
  minval: -89.24800872802734
  maxval: 3.2651710510253906
}
, input: "/encoder/layer.6/output/Add_output_0"
output: "/encoder/layer.6/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.000435094116255641
  zero_point: 255
  minval: -0.11094900220632553
  maxval: 0.0
}
, input: "/encoder/layer.6/output/Add_output_0"
input: "/encoder/layer.6/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.6/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.3610585033893585
  zero_point: 246
  minval: -88.82038879394531
  maxval: 3.2495265007019043
}
, input: "/encoder/layer.6/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.6/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 30.937496185302734
  zero_point: 0
  minval: 0.0
  maxval: 7889.0615234375
}
, input: "/encoder/layer.6/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.6/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.04150957241654396
  zero_point: 0
  minval: 0.0
  maxval: 10.584940910339355
}
, input: "/encoder/layer.6/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.6/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.04150957241654396
  zero_point: 0
  minval: 0.0
  maxval: 10.584940910339355
}
, input: "/encoder/layer.6/output/LayerNorm/Add_output_0"
output: "/encoder/layer.6/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.012758631259202957
  zero_point: 0
  minval: 0.0
  maxval: 3.253451108932495
}
, input: "/encoder/layer.6/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.6/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.6/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.11900883913040161
  zero_point: 230
  minval: -27.372034072875977
  maxval: 2.9752209186553955
}
, input: "/encoder/layer.6/output/LayerNorm/Div_output_0"
input: "encoder.layer.6.output.LayerNorm.weight"
output: "/encoder/layer.6/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06669235229492188
  zero_point: 219
  minval: -14.60562515258789
  maxval: 2.4009246826171875
}
, input: "/encoder/layer.6/output/LayerNorm/Mul_output_0"
input: "encoder.layer.6.output.LayerNorm.bias"
output: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06310923397541046
  zero_point: 219
  minval: -13.820921897888184
  maxval: 2.271932363510132
}
, input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1500"
output: "/encoder/layer.7/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04076783359050751
  zero_point: 139
  minval: -5.666728973388672
  maxval: 4.729068756103516
}
, input: "encoder.layer.7.attention.self.query.bias"
input: "/encoder/layer.7/attention/self/query/MatMul_output_0"
output: "/encoder/layer.7/attention/self/query/Add_output_0:0"
name: "/encoder/layer.7/attention/self/query/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04643896594643593
  zero_point: 141
  minval: -6.54789400100708
  maxval: 5.294042110443115
}
, input: "/encoder/layer.7/attention/self/query/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.7/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.7/attention/self/Reshape_2"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.04643896594643593
  zero_point: 141
  minval: -6.54789400100708
  maxval: 5.294042110443115
}
, input: "/encoder/layer.7/attention/self/Reshape_2_output_0"
output: "/encoder/layer.7/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.7/attention/self/Transpose_1"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.04643896594643593
  zero_point: 141
  minval: -6.54789400100708
  maxval: 5.294042110443115
}
, input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1501"
output: "/encoder/layer.7/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04032149165868759
  zero_point: 137
  minval: -5.524044513702393
  maxval: 4.757936000823975
}
, input: "encoder.layer.7.attention.self.key.bias"
input: "/encoder/layer.7/attention/self/key/MatMul_output_0"
output: "/encoder/layer.7/attention/self/key/Add_output_0:0"
name: "/encoder/layer.7/attention/self/key/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04019321873784065
  zero_point: 137
  minval: -5.506471157073975
  maxval: 4.742799758911133
}
, input: "/encoder/layer.7/attention/self/key/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.7/attention/self/Reshape_output_0:0"
name: "/encoder/layer.7/attention/self/Reshape"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.04019321873784065
  zero_point: 137
  minval: -5.506471157073975
  maxval: 4.742799758911133
}
, input: "/encoder/layer.7/attention/self/Reshape_output_0"
output: "/encoder/layer.7/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.7/attention/self/Transpose_2"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
quantize_info {
  scale: 0.04019321873784065
  zero_point: 137
  minval: -5.506471157073975
  maxval: 4.742799758911133
}
, input: "/encoder/layer.7/attention/self/Transpose_1_output_0"
input: "/encoder/layer.7/attention/self/Transpose_2_output_0"
output: "/encoder/layer.7/attention/self/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.34224170446395874
  zero_point: 66
  minval: -22.58795166015625
  maxval: 64.68367767333984
}
, input: "/encoder/layer.7/attention/self/MatMul_output_0"
output: "/encoder/layer.7/attention/self/Div_output_0:0"
name: "/encoder/layer.7/attention/self/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.04278021305799484
  zero_point: 66
  minval: -2.8234939575195312
  maxval: 8.08545970916748
}
, input: "/encoder/layer.7/attention/self/Div_output_0"
input: "/Mul_output_0"
output: "/encoder/layer.7/attention/self/Add_output_0:0"
name: "/encoder/layer.7/attention/self/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
, input: "/encoder/layer.7/attention/self/Add_output_0"
output: "/encoder/layer.7/attention/self/Softmax_output_0:0"
name: "/encoder/layer.7/attention/self/Softmax"
type: "Softmax"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
, input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1507"
output: "/encoder/layer.7/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.01867643930017948
  zero_point: 141
  minval: -2.63337779045105
  maxval: 2.1291139125823975
}
, input: "encoder.layer.7.attention.self.value.bias"
input: "/encoder/layer.7/attention/self/value/MatMul_output_0"
output: "/encoder/layer.7/attention/self/value/Add_output_0:0"
name: "/encoder/layer.7/attention/self/value/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.018876798450946808
  zero_point: 141
  minval: -2.661628484725952
  maxval: 2.1519548892974854
}
, input: "/encoder/layer.7/attention/self/value/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.7/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.7/attention/self/Reshape_1"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.018876798450946808
  zero_point: 141
  minval: -2.661628484725952
  maxval: 2.1519548892974854
}
, input: "/encoder/layer.7/attention/self/Reshape_1_output_0"
output: "/encoder/layer.7/attention/self/Transpose_output_0:0"
name: "/encoder/layer.7/attention/self/Transpose"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.018876798450946808
  zero_point: 141
  minval: -2.661628484725952
  maxval: 2.1519548892974854
}
, input: "/encoder/layer.7/attention/self/Softmax_output_0"
input: "/encoder/layer.7/attention/self/Transpose_output_0"
output: "/encoder/layer.7/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.7/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.007804992608726025
  zero_point: 134
  minval: -1.045868992805481
  maxval: 0.944404125213623
}
, input: "/encoder/layer.7/attention/self/MatMul_1_output_0"
output: "/encoder/layer.7/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.7/attention/self/Transpose_3"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.007804992608726025
  zero_point: 134
  minval: -1.045868992805481
  maxval: 0.944404125213623
}
, input: "/encoder/layer.7/attention/self/Transpose_3_output_0"
input: "/encoder/layer.0/attention/self/Constant_4_output_0"
output: "/encoder/layer.7/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.7/attention/self/Reshape_3"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.007804992608726025
  zero_point: 134
  minval: -1.045868992805481
  maxval: 0.944404125213623
}
, input: "/encoder/layer.7/attention/self/Reshape_3_output_0"
input: "onnx::MatMul_1522"
output: "/encoder/layer.7/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.7/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.015512127429246902
  zero_point: 180
  minval: -2.7921829223632812
  maxval: 1.1634095907211304
}
, input: "encoder.layer.7.attention.output.dense.bias"
input: "/encoder/layer.7/attention/output/dense/MatMul_output_0"
output: "/encoder/layer.7/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.7/attention/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.009801630862057209
  zero_point: 144
  minval: -1.4114347696304321
  maxval: 1.0879809856414795
}
, input: "/encoder/layer.7/attention/output/dense/Add_output_0"
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.7/attention/output/Add_output_0:0"
name: "/encoder/layer.7/attention/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06986185163259506
  zero_point: 218
  minval: -15.229883193969727
  maxval: 2.584888458251953
}
, input: "/encoder/layer.7/attention/output/Add_output_0"
output: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.00010946666589006782
  zero_point: 255
  minval: -0.027914000675082207
  maxval: 0.0
}
, input: "/encoder/layer.7/attention/output/Add_output_0"
input: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.7/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06974241137504578
  zero_point: 218
  minval: -15.203845024108887
  maxval: 2.5804691314697266
}
, input: "/encoder/layer.7/attention/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.7/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.9064976572990417
  zero_point: 0
  minval: 0.0
  maxval: 231.1569061279297
}
, input: "/encoder/layer.7/attention/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.003200941253453493
  zero_point: 0
  minval: 0.0
  maxval: 0.8162400126457214
}
, input: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.7/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.003200941253453493
  zero_point: 0
  minval: 0.0
  maxval: 0.8162400126457214
}
, input: "/encoder/layer.7/attention/output/LayerNorm/Add_output_0"
output: "/encoder/layer.7/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0035429804120212793
  zero_point: 0
  minval: 0.0
  maxval: 0.9034600257873535
}
, input: "/encoder/layer.7/attention/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.7/attention/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.7/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.08873584866523743
  zero_point: 222
  minval: -19.699357986450195
  maxval: 2.9282829761505127
}
, input: "/encoder/layer.7/attention/output/LayerNorm/Div_output_0"
input: "encoder.layer.7.attention.output.LayerNorm.weight"
output: "/encoder/layer.7/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.27034851908683777
  zero_point: 245
  minval: -66.23538970947266
  maxval: 2.7034852504730225
}
, input: "/encoder/layer.7/attention/output/LayerNorm/Mul_output_0"
input: "encoder.layer.7.attention.output.LayerNorm.bias"
output: "/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.27870744466781616
  zero_point: 245
  minval: -68.2833251953125
  maxval: 2.787074565887451
}
, input: "/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1523"
output: "/encoder/layer.7/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.7/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.0668439120054245
  zero_point: 195
  minval: -13.034563064575195
  maxval: 4.010634899139404
}
, input: "/encoder/layer.7/intermediate/dense/MatMul_output_0"
output: "/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1"
type: "Activation"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.015968652442097664
  zero_point: 11
  minval: -0.17565517127513885
  maxval: 3.8963510990142822
}
, input: "/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1_output_0"
input: "onnx::MatMul_1524"
output: "/encoder/layer.7/output/dense/MatMul_output_0:0"
name: "/encoder/layer.7/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.019198313355445862
  zero_point: 64
  minval: -1.2286920547485352
  maxval: 3.6668779850006104
}
, input: "encoder.layer.7.output.dense.bias"
input: "/encoder/layer.7/output/dense/MatMul_output_0"
output: "/encoder/layer.7/output/dense/Add_output_0:0"
name: "/encoder/layer.7/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.016439272090792656
  zero_point: 77
  minval: -1.2658239603042603
  maxval: 2.9261906147003174
}
, input: "/encoder/layer.7/output/dense/Add_output_0"
input: "/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.7/output/Add_output_0:0"
name: "/encoder/layer.7/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.28545618057250977
  zero_point: 242
  minval: -69.08039855957031
  maxval: 3.710930585861206
}
, input: "/encoder/layer.7/output/Add_output_0"
output: "/encoder/layer.7/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.00036383920814841986
  zero_point: 255
  minval: -0.0927790030837059
  maxval: 0.0
}
, input: "/encoder/layer.7/output/Add_output_0"
input: "/encoder/layer.7/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.7/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.28507280349731445
  zero_point: 242
  minval: -68.98761749267578
  maxval: 3.705946445465088
}
, input: "/encoder/layer.7/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.7/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 18.663888931274414
  zero_point: 0
  minval: 0.0
  maxval: 4759.29150390625
}
, input: "/encoder/layer.7/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.7/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.025551553815603256
  zero_point: 0
  minval: 0.0
  maxval: 6.515645980834961
}
, input: "/encoder/layer.7/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.7/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.025551553815603256
  zero_point: 0
  minval: 0.0
  maxval: 6.515645980834961
}
, input: "/encoder/layer.7/output/LayerNorm/Add_output_0"
output: "/encoder/layer.7/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.010010101832449436
  zero_point: 0
  minval: 0.0
  maxval: 2.5525760650634766
}
, input: "/encoder/layer.7/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.7/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.7/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.11906018853187561
  zero_point: 227
  minval: -27.026662826538086
  maxval: 3.3336853981018066
}
, input: "/encoder/layer.7/output/LayerNorm/Div_output_0"
input: "encoder.layer.7.output.LayerNorm.weight"
output: "/encoder/layer.7/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07451529055833817
  zero_point: 220
  minval: -16.39336395263672
  maxval: 2.608035087585449
}
, input: "/encoder/layer.7/output/LayerNorm/Mul_output_0"
input: "encoder.layer.7.output.LayerNorm.bias"
output: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07047713547945023
  zero_point: 219
  minval: -15.434492111206055
  maxval: 2.5371768474578857
}
, input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1525"
output: "/encoder/layer.8/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03878064453601837
  zero_point: 127
  minval: -4.92514181137085
  maxval: 4.963922500610352
}
, input: "encoder.layer.8.attention.self.query.bias"
input: "/encoder/layer.8/attention/self/query/MatMul_output_0"
output: "/encoder/layer.8/attention/self/query/Add_output_0:0"
name: "/encoder/layer.8/attention/self/query/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04355912655591965
  zero_point: 129
  minval: -5.61912727355957
  maxval: 5.488450050354004
}
, input: "/encoder/layer.8/attention/self/query/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.8/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.8/attention/self/Reshape_2"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.04355912655591965
  zero_point: 129
  minval: -5.61912727355957
  maxval: 5.488450050354004
}
, input: "/encoder/layer.8/attention/self/Reshape_2_output_0"
output: "/encoder/layer.8/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.8/attention/self/Transpose_1"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.04355912655591965
  zero_point: 129
  minval: -5.61912727355957
  maxval: 5.488450050354004
}
, input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1526"
output: "/encoder/layer.8/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.0334072969853878
  zero_point: 127
  minval: -4.242726802825928
  maxval: 4.276134014129639
}
, input: "encoder.layer.8.attention.self.key.bias"
input: "/encoder/layer.8/attention/self/key/MatMul_output_0"
output: "/encoder/layer.8/attention/self/key/Add_output_0:0"
name: "/encoder/layer.8/attention/self/key/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03330055624246597
  zero_point: 126
  minval: -4.1958699226379395
  maxval: 4.295771598815918
}
, input: "/encoder/layer.8/attention/self/key/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.8/attention/self/Reshape_output_0:0"
name: "/encoder/layer.8/attention/self/Reshape"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.03330055624246597
  zero_point: 126
  minval: -4.1958699226379395
  maxval: 4.295771598815918
}
, input: "/encoder/layer.8/attention/self/Reshape_output_0"
output: "/encoder/layer.8/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.8/attention/self/Transpose_2"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
quantize_info {
  scale: 0.03330055624246597
  zero_point: 126
  minval: -4.1958699226379395
  maxval: 4.295771598815918
}
, input: "/encoder/layer.8/attention/self/Transpose_1_output_0"
input: "/encoder/layer.8/attention/self/Transpose_2_output_0"
output: "/encoder/layer.8/attention/self/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.34134015440940857
  zero_point: 67
  minval: -22.86979103088379
  maxval: 64.17195129394531
}
, input: "/encoder/layer.8/attention/self/MatMul_output_0"
output: "/encoder/layer.8/attention/self/Div_output_0:0"
name: "/encoder/layer.8/attention/self/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.04266752302646637
  zero_point: 67
  minval: -2.8587238788604736
  maxval: 8.021493911743164
}
, input: "/encoder/layer.8/attention/self/Div_output_0"
input: "/Mul_output_0"
output: "/encoder/layer.8/attention/self/Add_output_0:0"
name: "/encoder/layer.8/attention/self/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
, input: "/encoder/layer.8/attention/self/Add_output_0"
output: "/encoder/layer.8/attention/self/Softmax_output_0:0"
name: "/encoder/layer.8/attention/self/Softmax"
type: "Softmax"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
, input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1532"
output: "/encoder/layer.8/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.02117350324988365
  zero_point: 125
  minval: -2.6466879844665527
  maxval: 2.7525556087493896
}
, input: "encoder.layer.8.attention.self.value.bias"
input: "/encoder/layer.8/attention/self/value/MatMul_output_0"
output: "/encoder/layer.8/attention/self/value/Add_output_0:0"
name: "/encoder/layer.8/attention/self/value/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.02119789645075798
  zero_point: 125
  minval: -2.6497368812561035
  maxval: 2.7557265758514404
}
, input: "/encoder/layer.8/attention/self/value/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.8/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.8/attention/self/Reshape_1"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.02119789645075798
  zero_point: 125
  minval: -2.6497368812561035
  maxval: 2.7557265758514404
}
, input: "/encoder/layer.8/attention/self/Reshape_1_output_0"
output: "/encoder/layer.8/attention/self/Transpose_output_0:0"
name: "/encoder/layer.8/attention/self/Transpose"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.02119789645075798
  zero_point: 125
  minval: -2.6497368812561035
  maxval: 2.7557265758514404
}
, input: "/encoder/layer.8/attention/self/Softmax_output_0"
input: "/encoder/layer.8/attention/self/Transpose_output_0"
output: "/encoder/layer.8/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.8/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.011665240861475468
  zero_point: 143
  minval: -1.6681294441223145
  maxval: 1.3065069913864136
}
, input: "/encoder/layer.8/attention/self/MatMul_1_output_0"
output: "/encoder/layer.8/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.8/attention/self/Transpose_3"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.011665240861475468
  zero_point: 143
  minval: -1.6681294441223145
  maxval: 1.3065069913864136
}
, input: "/encoder/layer.8/attention/self/Transpose_3_output_0"
input: "/encoder/layer.0/attention/self/Constant_4_output_0"
output: "/encoder/layer.8/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.8/attention/self/Reshape_3"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.011665240861475468
  zero_point: 143
  minval: -1.6681294441223145
  maxval: 1.3065069913864136
}
, input: "/encoder/layer.8/attention/self/Reshape_3_output_0"
input: "onnx::MatMul_1547"
output: "/encoder/layer.8/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.8/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.01757514476776123
  zero_point: 173
  minval: -3.0404999256134033
  maxval: 1.441161870956421
}
, input: "encoder.layer.8.attention.output.dense.bias"
input: "/encoder/layer.8/attention/output/dense/MatMul_output_0"
output: "/encoder/layer.8/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.8/attention/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.01261430885642767
  zero_point: 145
  minval: -1.8290748596191406
  maxval: 1.3875739574432373
}
, input: "/encoder/layer.8/attention/output/dense/Add_output_0"
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.8/attention/output/Add_output_0:0"
name: "/encoder/layer.8/attention/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.0788085088133812
  zero_point: 219
  minval: -17.259063720703125
  maxval: 2.837106466293335
}
, input: "/encoder/layer.8/attention/output/Add_output_0"
output: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.00014143137377686799
  zero_point: 255
  minval: -0.0360650010406971
  maxval: 0.0
}
, input: "/encoder/layer.8/attention/output/Add_output_0"
input: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.8/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07900568097829819
  zero_point: 218
  minval: -17.223237991333008
  maxval: 2.9232101440429688
}
, input: "/encoder/layer.8/attention/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.8/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 1.1632938385009766
  zero_point: 0
  minval: 0.0
  maxval: 296.6399230957031
}
, input: "/encoder/layer.8/attention/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.003563070669770241
  zero_point: 0
  minval: 0.0
  maxval: 0.9085829854011536
}
, input: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.8/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.003563070669770241
  zero_point: 0
  minval: 0.0
  maxval: 0.9085829854011536
}
, input: "/encoder/layer.8/attention/output/LayerNorm/Add_output_0"
output: "/encoder/layer.8/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0037380235735327005
  zero_point: 0
  minval: 0.0
  maxval: 0.9531959891319275
}
, input: "/encoder/layer.8/attention/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.8/attention/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.8/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.0832669585943222
  zero_point: 217
  minval: -18.06892967224121
  maxval: 3.164144515991211
}
, input: "/encoder/layer.8/attention/output/LayerNorm/Div_output_0"
input: "encoder.layer.8.attention.output.LayerNorm.weight"
output: "/encoder/layer.8/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.2278434932231903
  zero_point: 245
  minval: -55.8216552734375
  maxval: 2.278434991836548
}
, input: "/encoder/layer.8/attention/output/LayerNorm/Mul_output_0"
input: "encoder.layer.8.attention.output.LayerNorm.bias"
output: "/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.23593111336231232
  zero_point: 244
  minval: -57.56719207763672
  maxval: 2.5952422618865967
}
, input: "/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1548"
output: "/encoder/layer.8/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.8/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.08149689435958862
  zero_point: 213
  minval: -17.35883903503418
  maxval: 3.4228696823120117
}
, input: "/encoder/layer.8/intermediate/dense/MatMul_output_0"
output: "/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1"
type: "Activation"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.013834809884428978
  zero_point: 13
  minval: -0.17985253036022186
  maxval: 3.3480238914489746
}
, input: "/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1_output_0"
input: "onnx::MatMul_1549"
output: "/encoder/layer.8/output/dense/MatMul_output_0:0"
name: "/encoder/layer.8/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.022208763286471367
  zero_point: 61
  minval: -1.3547345399856567
  maxval: 4.308499813079834
}
, input: "encoder.layer.8.output.dense.bias"
input: "/encoder/layer.8/output/dense/MatMul_output_0"
output: "/encoder/layer.8/output/dense/Add_output_0:0"
name: "/encoder/layer.8/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.019233081489801407
  zero_point: 69
  minval: -1.3270825147628784
  maxval: 3.577353000640869
}
, input: "/encoder/layer.8/output/dense/Add_output_0"
input: "/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.8/output/Add_output_0:0"
name: "/encoder/layer.8/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.2258034199476242
  zero_point: 243
  minval: -54.87023162841797
  maxval: 2.7096409797668457
}
, input: "/encoder/layer.8/output/Add_output_0"
output: "/encoder/layer.8/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0003142000059597194
  zero_point: 255
  minval: -0.0801210030913353
  maxval: 0.0
}
, input: "/encoder/layer.8/output/Add_output_0"
input: "/encoder/layer.8/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.8/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.22476567327976227
  zero_point: 243
  minval: -54.61805725097656
  maxval: 2.697187900543213
}
, input: "/encoder/layer.8/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.8/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 11.698556900024414
  zero_point: 0
  minval: 0.0
  maxval: 2983.132080078125
}
, input: "/encoder/layer.8/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.8/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.01716194860637188
  zero_point: 0
  minval: 0.0
  maxval: 4.3762969970703125
}
, input: "/encoder/layer.8/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.8/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.01716194860637188
  zero_point: 0
  minval: 0.0
  maxval: 4.3762969970703125
}
, input: "/encoder/layer.8/output/LayerNorm/Add_output_0"
output: "/encoder/layer.8/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.008203764446079731
  zero_point: 0
  minval: 0.0
  maxval: 2.0919599533081055
}
, input: "/encoder/layer.8/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.8/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.8/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.1135154590010643
  zero_point: 230
  minval: -26.10855484008789
  maxval: 2.837886333465576
}
, input: "/encoder/layer.8/output/LayerNorm/Div_output_0"
input: "encoder.layer.8.output.LayerNorm.weight"
output: "/encoder/layer.8/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07404923439025879
  zero_point: 223
  minval: -16.51297950744629
  maxval: 2.3695755004882812
}
, input: "/encoder/layer.8/output/LayerNorm/Mul_output_0"
input: "encoder.layer.8.output.LayerNorm.bias"
output: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.0734701156616211
  zero_point: 223
  minval: -16.383834838867188
  maxval: 2.351043701171875
}
, input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1550"
output: "/encoder/layer.9/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.040860384702682495
  zero_point: 135
  minval: -5.5161519050598145
  maxval: 4.90324592590332
}
, input: "encoder.layer.9.attention.self.query.bias"
input: "/encoder/layer.9/attention/self/query/MatMul_output_0"
output: "/encoder/layer.9/attention/self/query/Add_output_0:0"
name: "/encoder/layer.9/attention/self/query/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.045451246201992035
  zero_point: 138
  minval: -6.272272109985352
  maxval: 5.317796230316162
}
, input: "/encoder/layer.9/attention/self/query/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.9/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.9/attention/self/Reshape_2"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.045451246201992035
  zero_point: 138
  minval: -6.272272109985352
  maxval: 5.317796230316162
}
, input: "/encoder/layer.9/attention/self/Reshape_2_output_0"
output: "/encoder/layer.9/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.9/attention/self/Transpose_1"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.045451246201992035
  zero_point: 138
  minval: -6.272272109985352
  maxval: 5.317796230316162
}
, input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1551"
output: "/encoder/layer.9/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03000347502529621
  zero_point: 131
  minval: -3.930455446243286
  maxval: 3.720431089401245
}
, input: "encoder.layer.9.attention.self.key.bias"
input: "/encoder/layer.9/attention/self/key/MatMul_output_0"
output: "/encoder/layer.9/attention/self/key/Add_output_0:0"
name: "/encoder/layer.9/attention/self/key/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.029980653896927834
  zero_point: 130
  minval: -3.8974850177764893
  maxval: 3.747581720352173
}
, input: "/encoder/layer.9/attention/self/key/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.9/attention/self/Reshape_output_0:0"
name: "/encoder/layer.9/attention/self/Reshape"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.029980653896927834
  zero_point: 130
  minval: -3.8974850177764893
  maxval: 3.747581720352173
}
, input: "/encoder/layer.9/attention/self/Reshape_output_0"
output: "/encoder/layer.9/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.9/attention/self/Transpose_2"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
quantize_info {
  scale: 0.029980653896927834
  zero_point: 130
  minval: -3.8974850177764893
  maxval: 3.747581720352173
}
, input: "/encoder/layer.9/attention/self/Transpose_1_output_0"
input: "/encoder/layer.9/attention/self/Transpose_2_output_0"
output: "/encoder/layer.9/attention/self/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.34506726264953613
  zero_point: 100
  minval: -34.5067253112793
  maxval: 53.48542404174805
}
, input: "/encoder/layer.9/attention/self/MatMul_output_0"
output: "/encoder/layer.9/attention/self/Div_output_0:0"
name: "/encoder/layer.9/attention/self/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.043133411556482315
  zero_point: 100
  minval: -4.31334114074707
  maxval: 6.685678482055664
}
, input: "/encoder/layer.9/attention/self/Div_output_0"
input: "/Mul_output_0"
output: "/encoder/layer.9/attention/self/Add_output_0:0"
name: "/encoder/layer.9/attention/self/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
, input: "/encoder/layer.9/attention/self/Add_output_0"
output: "/encoder/layer.9/attention/self/Softmax_output_0:0"
name: "/encoder/layer.9/attention/self/Softmax"
type: "Softmax"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
, input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1557"
output: "/encoder/layer.9/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.022493071854114532
  zero_point: 110
  minval: -2.4742379188537598
  maxval: 3.261495590209961
}
, input: "encoder.layer.9.attention.self.value.bias"
input: "/encoder/layer.9/attention/self/value/MatMul_output_0"
output: "/encoder/layer.9/attention/self/value/Add_output_0:0"
name: "/encoder/layer.9/attention/self/value/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.023025354370474815
  zero_point: 108
  minval: -2.4867382049560547
  maxval: 3.3847270011901855
}
, input: "/encoder/layer.9/attention/self/value/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.9/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.9/attention/self/Reshape_1"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.023025354370474815
  zero_point: 108
  minval: -2.4867382049560547
  maxval: 3.3847270011901855
}
, input: "/encoder/layer.9/attention/self/Reshape_1_output_0"
output: "/encoder/layer.9/attention/self/Transpose_output_0:0"
name: "/encoder/layer.9/attention/self/Transpose"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.023025354370474815
  zero_point: 108
  minval: -2.4867382049560547
  maxval: 3.3847270011901855
}
, input: "/encoder/layer.9/attention/self/Softmax_output_0"
input: "/encoder/layer.9/attention/self/Transpose_output_0"
output: "/encoder/layer.9/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.9/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.01358900684863329
  zero_point: 106
  minval: -1.4404346942901611
  maxval: 2.024761915206909
}
, input: "/encoder/layer.9/attention/self/MatMul_1_output_0"
output: "/encoder/layer.9/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.9/attention/self/Transpose_3"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.01358900684863329
  zero_point: 106
  minval: -1.4404346942901611
  maxval: 2.024761915206909
}
, input: "/encoder/layer.9/attention/self/Transpose_3_output_0"
input: "/encoder/layer.0/attention/self/Constant_4_output_0"
output: "/encoder/layer.9/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.9/attention/self/Reshape_3"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.01358900684863329
  zero_point: 106
  minval: -1.4404346942901611
  maxval: 2.024761915206909
}
, input: "/encoder/layer.9/attention/self/Reshape_3_output_0"
input: "onnx::MatMul_1572"
output: "/encoder/layer.9/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.9/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.010727767832577229
  zero_point: 125
  minval: -1.3409709930419922
  maxval: 1.394609808921814
}
, input: "encoder.layer.9.attention.output.dense.bias"
input: "/encoder/layer.9/attention/output/dense/MatMul_output_0"
output: "/encoder/layer.9/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.9/attention/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.010656259953975677
  zero_point: 128
  minval: -1.3640012741088867
  maxval: 1.3533450365066528
}
, input: "/encoder/layer.9/attention/output/dense/Add_output_0"
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.9/attention/output/Add_output_0:0"
name: "/encoder/layer.9/attention/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07457316666841507
  zero_point: 214
  minval: -15.958657264709473
  maxval: 3.057499647140503
}
, input: "/encoder/layer.9/attention/output/Add_output_0"
output: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0001346705830655992
  zero_point: 255
  minval: -0.034341000020504
  maxval: 0.0
}
, input: "/encoder/layer.9/attention/output/Add_output_0"
input: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.9/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07447197288274765
  zero_point: 214
  minval: -15.937003135681152
  maxval: 3.0533509254455566
}
, input: "/encoder/layer.9/attention/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.9/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.9944464564323425
  zero_point: 0
  minval: 0.0
  maxval: 253.58384704589844
}
, input: "/encoder/layer.9/attention/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.003626580350100994
  zero_point: 0
  minval: 0.0
  maxval: 0.9247779846191406
}
, input: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.9/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.003626580350100994
  zero_point: 0
  minval: 0.0
  maxval: 0.9247779846191406
}
, input: "/encoder/layer.9/attention/output/LayerNorm/Add_output_0"
output: "/encoder/layer.9/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0037711921613663435
  zero_point: 0
  minval: 0.0
  maxval: 0.961654007434845
}
, input: "/encoder/layer.9/attention/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.9/attention/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.9/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07781985402107239
  zero_point: 213
  minval: -16.57563018798828
  maxval: 3.2684340476989746
}
, input: "/encoder/layer.9/attention/output/LayerNorm/Div_output_0"
input: "encoder.layer.9.attention.output.LayerNorm.weight"
output: "/encoder/layer.9/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.12420880794525146
  zero_point: 234
  minval: -29.064861297607422
  maxval: 2.608384847640991
}
, input: "/encoder/layer.9/attention/output/LayerNorm/Mul_output_0"
input: "encoder.layer.9.attention.output.LayerNorm.bias"
output: "/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.1305486261844635
  zero_point: 234
  minval: -30.54837989807129
  maxval: 2.7415213584899902
}
, input: "/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1573"
output: "/encoder/layer.9/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.9/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.07669970393180847
  zero_point: 218
  minval: -16.720535278320312
  maxval: 2.8378889560699463
}
, input: "/encoder/layer.9/intermediate/dense/MatMul_output_0"
output: "/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1"
type: "Activation"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.010867472738027573
  zero_point: 16
  minval: -0.17387956380844116
  maxval: 2.5973260402679443
}
, input: "/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1_output_0"
input: "onnx::MatMul_1574"
output: "/encoder/layer.9/output/dense/MatMul_output_0:0"
name: "/encoder/layer.9/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.10220877826213837
  zero_point: 155
  minval: -15.842361450195312
  maxval: 10.220877647399902
}
, input: "encoder.layer.9.output.dense.bias"
input: "/encoder/layer.9/output/dense/MatMul_output_0"
output: "/encoder/layer.9/output/dense/Add_output_0:0"
name: "/encoder/layer.9/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.1061997264623642
  zero_point: 156
  minval: -16.567157745361328
  maxval: 10.513772964477539
}
, input: "/encoder/layer.9/output/dense/Add_output_0"
input: "/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.9/output/Add_output_0:0"
name: "/encoder/layer.9/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.1955433040857315
  zero_point: 191
  minval: -37.34877014160156
  maxval: 12.514771461486816
}
, input: "/encoder/layer.9/output/Add_output_0"
output: "/encoder/layer.9/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0003437490086071193
  zero_point: 255
  minval: -0.08765599876642227
  maxval: 0.0
}
, input: "/encoder/layer.9/output/Add_output_0"
input: "/encoder/layer.9/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.9/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.1950843632221222
  zero_point: 191
  minval: -37.261112213134766
  maxval: 12.48539924621582
}
, input: "/encoder/layer.9/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.9/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 5.444668769836426
  zero_point: 0
  minval: 0.0
  maxval: 1388.3905029296875
}
, input: "/encoder/layer.9/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.9/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.012891761027276516
  zero_point: 0
  minval: 0.0
  maxval: 3.2873990535736084
}
, input: "/encoder/layer.9/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.9/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.012891761027276516
  zero_point: 0
  minval: 0.0
  maxval: 3.2873990535736084
}
, input: "/encoder/layer.9/output/LayerNorm/Add_output_0"
output: "/encoder/layer.9/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.007110270671546459
  zero_point: 0
  minval: 0.0
  maxval: 1.8131190538406372
}
, input: "/encoder/layer.9/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.9/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.9/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.1075960323214531
  zero_point: 191
  minval: -20.55084228515625
  maxval: 6.886146068572998
}
, input: "/encoder/layer.9/output/LayerNorm/Div_output_0"
input: "encoder.layer.9.output.LayerNorm.weight"
output: "/encoder/layer.9/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07400540262460709
  zero_point: 220
  minval: -16.28118896484375
  maxval: 2.590189218521118
}
, input: "/encoder/layer.9/output/LayerNorm/Mul_output_0"
input: "encoder.layer.9.output.LayerNorm.bias"
output: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07520761340856552
  zero_point: 222
  minval: -16.696090698242188
  maxval: 2.48185133934021
}
, input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1575"
output: "/encoder/layer.10/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.035721272230148315
  zero_point: 147
  minval: -5.2510271072387695
  maxval: 3.8578972816467285
}
, input: "encoder.layer.10.attention.self.query.bias"
input: "/encoder/layer.10/attention/self/query/MatMul_output_0"
output: "/encoder/layer.10/attention/self/query/Add_output_0:0"
name: "/encoder/layer.10/attention/self/query/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03757181391119957
  zero_point: 147
  minval: -5.523056983947754
  maxval: 4.057755947113037
}
, input: "/encoder/layer.10/attention/self/query/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.10/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.10/attention/self/Reshape_2"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.03757181391119957
  zero_point: 147
  minval: -5.523056983947754
  maxval: 4.057755947113037
}
, input: "/encoder/layer.10/attention/self/Reshape_2_output_0"
output: "/encoder/layer.10/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.10/attention/self/Transpose_1"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.03757181391119957
  zero_point: 147
  minval: -5.523056983947754
  maxval: 4.057755947113037
}
, input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1576"
output: "/encoder/layer.10/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03174690157175064
  zero_point: 120
  minval: -3.8096280097961426
  maxval: 4.285831451416016
}
, input: "encoder.layer.10.attention.self.key.bias"
input: "/encoder/layer.10/attention/self/key/MatMul_output_0"
output: "/encoder/layer.10/attention/self/key/Add_output_0:0"
name: "/encoder/layer.10/attention/self/key/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.031860560178756714
  zero_point: 120
  minval: -3.8232669830322266
  maxval: 4.301175594329834
}
, input: "/encoder/layer.10/attention/self/key/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.10/attention/self/Reshape_output_0:0"
name: "/encoder/layer.10/attention/self/Reshape"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.031860560178756714
  zero_point: 120
  minval: -3.8232669830322266
  maxval: 4.301175594329834
}
, input: "/encoder/layer.10/attention/self/Reshape_output_0"
output: "/encoder/layer.10/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.10/attention/self/Transpose_2"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
quantize_info {
  scale: 0.031860560178756714
  zero_point: 120
  minval: -3.8232669830322266
  maxval: 4.301175594329834
}
, input: "/encoder/layer.10/attention/self/Transpose_1_output_0"
input: "/encoder/layer.10/attention/self/Transpose_2_output_0"
output: "/encoder/layer.10/attention/self/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.37985730171203613
  zero_point: 164
  minval: -62.29659652709961
  maxval: 34.567012786865234
}
, input: "/encoder/layer.10/attention/self/MatMul_output_0"
output: "/encoder/layer.10/attention/self/Div_output_0:0"
name: "/encoder/layer.10/attention/self/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.047482166439294815
  zero_point: 164
  minval: -7.787075042724609
  maxval: 4.3208770751953125
}
, input: "/encoder/layer.10/attention/self/Div_output_0"
input: "/Mul_output_0"
output: "/encoder/layer.10/attention/self/Add_output_0:0"
name: "/encoder/layer.10/attention/self/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
, input: "/encoder/layer.10/attention/self/Add_output_0"
output: "/encoder/layer.10/attention/self/Softmax_output_0:0"
name: "/encoder/layer.10/attention/self/Softmax"
type: "Softmax"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
, input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1582"
output: "/encoder/layer.10/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.018686113879084587
  zero_point: 140
  minval: -2.616055965423584
  maxval: 2.1489031314849854
}
, input: "encoder.layer.10.attention.self.value.bias"
input: "/encoder/layer.10/attention/self/value/MatMul_output_0"
output: "/encoder/layer.10/attention/self/value/Add_output_0:0"
name: "/encoder/layer.10/attention/self/value/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.01952427253127098
  zero_point: 136
  minval: -2.655301094055176
  maxval: 2.3233883380889893
}
, input: "/encoder/layer.10/attention/self/value/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.10/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.10/attention/self/Reshape_1"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.01952427253127098
  zero_point: 136
  minval: -2.655301094055176
  maxval: 2.3233883380889893
}
, input: "/encoder/layer.10/attention/self/Reshape_1_output_0"
output: "/encoder/layer.10/attention/self/Transpose_output_0:0"
name: "/encoder/layer.10/attention/self/Transpose"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.01952427253127098
  zero_point: 136
  minval: -2.655301094055176
  maxval: 2.3233883380889893
}
, input: "/encoder/layer.10/attention/self/Softmax_output_0"
input: "/encoder/layer.10/attention/self/Transpose_output_0"
output: "/encoder/layer.10/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.10/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.013253866694867611
  zero_point: 120
  minval: -1.5904639959335327
  maxval: 1.7892719507217407
}
, input: "/encoder/layer.10/attention/self/MatMul_1_output_0"
output: "/encoder/layer.10/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.10/attention/self/Transpose_3"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.013253866694867611
  zero_point: 120
  minval: -1.5904639959335327
  maxval: 1.7892719507217407
}
, input: "/encoder/layer.10/attention/self/Transpose_3_output_0"
input: "/encoder/layer.0/attention/self/Constant_4_output_0"
output: "/encoder/layer.10/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.10/attention/self/Reshape_3"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.013253866694867611
  zero_point: 120
  minval: -1.5904639959335327
  maxval: 1.7892719507217407
}
, input: "/encoder/layer.10/attention/self/Reshape_3_output_0"
input: "onnx::MatMul_1597"
output: "/encoder/layer.10/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.10/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.011150236241519451
  zero_point: 127
  minval: -1.4160799980163574
  maxval: 1.4272302389144897
}
, input: "encoder.layer.10.attention.output.dense.bias"
input: "/encoder/layer.10/attention/output/dense/MatMul_output_0"
output: "/encoder/layer.10/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.10/attention/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.010908850468695164
  zero_point: 127
  minval: -1.385424017906189
  maxval: 1.396332859992981
}
, input: "/encoder/layer.10/attention/output/dense/Add_output_0"
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.10/attention/output/Add_output_0:0"
name: "/encoder/layer.10/attention/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07651827484369278
  zero_point: 215
  minval: -16.45142936706543
  maxval: 3.0607309341430664
}
, input: "/encoder/layer.10/attention/output/Add_output_0"
output: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.00012767451698891819
  zero_point: 255
  minval: -0.03255699947476387
  maxval: 0.0
}
, input: "/encoder/layer.10/attention/output/Add_output_0"
input: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.10/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07627394050359726
  zero_point: 215
  minval: -16.398897171020508
  maxval: 3.050957679748535
}
, input: "/encoder/layer.10/attention/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.10/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 1.0546032190322876
  zero_point: 0
  minval: 0.0
  maxval: 268.923828125
}
, input: "/encoder/layer.10/attention/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.004220109898597002
  zero_point: 0
  minval: 0.0
  maxval: 1.0761280059814453
}
, input: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.10/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.004220109898597002
  zero_point: 0
  minval: 0.0
  maxval: 1.0761280059814453
}
, input: "/encoder/layer.10/attention/output/LayerNorm/Add_output_0"
output: "/encoder/layer.10/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0040681017562747
  zero_point: 0
  minval: 0.0
  maxval: 1.0373660326004028
}
, input: "/encoder/layer.10/attention/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.10/attention/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.10/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07421695441007614
  zero_point: 213
  minval: -15.808212280273438
  maxval: 3.117112159729004
}
, input: "/encoder/layer.10/attention/output/LayerNorm/Div_output_0"
input: "encoder.layer.10.attention.output.LayerNorm.weight"
output: "/encoder/layer.10/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.12244266271591187
  zero_point: 224
  minval: -27.427156448364258
  maxval: 3.795722484588623
}
, input: "/encoder/layer.10/attention/output/LayerNorm/Mul_output_0"
input: "encoder.layer.10.attention.output.LayerNorm.bias"
output: "/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.13265176117420197
  zero_point: 221
  minval: -29.3160400390625
  maxval: 4.510159969329834
}
, input: "/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1598"
output: "/encoder/layer.10/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.10/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.14899571239948273
  zero_point: 63
  minval: -9.38672924041748
  maxval: 28.607175827026367
}
, input: "/encoder/layer.10/intermediate/dense/MatMul_output_0"
output: "/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1"
type: "Activation"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.11296462267637253
  zero_point: 2
  minval: -0.22592924535274506
  maxval: 28.580049514770508
}
, input: "/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1_output_0"
input: "onnx::MatMul_1599"
output: "/encoder/layer.10/output/dense/MatMul_output_0:0"
name: "/encoder/layer.10/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.8073998093605042
  zero_point: 248
  minval: -200.2351531982422
  maxval: 5.651798725128174
}
, input: "encoder.layer.10.output.dense.bias"
input: "/encoder/layer.10/output/dense/MatMul_output_0"
output: "/encoder/layer.10/output/dense/Add_output_0:0"
name: "/encoder/layer.10/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.8121053576469421
  zero_point: 248
  minval: -201.40213012695312
  maxval: 5.684737682342529
}
, input: "/encoder/layer.10/output/dense/Add_output_0"
input: "/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.10/output/Add_output_0:0"
name: "/encoder/layer.10/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.8471226096153259
  zero_point: 243
  minval: -205.85079956054688
  maxval: 10.165472030639648
}
, input: "/encoder/layer.10/output/Add_output_0"
output: "/encoder/layer.10/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0014954509679228067
  zero_point: 255
  minval: -0.38133999705314636
  maxval: 0.0
}
, input: "/encoder/layer.10/output/Add_output_0"
input: "/encoder/layer.10/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.10/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.8455533385276794
  zero_point: 243
  minval: -205.46946716308594
  maxval: 10.14664077758789
}
, input: "/encoder/layer.10/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.10/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 165.5596160888672
  zero_point: 0
  minval: 0.0
  maxval: 42217.703125
}
, input: "/encoder/layer.10/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.10/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.24165654182434082
  zero_point: 0
  minval: 0.0
  maxval: 61.62241744995117
}
, input: "/encoder/layer.10/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.10/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.24165654182434082
  zero_point: 0
  minval: 0.0
  maxval: 61.62241744995117
}
, input: "/encoder/layer.10/output/LayerNorm/Add_output_0"
output: "/encoder/layer.10/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.03078429400920868
  zero_point: 0
  minval: 0.0
  maxval: 7.849995136260986
}
, input: "/encoder/layer.10/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.10/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.10/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.11429900676012039
  zero_point: 229
  minval: -26.17447280883789
  maxval: 2.9717743396759033
}
, input: "/encoder/layer.10/output/LayerNorm/Div_output_0"
input: "encoder.layer.10.output.LayerNorm.weight"
output: "/encoder/layer.10/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07190462201833725
  zero_point: 222
  minval: -15.962825775146484
  maxval: 2.3728525638580322
}
, input: "/encoder/layer.10/output/LayerNorm/Mul_output_0"
input: "encoder.layer.10.output.LayerNorm.bias"
output: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07423636317253113
  zero_point: 224
  minval: -16.62894630432129
  maxval: 2.3013274669647217
}
, input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1600"
output: "/encoder/layer.11/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.027746092528104782
  zero_point: 131
  minval: -3.634737968444824
  maxval: 3.4405152797698975
}
, input: "encoder.layer.11.attention.self.query.bias"
input: "/encoder/layer.11/attention/self/query/MatMul_output_0"
output: "/encoder/layer.11/attention/self/query/Add_output_0:0"
name: "/encoder/layer.11/attention/self/query/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.028647832572460175
  zero_point: 126
  minval: -3.6096270084381104
  maxval: 3.695570468902588
}
, input: "/encoder/layer.11/attention/self/query/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.11/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.11/attention/self/Reshape_2"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.028647832572460175
  zero_point: 126
  minval: -3.6096270084381104
  maxval: 3.695570468902588
}
, input: "/encoder/layer.11/attention/self/Reshape_2_output_0"
output: "/encoder/layer.11/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.11/attention/self/Transpose_1"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.028647832572460175
  zero_point: 126
  minval: -3.6096270084381104
  maxval: 3.695570468902588
}
, input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1601"
output: "/encoder/layer.11/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.027924062684178352
  zero_point: 129
  minval: -3.6022040843963623
  maxval: 3.5184319019317627
}
, input: "encoder.layer.11.attention.self.key.bias"
input: "/encoder/layer.11/attention/self/key/MatMul_output_0"
output: "/encoder/layer.11/attention/self/key/Add_output_0:0"
name: "/encoder/layer.11/attention/self/key/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.027895448729395866
  zero_point: 129
  minval: -3.598512887954712
  maxval: 3.514826536178589
}
, input: "/encoder/layer.11/attention/self/key/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.11/attention/self/Reshape_output_0:0"
name: "/encoder/layer.11/attention/self/Reshape"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.027895448729395866
  zero_point: 129
  minval: -3.598512887954712
  maxval: 3.514826536178589
}
, input: "/encoder/layer.11/attention/self/Reshape_output_0"
output: "/encoder/layer.11/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.11/attention/self/Transpose_2"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
quantize_info {
  scale: 0.027895448729395866
  zero_point: 129
  minval: -3.598512887954712
  maxval: 3.514826536178589
}
, input: "/encoder/layer.11/attention/self/Transpose_1_output_0"
input: "/encoder/layer.11/attention/self/Transpose_2_output_0"
output: "/encoder/layer.11/attention/self/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.23882785439491272
  zero_point: 129
  minval: -30.808794021606445
  maxval: 30.092309951782227
}
, input: "/encoder/layer.11/attention/self/MatMul_output_0"
output: "/encoder/layer.11/attention/self/Div_output_0:0"
name: "/encoder/layer.11/attention/self/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.02985348366200924
  zero_point: 129
  minval: -3.8510994911193848
  maxval: 3.7615389823913574
}
, input: "/encoder/layer.11/attention/self/Div_output_0"
input: "/Mul_output_0"
output: "/encoder/layer.11/attention/self/Add_output_0:0"
name: "/encoder/layer.11/attention/self/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
, input: "/encoder/layer.11/attention/self/Add_output_0"
output: "/encoder/layer.11/attention/self/Softmax_output_0:0"
name: "/encoder/layer.11/attention/self/Softmax"
type: "Softmax"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
, input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1607"
output: "/encoder/layer.11/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.020123830065131187
  zero_point: 124
  minval: -2.4953548908233643
  maxval: 2.6362218856811523
}
, input: "encoder.layer.11.attention.self.value.bias"
input: "/encoder/layer.11/attention/self/value/MatMul_output_0"
output: "/encoder/layer.11/attention/self/value/Add_output_0:0"
name: "/encoder/layer.11/attention/self/value/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.01989193633198738
  zero_point: 124
  minval: -2.466599941253662
  maxval: 2.6058435440063477
}
, input: "/encoder/layer.11/attention/self/value/Add_output_0"
input: "/encoder/layer.0/attention/self/Constant_output_0"
output: "/encoder/layer.11/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.11/attention/self/Reshape_1"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.01989193633198738
  zero_point: 124
  minval: -2.466599941253662
  maxval: 2.6058435440063477
}
, input: "/encoder/layer.11/attention/self/Reshape_1_output_0"
output: "/encoder/layer.11/attention/self/Transpose_output_0:0"
name: "/encoder/layer.11/attention/self/Transpose"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.01989193633198738
  zero_point: 124
  minval: -2.466599941253662
  maxval: 2.6058435440063477
}
, input: "/encoder/layer.11/attention/self/Softmax_output_0"
input: "/encoder/layer.11/attention/self/Transpose_output_0"
output: "/encoder/layer.11/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.11/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.013856226578354836
  zero_point: 128
  minval: -1.773597002029419
  maxval: 1.7597408294677734
}
, input: "/encoder/layer.11/attention/self/MatMul_1_output_0"
output: "/encoder/layer.11/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.11/attention/self/Transpose_3"
type: "Transpose"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
quantize_info {
  scale: 0.013856226578354836
  zero_point: 128
  minval: -1.773597002029419
  maxval: 1.7597408294677734
}
, input: "/encoder/layer.11/attention/self/Transpose_3_output_0"
input: "/encoder/layer.0/attention/self/Constant_4_output_0"
output: "/encoder/layer.11/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.11/attention/self/Reshape_3"
type: "Reshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.013856226578354836
  zero_point: 128
  minval: -1.773597002029419
  maxval: 1.7597408294677734
}
, input: "/encoder/layer.11/attention/self/Reshape_3_output_0"
input: "onnx::MatMul_1622"
output: "/encoder/layer.11/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.11/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.013555709272623062
  zero_point: 124
  minval: -1.680907964706421
  maxval: 1.775797963142395
}
, input: "encoder.layer.11.attention.output.dense.bias"
input: "/encoder/layer.11/attention/output/dense/MatMul_output_0"
output: "/encoder/layer.11/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.11/attention/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.01359746977686882
  zero_point: 121
  minval: -1.6452938318252563
  maxval: 1.8220609426498413
}
, input: "/encoder/layer.11/attention/output/dense/Add_output_0"
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.11/attention/output/Add_output_0:0"
name: "/encoder/layer.11/attention/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.08329323679208755
  zero_point: 218
  minval: -18.15792465209961
  maxval: 3.0818495750427246
}
, input: "/encoder/layer.11/attention/output/Add_output_0"
output: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.00014256470603868365
  zero_point: 255
  minval: -0.036354001611471176
  maxval: 0.0
}
, input: "/encoder/layer.11/attention/output/Add_output_0"
input: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.11/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.08313101530075073
  zero_point: 218
  minval: -18.122560501098633
  maxval: 3.075847625732422
}
, input: "/encoder/layer.11/attention/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.11/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 1.287949800491333
  zero_point: 0
  minval: 0.0
  maxval: 328.42718505859375
}
, input: "/encoder/layer.11/attention/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.00558821577578783
  zero_point: 0
  minval: 0.0
  maxval: 1.424994945526123
}
, input: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.11/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.00558821577578783
  zero_point: 0
  minval: 0.0
  maxval: 1.424994945526123
}
, input: "/encoder/layer.11/attention/output/LayerNorm/Add_output_0"
output: "/encoder/layer.11/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.004681298043578863
  zero_point: 0
  minval: 0.0
  maxval: 1.1937309503555298
}
, input: "/encoder/layer.11/attention/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.11/attention/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.11/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07127435505390167
  zero_point: 213
  minval: -15.181438446044922
  maxval: 2.993522882461548
}
, input: "/encoder/layer.11/attention/output/LayerNorm/Div_output_0"
input: "encoder.layer.11.attention.output.LayerNorm.weight"
output: "/encoder/layer.11/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.10579519718885422
  zero_point: 231
  minval: -24.438690185546875
  maxval: 2.5390846729278564
}
, input: "/encoder/layer.11/attention/output/LayerNorm/Mul_output_0"
input: "encoder.layer.11.attention.output.LayerNorm.bias"
output: "/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.11408033967018127
  zero_point: 234
  minval: -26.694799423217773
  maxval: 2.3956871032714844
}
, input: "/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0"
input: "onnx::MatMul_1623"
output: "/encoder/layer.11/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.11/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.031074268743395805
  zero_point: 125
  minval: -3.8842835426330566
  maxval: 4.0396552085876465
}
, input: "/encoder/layer.11/intermediate/dense/MatMul_output_0"
output: "/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1"
type: "Activation"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.01545190904289484
  zero_point: 11
  minval: -0.16997100412845612
  maxval: 3.770265817642212
}
, input: "/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1_output_0"
input: "onnx::MatMul_1624"
output: "/encoder/layer.11/output/dense/MatMul_output_0:0"
name: "/encoder/layer.11/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.044259894639253616
  zero_point: 172
  minval: -7.612701892852783
  maxval: 3.6735713481903076
}
, input: "encoder.layer.11.output.dense.bias"
input: "/encoder/layer.11/output/dense/MatMul_output_0"
output: "/encoder/layer.11/output/dense/Add_output_0:0"
name: "/encoder/layer.11/output/dense/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.044334687292575836
  zero_point: 176
  minval: -7.802905082702637
  maxval: 3.5024402141571045
}
, input: "/encoder/layer.11/output/dense/Add_output_0"
input: "/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0"
output: "/encoder/layer.11/output/Add_output_0:0"
name: "/encoder/layer.11/output/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.1198514774441719
  zero_point: 225
  minval: -26.966583251953125
  maxval: 3.5955443382263184
}
, input: "/encoder/layer.11/output/Add_output_0"
output: "/encoder/layer.11/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.11/output/LayerNorm/ReduceMean"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.0002673058770596981
  zero_point: 255
  minval: -0.06816300004720688
  maxval: 0.0
}
, input: "/encoder/layer.11/output/Add_output_0"
input: "/encoder/layer.11/output/LayerNorm/ReduceMean_output_0"
output: "/encoder/layer.11/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.11/output/LayerNorm/Sub"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.11954853683710098
  zero_point: 225
  minval: -26.898420333862305
  maxval: 3.586456060409546
}
, input: "/encoder/layer.11/output/LayerNorm/Sub_output_0"
output: "/encoder/layer.11/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.11/output/LayerNorm/Pow"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 2.837352991104126
  zero_point: 0
  minval: 0.0
  maxval: 723.5250244140625
}
, input: "/encoder/layer.11/output/LayerNorm/Pow_output_0"
output: "/encoder/layer.11/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.11/output/LayerNorm/ReduceMean_1"
type: "Reduce"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.007044729311019182
  zero_point: 0
  minval: 0.0
  maxval: 1.7964060306549072
}
, input: "/encoder/layer.11/output/LayerNorm/ReduceMean_1_output_0"
output: "/encoder/layer.11/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.11/output/LayerNorm/Add"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.007044729311019182
  zero_point: 0
  minval: 0.0
  maxval: 1.7964060306549072
}
, input: "/encoder/layer.11/output/LayerNorm/Add_output_0"
output: "/encoder/layer.11/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.11/output/LayerNorm/Sqrt"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
quantize_info {
  scale: 0.005256082396954298
  zero_point: 0
  minval: 0.0
  maxval: 1.3403010368347168
}
, input: "/encoder/layer.11/output/LayerNorm/Sub_output_0"
input: "/encoder/layer.11/output/LayerNorm/Sqrt_output_0"
output: "/encoder/layer.11/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.11/output/LayerNorm/Div"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.09080971777439117
  zero_point: 221
  minval: -20.068946838378906
  maxval: 3.0875303745269775
}
, input: "/encoder/layer.11/output/LayerNorm/Div_output_0"
input: "encoder.layer.11.output.LayerNorm.weight"
output: "/encoder/layer.11/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.11/output/LayerNorm/Mul"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.028795626014471054
  zero_point: 190
  minval: -5.4711689949035645
  maxval: 1.8717156648635864
}
, input: "/encoder/layer.11/output/LayerNorm/Mul_output_0"
input: "encoder.layer.11.output.LayerNorm.bias"
output: "mace_output_node_last_hidden_state:0"
name: "mace_output_node_/encoder/layer.11/output/LayerNorm/Add_1"
type: "Eltwise"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.028129352256655693
  zero_point: 187
  minval: -5.260189056396484
  maxval: 1.9127960205078125
}
, input: "mace_output_node_last_hidden_state"
output: "last_hidden_state:0"
name: "last_hidden_state"
type: "Dequantize"
arg {
  name: "T"
  i: 2
}
arg {
  name: "data_format"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_type: DT_FLOAT
, input: "mace_output_node_last_hidden_state"
input: "/Constant_output_0"
output: "/pooler/Gather_output_0:0"
name: "/pooler/Gather"
type: "Gather"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 1
}
output_shape {
  dims: 1
  dims: 1
  dims: 768
}
quantize_info {
  scale: 0.025098640471696854
  zero_point: 209
  minval: -5.2456159591674805
  maxval: 1.1545374393463135
}
, input: "/pooler/Gather_output_0"
input: "pooler.dense.weight"
input: "pooler.dense.bias"
output: "/pooler/dense/Gemm_output_0:0"
name: "/pooler/dense/Gemm"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "transpose_a"
  i: 0
}
arg {
  name: "transpose_b"
  i: 1
}
output_shape {
  dims: 1
  dims: 768
}
quantize_info {
  scale: 0.02376180700957775
  zero_point: 124
  minval: -2.9464640617370605
  maxval: 3.1127965450286865
}
, input: "/pooler/dense/Gemm_output_0"
output: "mace_output_node_pooler_output:0"
name: "mace_output_node_/pooler/activation/Tanh"
type: "Activation"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "activation"
  s: "TANH"
}
arg {
  name: "activation_coefficient"
  f: 0.0
}
output_shape {
  dims: 1
  dims: 768
}
quantize_info {
  scale: 0.0078125
  zero_point: 128
  minval: -1.0
  maxval: 0.9921875
}
, input: "mace_output_node_pooler_output"
output: "pooler_output:0"
name: "pooler_output"
type: "Dequantize"
arg {
  name: "T"
  i: 2
}
arg {
  name: "data_format"
  i: 0
}
output_shape {
  dims: 1
  dims: 768
}
output_type: DT_FLOAT
]
this is op:
input: "/embeddings/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1325"
output: "/encoder/layer.0/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03517516702413559
  zero_point: 127
  minval: -4.467246055603027
  maxval: 4.5024213790893555
}

this is gemm op:
input: "/embeddings/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1325"
output: "/encoder/layer.0/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03517516702413559
  zero_point: 127
  minval: -4.467246055603027
  maxval: 4.5024213790893555
}

this is gemm requantize_op:
input: "/encoder/layer.0/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.0/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.0/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.0/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.0/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.0/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03517516702413559
  zero_point: 127
  minval: -4.467246055603027
  maxval: 4.5024213790893555
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/embeddings/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1326"
output: "/encoder/layer.0/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03920615836977959
  zero_point: 132
  minval: -5.175212860107422
  maxval: 4.822357654571533
}

this is gemm op:
input: "/embeddings/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1326"
output: "/encoder/layer.0/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03920615836977959
  zero_point: 132
  minval: -5.175212860107422
  maxval: 4.822357654571533
}

this is gemm requantize_op:
input: "/encoder/layer.0/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.0/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.0/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.0/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.0/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.0/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03920615836977959
  zero_point: 132
  minval: -5.175212860107422
  maxval: 4.822357654571533
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.0/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.0/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.0/attention/self/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.4610340893268585
  zero_point: 73
  minval: -33.655487060546875
  maxval: 83.908203125
}

this is gemm op:
input: "/encoder/layer.0/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.0/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.0/attention/self/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.4610340893268585
  zero_point: 73
  minval: -33.655487060546875
  maxval: 83.908203125
}

this is gemm requantize_op:
input: "/encoder/layer.0/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.0/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.0/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.0/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.0/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.0/attention/self/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.4610340893268585
  zero_point: 73
  minval: -33.655487060546875
  maxval: 83.908203125
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/embeddings/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1332"
output: "/encoder/layer.0/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.020430883392691612
  zero_point: 129
  minval: -2.6355841159820557
  maxval: 2.574291467666626
}

this is gemm op:
input: "/embeddings/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1332"
output: "/encoder/layer.0/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.020430883392691612
  zero_point: 129
  minval: -2.6355841159820557
  maxval: 2.574291467666626
}

this is gemm requantize_op:
input: "/encoder/layer.0/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.0/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.0/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.0/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.0/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.0/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.020430883392691612
  zero_point: 129
  minval: -2.6355841159820557
  maxval: 2.574291467666626
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.0/attention/self/Softmax_output_0:0"
input: "/encoder/layer.0/attention/self/Transpose_output_0:0"
output: "/encoder/layer.0/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.0/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.010315447114408016
  zero_point: 105
  minval: -1.0831218957901
  maxval: 1.5473170280456543
}

this is gemm op:
input: "/encoder/layer.0/attention/self/Softmax_output_0:0"
input: "/encoder/layer.0/attention/self/Transpose_output_0:0"
output: "/encoder/layer.0/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.0/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.010315447114408016
  zero_point: 105
  minval: -1.0831218957901
  maxval: 1.5473170280456543
}

this is gemm requantize_op:
input: "/encoder/layer.0/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.0/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.0/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.0/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.0/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.0/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.0/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010315447114408016
  zero_point: 105
  minval: -1.0831218957901
  maxval: 1.5473170280456543
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 768]
this is op:
input: "/encoder/layer.0/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1347"
output: "/encoder/layer.0/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.0/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.009964870288968086
  zero_point: 132
  minval: -1.315362811088562
  maxval: 1.2256790399551392
}

this is gemm op:
input: "/encoder/layer.0/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1347"
output: "/encoder/layer.0/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.0/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.009964870288968086
  zero_point: 132
  minval: -1.315362811088562
  maxval: 1.2256790399551392
}

this is gemm requantize_op:
input: "/encoder/layer.0/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.0/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.0/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.0/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.0/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.0/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.0/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.009964870288968086
  zero_point: 132
  minval: -1.315362811088562
  maxval: 1.2256790399551392
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1348"
output: "/encoder/layer.0/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.0/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.10121992975473404
  zero_point: 167
  minval: -16.903728485107422
  maxval: 8.907354354858398
}

this is gemm op:
input: "/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1348"
output: "/encoder/layer.0/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.0/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.10121992975473404
  zero_point: 167
  minval: -16.903728485107422
  maxval: 8.907354354858398
}

this is gemm requantize_op:
input: "/encoder/layer.0/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.0/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.0/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.0/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.0/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.0/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.0/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.10121992975473404
  zero_point: 167
  minval: -16.903728485107422
  maxval: 8.907354354858398
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1349"
output: "/encoder/layer.0/output/dense/MatMul_output_0:0"
name: "/encoder/layer.0/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06505445390939713
  zero_point: 218
  minval: -14.18187141418457
  maxval: 2.407014846801758
}

this is gemm op:
input: "/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1349"
output: "/encoder/layer.0/output/dense/MatMul_output_0:0"
name: "/encoder/layer.0/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.06505445390939713
  zero_point: 218
  minval: -14.18187141418457
  maxval: 2.407014846801758
}

this is gemm requantize_op:
input: "/encoder/layer.0/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.0/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.0/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.0/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.0/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.0/output/dense/MatMul_output_0:0"
name: "/encoder/layer.0/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06505445390939713
  zero_point: 218
  minval: -14.18187141418457
  maxval: 2.407014846801758
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1350"
output: "/encoder/layer.1/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.036228954792022705
  zero_point: 133
  minval: -4.818450927734375
  maxval: 4.4199323654174805
}

this is gemm op:
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1350"
output: "/encoder/layer.1/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.036228954792022705
  zero_point: 133
  minval: -4.818450927734375
  maxval: 4.4199323654174805
}

this is gemm requantize_op:
input: "/encoder/layer.1/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.1/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.1/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.1/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.1/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.1/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.036228954792022705
  zero_point: 133
  minval: -4.818450927734375
  maxval: 4.4199323654174805
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1351"
output: "/encoder/layer.1/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.041271936148405075
  zero_point: 129
  minval: -5.324079990386963
  maxval: 5.200263977050781
}

this is gemm op:
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1351"
output: "/encoder/layer.1/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.041271936148405075
  zero_point: 129
  minval: -5.324079990386963
  maxval: 5.200263977050781
}

this is gemm requantize_op:
input: "/encoder/layer.1/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.1/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.1/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.1/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.1/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.1/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.041271936148405075
  zero_point: 129
  minval: -5.324079990386963
  maxval: 5.200263977050781
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.1/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.1/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.1/attention/self/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.5172810554504395
  zero_point: 75
  minval: -38.796077728271484
  maxval: 93.11058807373047
}

this is gemm op:
input: "/encoder/layer.1/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.1/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.1/attention/self/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.5172810554504395
  zero_point: 75
  minval: -38.796077728271484
  maxval: 93.11058807373047
}

this is gemm requantize_op:
input: "/encoder/layer.1/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.1/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.1/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.1/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.1/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.1/attention/self/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.5172810554504395
  zero_point: 75
  minval: -38.796077728271484
  maxval: 93.11058807373047
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1357"
output: "/encoder/layer.1/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.01952419988811016
  zero_point: 115
  minval: -2.2452828884124756
  maxval: 2.7333879470825195
}

this is gemm op:
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1357"
output: "/encoder/layer.1/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.01952419988811016
  zero_point: 115
  minval: -2.2452828884124756
  maxval: 2.7333879470825195
}

this is gemm requantize_op:
input: "/encoder/layer.1/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.1/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.1/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.1/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.1/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.1/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01952419988811016
  zero_point: 115
  minval: -2.2452828884124756
  maxval: 2.7333879470825195
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.1/attention/self/Softmax_output_0:0"
input: "/encoder/layer.1/attention/self/Transpose_output_0:0"
output: "/encoder/layer.1/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.1/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.011402285657823086
  zero_point: 122
  minval: -1.3910788297653198
  maxval: 1.5165040493011475
}

this is gemm op:
input: "/encoder/layer.1/attention/self/Softmax_output_0:0"
input: "/encoder/layer.1/attention/self/Transpose_output_0:0"
output: "/encoder/layer.1/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.1/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.011402285657823086
  zero_point: 122
  minval: -1.3910788297653198
  maxval: 1.5165040493011475
}

this is gemm requantize_op:
input: "/encoder/layer.1/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.1/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.1/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.1/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.1/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.1/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.1/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.011402285657823086
  zero_point: 122
  minval: -1.3910788297653198
  maxval: 1.5165040493011475
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 768]
this is op:
input: "/encoder/layer.1/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1372"
output: "/encoder/layer.1/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.1/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.008185404352843761
  zero_point: 104
  minval: -0.851282000541687
  maxval: 1.2359960079193115
}

this is gemm op:
input: "/encoder/layer.1/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1372"
output: "/encoder/layer.1/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.1/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.008185404352843761
  zero_point: 104
  minval: -0.851282000541687
  maxval: 1.2359960079193115
}

this is gemm requantize_op:
input: "/encoder/layer.1/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.1/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.1/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.1/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.1/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.1/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.1/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.008185404352843761
  zero_point: 104
  minval: -0.851282000541687
  maxval: 1.2359960079193115
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1373"
output: "/encoder/layer.1/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.1/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.08946271240711212
  zero_point: 164
  minval: -14.671884536743164
  maxval: 8.141106605529785
}

this is gemm op:
input: "/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1373"
output: "/encoder/layer.1/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.1/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.08946271240711212
  zero_point: 164
  minval: -14.671884536743164
  maxval: 8.141106605529785
}

this is gemm requantize_op:
input: "/encoder/layer.1/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.1/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.1/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.1/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.1/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.1/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.1/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.08946271240711212
  zero_point: 164
  minval: -14.671884536743164
  maxval: 8.141106605529785
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1374"
output: "/encoder/layer.1/output/dense/MatMul_output_0:0"
name: "/encoder/layer.1/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.069577157497406
  zero_point: 217
  minval: -15.09824275970459
  maxval: 2.6439318656921387
}

this is gemm op:
input: "/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1374"
output: "/encoder/layer.1/output/dense/MatMul_output_0:0"
name: "/encoder/layer.1/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.069577157497406
  zero_point: 217
  minval: -15.09824275970459
  maxval: 2.6439318656921387
}

this is gemm requantize_op:
input: "/encoder/layer.1/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.1/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.1/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.1/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.1/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.1/output/dense/MatMul_output_0:0"
name: "/encoder/layer.1/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.069577157497406
  zero_point: 217
  minval: -15.09824275970459
  maxval: 2.6439318656921387
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1375"
output: "/encoder/layer.2/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04154577851295471
  zero_point: 138
  minval: -5.7333173751831055
  maxval: 4.860856056213379
}

this is gemm op:
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1375"
output: "/encoder/layer.2/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04154577851295471
  zero_point: 138
  minval: -5.7333173751831055
  maxval: 4.860856056213379
}

this is gemm requantize_op:
input: "/encoder/layer.2/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.2/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.2/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.2/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.2/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.2/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04154577851295471
  zero_point: 138
  minval: -5.7333173751831055
  maxval: 4.860856056213379
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1376"
output: "/encoder/layer.2/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04573328047990799
  zero_point: 138
  minval: -6.311192989349365
  maxval: 5.350793838500977
}

this is gemm op:
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1376"
output: "/encoder/layer.2/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04573328047990799
  zero_point: 138
  minval: -6.311192989349365
  maxval: 5.350793838500977
}

this is gemm requantize_op:
input: "/encoder/layer.2/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.2/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.2/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.2/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.2/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.2/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04573328047990799
  zero_point: 138
  minval: -6.311192989349365
  maxval: 5.350793838500977
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.2/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.2/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.2/attention/self/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.5811166763305664
  zero_point: 59
  minval: -34.285884857177734
  maxval: 113.89887237548828
}

this is gemm op:
input: "/encoder/layer.2/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.2/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.2/attention/self/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.5811166763305664
  zero_point: 59
  minval: -34.285884857177734
  maxval: 113.89887237548828
}

this is gemm requantize_op:
input: "/encoder/layer.2/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.2/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.2/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.2/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.2/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.2/attention/self/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.5811166763305664
  zero_point: 59
  minval: -34.285884857177734
  maxval: 113.89887237548828
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1382"
output: "/encoder/layer.2/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.018187351524829865
  zero_point: 124
  minval: -2.2552316188812256
  maxval: 2.3825430870056152
}

this is gemm op:
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1382"
output: "/encoder/layer.2/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.018187351524829865
  zero_point: 124
  minval: -2.2552316188812256
  maxval: 2.3825430870056152
}

this is gemm requantize_op:
input: "/encoder/layer.2/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.2/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.2/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.2/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.2/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.2/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018187351524829865
  zero_point: 124
  minval: -2.2552316188812256
  maxval: 2.3825430870056152
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.2/attention/self/Softmax_output_0:0"
input: "/encoder/layer.2/attention/self/Transpose_output_0:0"
output: "/encoder/layer.2/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.2/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.00788026675581932
  zero_point: 105
  minval: -0.8274279832839966
  maxval: 1.1820399761199951
}

this is gemm op:
input: "/encoder/layer.2/attention/self/Softmax_output_0:0"
input: "/encoder/layer.2/attention/self/Transpose_output_0:0"
output: "/encoder/layer.2/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.2/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.00788026675581932
  zero_point: 105
  minval: -0.8274279832839966
  maxval: 1.1820399761199951
}

this is gemm requantize_op:
input: "/encoder/layer.2/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.2/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.2/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.2/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.2/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.2/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.2/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.00788026675581932
  zero_point: 105
  minval: -0.8274279832839966
  maxval: 1.1820399761199951
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 768]
this is op:
input: "/encoder/layer.2/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1397"
output: "/encoder/layer.2/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.2/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.006788904778659344
  zero_point: 129
  minval: -0.8757687211036682
  maxval: 0.8554019927978516
}

this is gemm op:
input: "/encoder/layer.2/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1397"
output: "/encoder/layer.2/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.2/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.006788904778659344
  zero_point: 129
  minval: -0.8757687211036682
  maxval: 0.8554019927978516
}

this is gemm requantize_op:
input: "/encoder/layer.2/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.2/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.2/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.2/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.2/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.2/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.2/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.006788904778659344
  zero_point: 129
  minval: -0.8757687211036682
  maxval: 0.8554019927978516
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1398"
output: "/encoder/layer.2/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.2/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.2867799997329712
  zero_point: 69
  minval: -19.78782081604004
  maxval: 53.34107971191406
}

this is gemm op:
input: "/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1398"
output: "/encoder/layer.2/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.2/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.2867799997329712
  zero_point: 69
  minval: -19.78782081604004
  maxval: 53.34107971191406
}

this is gemm requantize_op:
input: "/encoder/layer.2/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.2/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.2/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.2/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.2/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.2/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.2/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2867799997329712
  zero_point: 69
  minval: -19.78782081604004
  maxval: 53.34107971191406
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1399"
output: "/encoder/layer.2/output/dense/MatMul_output_0:0"
name: "/encoder/layer.2/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.8529177308082581
  zero_point: 251
  minval: -214.0823516845703
  maxval: 3.4116709232330322
}

this is gemm op:
input: "/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1399"
output: "/encoder/layer.2/output/dense/MatMul_output_0:0"
name: "/encoder/layer.2/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.8529177308082581
  zero_point: 251
  minval: -214.0823516845703
  maxval: 3.4116709232330322
}

this is gemm requantize_op:
input: "/encoder/layer.2/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.2/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.2/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.2/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.2/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.2/output/dense/MatMul_output_0:0"
name: "/encoder/layer.2/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.8529177308082581
  zero_point: 251
  minval: -214.0823516845703
  maxval: 3.4116709232330322
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1400"
output: "/encoder/layer.3/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03683091327548027
  zero_point: 141
  minval: -5.1931586265563965
  maxval: 4.198723793029785
}

this is gemm op:
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1400"
output: "/encoder/layer.3/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03683091327548027
  zero_point: 141
  minval: -5.1931586265563965
  maxval: 4.198723793029785
}

this is gemm requantize_op:
input: "/encoder/layer.3/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.3/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.3/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.3/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.3/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.3/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03683091327548027
  zero_point: 141
  minval: -5.1931586265563965
  maxval: 4.198723793029785
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1401"
output: "/encoder/layer.3/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04226052016019821
  zero_point: 120
  minval: -5.071262359619141
  maxval: 5.705170154571533
}

this is gemm op:
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1401"
output: "/encoder/layer.3/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04226052016019821
  zero_point: 120
  minval: -5.071262359619141
  maxval: 5.705170154571533
}

this is gemm requantize_op:
input: "/encoder/layer.3/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.3/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.3/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.3/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.3/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.3/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04226052016019821
  zero_point: 120
  minval: -5.071262359619141
  maxval: 5.705170154571533
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.3/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.3/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.3/attention/self/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.4197385907173157
  zero_point: 30
  minval: -12.592158317565918
  maxval: 94.4411849975586
}

this is gemm op:
input: "/encoder/layer.3/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.3/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.3/attention/self/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.4197385907173157
  zero_point: 30
  minval: -12.592158317565918
  maxval: 94.4411849975586
}

this is gemm requantize_op:
input: "/encoder/layer.3/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.3/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.3/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.3/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.3/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.3/attention/self/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.4197385907173157
  zero_point: 30
  minval: -12.592158317565918
  maxval: 94.4411849975586
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1407"
output: "/encoder/layer.3/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.017904654145240784
  zero_point: 124
  minval: -2.220176935195923
  maxval: 2.3455095291137695
}

this is gemm op:
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1407"
output: "/encoder/layer.3/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.017904654145240784
  zero_point: 124
  minval: -2.220176935195923
  maxval: 2.3455095291137695
}

this is gemm requantize_op:
input: "/encoder/layer.3/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.3/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.3/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.3/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.3/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.3/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.017904654145240784
  zero_point: 124
  minval: -2.220176935195923
  maxval: 2.3455095291137695
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.3/attention/self/Softmax_output_0:0"
input: "/encoder/layer.3/attention/self/Transpose_output_0:0"
output: "/encoder/layer.3/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.3/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.0067507983185350895
  zero_point: 129
  minval: -0.8708530068397522
  maxval: 0.8506006002426147
}

this is gemm op:
input: "/encoder/layer.3/attention/self/Softmax_output_0:0"
input: "/encoder/layer.3/attention/self/Transpose_output_0:0"
output: "/encoder/layer.3/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.3/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.0067507983185350895
  zero_point: 129
  minval: -0.8708530068397522
  maxval: 0.8506006002426147
}

this is gemm requantize_op:
input: "/encoder/layer.3/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.3/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.3/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.3/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.3/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.3/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.3/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0067507983185350895
  zero_point: 129
  minval: -0.8708530068397522
  maxval: 0.8506006002426147
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 768]
this is op:
input: "/encoder/layer.3/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1422"
output: "/encoder/layer.3/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.3/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.005419538356363773
  zero_point: 151
  minval: -0.8183503150939941
  maxval: 0.5636320114135742
}

this is gemm op:
input: "/encoder/layer.3/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1422"
output: "/encoder/layer.3/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.3/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.005419538356363773
  zero_point: 151
  minval: -0.8183503150939941
  maxval: 0.5636320114135742
}

this is gemm requantize_op:
input: "/encoder/layer.3/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.3/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.3/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.3/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.3/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.3/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.3/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.005419538356363773
  zero_point: 151
  minval: -0.8183503150939941
  maxval: 0.5636320114135742
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1423"
output: "/encoder/layer.3/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.3/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.2499488741159439
  zero_point: 232
  minval: -57.988136291503906
  maxval: 5.748824119567871
}

this is gemm op:
input: "/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1423"
output: "/encoder/layer.3/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.3/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.2499488741159439
  zero_point: 232
  minval: -57.988136291503906
  maxval: 5.748824119567871
}

this is gemm requantize_op:
input: "/encoder/layer.3/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.3/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.3/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.3/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.3/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.3/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.3/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2499488741159439
  zero_point: 232
  minval: -57.988136291503906
  maxval: 5.748824119567871
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1424"
output: "/encoder/layer.3/output/dense/MatMul_output_0:0"
name: "/encoder/layer.3/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.2377270609140396
  zero_point: 240
  minval: -57.05449295043945
  maxval: 3.565905809402466
}

this is gemm op:
input: "/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1424"
output: "/encoder/layer.3/output/dense/MatMul_output_0:0"
name: "/encoder/layer.3/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.2377270609140396
  zero_point: 240
  minval: -57.05449295043945
  maxval: 3.565905809402466
}

this is gemm requantize_op:
input: "/encoder/layer.3/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.3/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.3/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.3/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.3/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.3/output/dense/MatMul_output_0:0"
name: "/encoder/layer.3/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2377270609140396
  zero_point: 240
  minval: -57.05449295043945
  maxval: 3.565905809402466
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1425"
output: "/encoder/layer.4/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03810853511095047
  zero_point: 144
  minval: -5.487628936767578
  maxval: 4.230047225952148
}

this is gemm op:
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1425"
output: "/encoder/layer.4/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03810853511095047
  zero_point: 144
  minval: -5.487628936767578
  maxval: 4.230047225952148
}

this is gemm requantize_op:
input: "/encoder/layer.4/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.4/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.4/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.4/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.4/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.4/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03810853511095047
  zero_point: 144
  minval: -5.487628936767578
  maxval: 4.230047225952148
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1426"
output: "/encoder/layer.4/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.035824548453092575
  zero_point: 142
  minval: -5.087086200714111
  maxval: 4.048173904418945
}

this is gemm op:
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1426"
output: "/encoder/layer.4/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.035824548453092575
  zero_point: 142
  minval: -5.087086200714111
  maxval: 4.048173904418945
}

this is gemm requantize_op:
input: "/encoder/layer.4/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.4/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.4/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.4/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.4/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.4/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.035824548453092575
  zero_point: 142
  minval: -5.087086200714111
  maxval: 4.048173904418945
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.4/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.4/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.4/attention/self/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.40570372343063354
  zero_point: 72
  minval: -29.210668563842773
  maxval: 74.24378204345703
}

this is gemm op:
input: "/encoder/layer.4/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.4/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.4/attention/self/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.40570372343063354
  zero_point: 72
  minval: -29.210668563842773
  maxval: 74.24378204345703
}

this is gemm requantize_op:
input: "/encoder/layer.4/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.4/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.4/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.4/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.4/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.4/attention/self/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.40570372343063354
  zero_point: 72
  minval: -29.210668563842773
  maxval: 74.24378204345703
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1432"
output: "/encoder/layer.4/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.021970756351947784
  zero_point: 103
  minval: -2.2629880905151367
  maxval: 3.339555025100708
}

this is gemm op:
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1432"
output: "/encoder/layer.4/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.021970756351947784
  zero_point: 103
  minval: -2.2629880905151367
  maxval: 3.339555025100708
}

this is gemm requantize_op:
input: "/encoder/layer.4/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.4/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.4/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.4/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.4/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.4/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.021970756351947784
  zero_point: 103
  minval: -2.2629880905151367
  maxval: 3.339555025100708
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.4/attention/self/Softmax_output_0:0"
input: "/encoder/layer.4/attention/self/Transpose_output_0:0"
output: "/encoder/layer.4/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.4/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.007573618553578854
  zero_point: 137
  minval: -1.037585735321045
  maxval: 0.8936870098114014
}

this is gemm op:
input: "/encoder/layer.4/attention/self/Softmax_output_0:0"
input: "/encoder/layer.4/attention/self/Transpose_output_0:0"
output: "/encoder/layer.4/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.4/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.007573618553578854
  zero_point: 137
  minval: -1.037585735321045
  maxval: 0.8936870098114014
}

this is gemm requantize_op:
input: "/encoder/layer.4/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.4/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.4/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.4/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.4/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.4/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.4/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007573618553578854
  zero_point: 137
  minval: -1.037585735321045
  maxval: 0.8936870098114014
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 768]
this is op:
input: "/encoder/layer.4/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1447"
output: "/encoder/layer.4/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.4/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.008231732062995434
  zero_point: 157
  minval: -1.292382001876831
  maxval: 0.8067097663879395
}

this is gemm op:
input: "/encoder/layer.4/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1447"
output: "/encoder/layer.4/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.4/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.008231732062995434
  zero_point: 157
  minval: -1.292382001876831
  maxval: 0.8067097663879395
}

this is gemm requantize_op:
input: "/encoder/layer.4/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.4/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.4/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.4/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.4/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.4/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.4/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.008231732062995434
  zero_point: 157
  minval: -1.292382001876831
  maxval: 0.8067097663879395
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1448"
output: "/encoder/layer.4/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.4/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.2427986115217209
  zero_point: 226
  minval: -54.87248611450195
  maxval: 7.041159629821777
}

this is gemm op:
input: "/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1448"
output: "/encoder/layer.4/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.4/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.2427986115217209
  zero_point: 226
  minval: -54.87248611450195
  maxval: 7.041159629821777
}

this is gemm requantize_op:
input: "/encoder/layer.4/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.4/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.4/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.4/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.4/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.4/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.4/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2427986115217209
  zero_point: 226
  minval: -54.87248611450195
  maxval: 7.041159629821777
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1449"
output: "/encoder/layer.4/output/dense/MatMul_output_0:0"
name: "/encoder/layer.4/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.19222192466259003
  zero_point: 233
  minval: -44.7877082824707
  maxval: 4.228882312774658
}

this is gemm op:
input: "/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1449"
output: "/encoder/layer.4/output/dense/MatMul_output_0:0"
name: "/encoder/layer.4/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.19222192466259003
  zero_point: 233
  minval: -44.7877082824707
  maxval: 4.228882312774658
}

this is gemm requantize_op:
input: "/encoder/layer.4/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.4/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.4/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.4/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.4/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.4/output/dense/MatMul_output_0:0"
name: "/encoder/layer.4/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.19222192466259003
  zero_point: 233
  minval: -44.7877082824707
  maxval: 4.228882312774658
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1450"
output: "/encoder/layer.5/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04121337831020355
  zero_point: 151
  minval: -6.223219871520996
  maxval: 4.286191463470459
}

this is gemm op:
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1450"
output: "/encoder/layer.5/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04121337831020355
  zero_point: 151
  minval: -6.223219871520996
  maxval: 4.286191463470459
}

this is gemm requantize_op:
input: "/encoder/layer.5/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.5/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.5/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.5/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.5/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.5/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04121337831020355
  zero_point: 151
  minval: -6.223219871520996
  maxval: 4.286191463470459
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1451"
output: "/encoder/layer.5/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03027612902224064
  zero_point: 131
  minval: -3.966172933578491
  maxval: 3.754240036010742
}

this is gemm op:
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1451"
output: "/encoder/layer.5/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03027612902224064
  zero_point: 131
  minval: -3.966172933578491
  maxval: 3.754240036010742
}

this is gemm requantize_op:
input: "/encoder/layer.5/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.5/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.5/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.5/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.5/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.5/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03027612902224064
  zero_point: 131
  minval: -3.966172933578491
  maxval: 3.754240036010742
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.5/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.5/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.5/attention/self/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.3326273262500763
  zero_point: 54
  minval: -17.961875915527344
  maxval: 66.85809326171875
}

this is gemm op:
input: "/encoder/layer.5/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.5/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.5/attention/self/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.3326273262500763
  zero_point: 54
  minval: -17.961875915527344
  maxval: 66.85809326171875
}

this is gemm requantize_op:
input: "/encoder/layer.5/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.5/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.5/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.5/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.5/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.5/attention/self/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.3326273262500763
  zero_point: 54
  minval: -17.961875915527344
  maxval: 66.85809326171875
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1457"
output: "/encoder/layer.5/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.018208399415016174
  zero_point: 117
  minval: -2.130382537841797
  maxval: 2.51275897026062
}

this is gemm op:
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1457"
output: "/encoder/layer.5/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.018208399415016174
  zero_point: 117
  minval: -2.130382537841797
  maxval: 2.51275897026062
}

this is gemm requantize_op:
input: "/encoder/layer.5/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.5/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.5/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.5/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.5/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.5/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018208399415016174
  zero_point: 117
  minval: -2.130382537841797
  maxval: 2.51275897026062
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.5/attention/self/Softmax_output_0:0"
input: "/encoder/layer.5/attention/self/Transpose_output_0:0"
output: "/encoder/layer.5/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.5/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.007289385888725519
  zero_point: 141
  minval: -1.0278034210205078
  maxval: 0.8309900164604187
}

this is gemm op:
input: "/encoder/layer.5/attention/self/Softmax_output_0:0"
input: "/encoder/layer.5/attention/self/Transpose_output_0:0"
output: "/encoder/layer.5/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.5/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.007289385888725519
  zero_point: 141
  minval: -1.0278034210205078
  maxval: 0.8309900164604187
}

this is gemm requantize_op:
input: "/encoder/layer.5/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.5/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.5/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.5/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.5/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.5/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.5/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007289385888725519
  zero_point: 141
  minval: -1.0278034210205078
  maxval: 0.8309900164604187
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 768]
this is op:
input: "/encoder/layer.5/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1472"
output: "/encoder/layer.5/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.5/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.007264192681759596
  zero_point: 140
  minval: -1.0169869661331177
  maxval: 0.8353821635246277
}

this is gemm op:
input: "/encoder/layer.5/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1472"
output: "/encoder/layer.5/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.5/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.007264192681759596
  zero_point: 140
  minval: -1.0169869661331177
  maxval: 0.8353821635246277
}

this is gemm requantize_op:
input: "/encoder/layer.5/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.5/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.5/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.5/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.5/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.5/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.5/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007264192681759596
  zero_point: 140
  minval: -1.0169869661331177
  maxval: 0.8353821635246277
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1473"
output: "/encoder/layer.5/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.5/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.1768578439950943
  zero_point: 236
  minval: -41.73844909667969
  maxval: 3.3602991104125977
}

this is gemm op:
input: "/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1473"
output: "/encoder/layer.5/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.5/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.1768578439950943
  zero_point: 236
  minval: -41.73844909667969
  maxval: 3.3602991104125977
}

this is gemm requantize_op:
input: "/encoder/layer.5/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.5/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.5/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.5/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.5/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.5/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.5/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.1768578439950943
  zero_point: 236
  minval: -41.73844909667969
  maxval: 3.3602991104125977
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1474"
output: "/encoder/layer.5/output/dense/MatMul_output_0:0"
name: "/encoder/layer.5/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.08409030735492706
  zero_point: 214
  minval: -17.995325088500977
  maxval: 3.447702407836914
}

this is gemm op:
input: "/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1474"
output: "/encoder/layer.5/output/dense/MatMul_output_0:0"
name: "/encoder/layer.5/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.08409030735492706
  zero_point: 214
  minval: -17.995325088500977
  maxval: 3.447702407836914
}

this is gemm requantize_op:
input: "/encoder/layer.5/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.5/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.5/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.5/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.5/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.5/output/dense/MatMul_output_0:0"
name: "/encoder/layer.5/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.08409030735492706
  zero_point: 214
  minval: -17.995325088500977
  maxval: 3.447702407836914
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1475"
output: "/encoder/layer.6/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04819261282682419
  zero_point: 144
  minval: -6.939736366271973
  maxval: 5.349380016326904
}

this is gemm op:
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1475"
output: "/encoder/layer.6/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04819261282682419
  zero_point: 144
  minval: -6.939736366271973
  maxval: 5.349380016326904
}

this is gemm requantize_op:
input: "/encoder/layer.6/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.6/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.6/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.6/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.6/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.6/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04819261282682419
  zero_point: 144
  minval: -6.939736366271973
  maxval: 5.349380016326904
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1476"
output: "/encoder/layer.6/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03172209858894348
  zero_point: 140
  minval: -4.441093921661377
  maxval: 3.6480414867401123
}

this is gemm op:
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1476"
output: "/encoder/layer.6/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03172209858894348
  zero_point: 140
  minval: -4.441093921661377
  maxval: 3.6480414867401123
}

this is gemm requantize_op:
input: "/encoder/layer.6/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.6/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.6/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.6/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.6/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.6/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03172209858894348
  zero_point: 140
  minval: -4.441093921661377
  maxval: 3.6480414867401123
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.6/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.6/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.6/attention/self/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.34057220816612244
  zero_point: 44
  minval: -14.985177040100098
  maxval: 71.86073303222656
}

this is gemm op:
input: "/encoder/layer.6/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.6/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.6/attention/self/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.34057220816612244
  zero_point: 44
  minval: -14.985177040100098
  maxval: 71.86073303222656
}

this is gemm requantize_op:
input: "/encoder/layer.6/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.6/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.6/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.6/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.6/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.6/attention/self/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.34057220816612244
  zero_point: 44
  minval: -14.985177040100098
  maxval: 71.86073303222656
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1482"
output: "/encoder/layer.6/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.018793268129229546
  zero_point: 128
  minval: -2.405538320541382
  maxval: 2.386744976043701
}

this is gemm op:
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1482"
output: "/encoder/layer.6/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.018793268129229546
  zero_point: 128
  minval: -2.405538320541382
  maxval: 2.386744976043701
}

this is gemm requantize_op:
input: "/encoder/layer.6/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.6/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.6/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.6/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.6/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.6/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018793268129229546
  zero_point: 128
  minval: -2.405538320541382
  maxval: 2.386744976043701
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.6/attention/self/Softmax_output_0:0"
input: "/encoder/layer.6/attention/self/Transpose_output_0:0"
output: "/encoder/layer.6/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.6/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.010126526467502117
  zero_point: 124
  minval: -1.255689263343811
  maxval: 1.3265750408172607
}

this is gemm op:
input: "/encoder/layer.6/attention/self/Softmax_output_0:0"
input: "/encoder/layer.6/attention/self/Transpose_output_0:0"
output: "/encoder/layer.6/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.6/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.010126526467502117
  zero_point: 124
  minval: -1.255689263343811
  maxval: 1.3265750408172607
}

this is gemm requantize_op:
input: "/encoder/layer.6/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.6/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.6/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.6/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.6/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.6/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.6/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010126526467502117
  zero_point: 124
  minval: -1.255689263343811
  maxval: 1.3265750408172607
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 768]
this is op:
input: "/encoder/layer.6/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1497"
output: "/encoder/layer.6/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.6/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.010015870444476604
  zero_point: 108
  minval: -1.0817140340805054
  maxval: 1.4723329544067383
}

this is gemm op:
input: "/encoder/layer.6/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1497"
output: "/encoder/layer.6/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.6/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.010015870444476604
  zero_point: 108
  minval: -1.0817140340805054
  maxval: 1.4723329544067383
}

this is gemm requantize_op:
input: "/encoder/layer.6/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.6/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.6/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.6/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.6/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.6/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.6/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010015870444476604
  zero_point: 108
  minval: -1.0817140340805054
  maxval: 1.4723329544067383
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1498"
output: "/encoder/layer.6/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.6/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.0957103744149208
  zero_point: 213
  minval: -20.386308670043945
  maxval: 4.019835472106934
}

this is gemm op:
input: "/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1498"
output: "/encoder/layer.6/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.6/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.0957103744149208
  zero_point: 213
  minval: -20.386308670043945
  maxval: 4.019835472106934
}

this is gemm requantize_op:
input: "/encoder/layer.6/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.6/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.6/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.6/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.6/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.6/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.6/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0957103744149208
  zero_point: 213
  minval: -20.386308670043945
  maxval: 4.019835472106934
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1499"
output: "/encoder/layer.6/output/dense/MatMul_output_0:0"
name: "/encoder/layer.6/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07174398005008698
  zero_point: 219
  minval: -15.711932182312012
  maxval: 2.5827834606170654
}

this is gemm op:
input: "/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1499"
output: "/encoder/layer.6/output/dense/MatMul_output_0:0"
name: "/encoder/layer.6/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.07174398005008698
  zero_point: 219
  minval: -15.711932182312012
  maxval: 2.5827834606170654
}

this is gemm requantize_op:
input: "/encoder/layer.6/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.6/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.6/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.6/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.6/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.6/output/dense/MatMul_output_0:0"
name: "/encoder/layer.6/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07174398005008698
  zero_point: 219
  minval: -15.711932182312012
  maxval: 2.5827834606170654
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1500"
output: "/encoder/layer.7/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04076783359050751
  zero_point: 139
  minval: -5.666728973388672
  maxval: 4.729068756103516
}

this is gemm op:
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1500"
output: "/encoder/layer.7/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04076783359050751
  zero_point: 139
  minval: -5.666728973388672
  maxval: 4.729068756103516
}

this is gemm requantize_op:
input: "/encoder/layer.7/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.7/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.7/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.7/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.7/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.7/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04076783359050751
  zero_point: 139
  minval: -5.666728973388672
  maxval: 4.729068756103516
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1501"
output: "/encoder/layer.7/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04032149165868759
  zero_point: 137
  minval: -5.524044513702393
  maxval: 4.757936000823975
}

this is gemm op:
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1501"
output: "/encoder/layer.7/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.04032149165868759
  zero_point: 137
  minval: -5.524044513702393
  maxval: 4.757936000823975
}

this is gemm requantize_op:
input: "/encoder/layer.7/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.7/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.7/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.7/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.7/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.7/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04032149165868759
  zero_point: 137
  minval: -5.524044513702393
  maxval: 4.757936000823975
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.7/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.7/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.7/attention/self/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.34224170446395874
  zero_point: 66
  minval: -22.58795166015625
  maxval: 64.68367767333984
}

this is gemm op:
input: "/encoder/layer.7/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.7/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.7/attention/self/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.34224170446395874
  zero_point: 66
  minval: -22.58795166015625
  maxval: 64.68367767333984
}

this is gemm requantize_op:
input: "/encoder/layer.7/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.7/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.7/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.7/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.7/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.7/attention/self/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.34224170446395874
  zero_point: 66
  minval: -22.58795166015625
  maxval: 64.68367767333984
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1507"
output: "/encoder/layer.7/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.01867643930017948
  zero_point: 141
  minval: -2.63337779045105
  maxval: 2.1291139125823975
}

this is gemm op:
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1507"
output: "/encoder/layer.7/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.01867643930017948
  zero_point: 141
  minval: -2.63337779045105
  maxval: 2.1291139125823975
}

this is gemm requantize_op:
input: "/encoder/layer.7/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.7/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.7/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.7/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.7/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.7/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01867643930017948
  zero_point: 141
  minval: -2.63337779045105
  maxval: 2.1291139125823975
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.7/attention/self/Softmax_output_0:0"
input: "/encoder/layer.7/attention/self/Transpose_output_0:0"
output: "/encoder/layer.7/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.7/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.007804992608726025
  zero_point: 134
  minval: -1.045868992805481
  maxval: 0.944404125213623
}

this is gemm op:
input: "/encoder/layer.7/attention/self/Softmax_output_0:0"
input: "/encoder/layer.7/attention/self/Transpose_output_0:0"
output: "/encoder/layer.7/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.7/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.007804992608726025
  zero_point: 134
  minval: -1.045868992805481
  maxval: 0.944404125213623
}

this is gemm requantize_op:
input: "/encoder/layer.7/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.7/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.7/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.7/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.7/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.7/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.7/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007804992608726025
  zero_point: 134
  minval: -1.045868992805481
  maxval: 0.944404125213623
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 768]
this is op:
input: "/encoder/layer.7/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1522"
output: "/encoder/layer.7/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.7/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.015512127429246902
  zero_point: 180
  minval: -2.7921829223632812
  maxval: 1.1634095907211304
}

this is gemm op:
input: "/encoder/layer.7/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1522"
output: "/encoder/layer.7/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.7/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.015512127429246902
  zero_point: 180
  minval: -2.7921829223632812
  maxval: 1.1634095907211304
}

this is gemm requantize_op:
input: "/encoder/layer.7/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.7/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.7/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.7/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.7/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.7/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.7/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.015512127429246902
  zero_point: 180
  minval: -2.7921829223632812
  maxval: 1.1634095907211304
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1523"
output: "/encoder/layer.7/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.7/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.0668439120054245
  zero_point: 195
  minval: -13.034563064575195
  maxval: 4.010634899139404
}

this is gemm op:
input: "/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1523"
output: "/encoder/layer.7/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.7/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.0668439120054245
  zero_point: 195
  minval: -13.034563064575195
  maxval: 4.010634899139404
}

this is gemm requantize_op:
input: "/encoder/layer.7/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.7/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.7/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.7/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.7/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.7/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.7/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0668439120054245
  zero_point: 195
  minval: -13.034563064575195
  maxval: 4.010634899139404
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1524"
output: "/encoder/layer.7/output/dense/MatMul_output_0:0"
name: "/encoder/layer.7/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.019198313355445862
  zero_point: 64
  minval: -1.2286920547485352
  maxval: 3.6668779850006104
}

this is gemm op:
input: "/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1524"
output: "/encoder/layer.7/output/dense/MatMul_output_0:0"
name: "/encoder/layer.7/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.019198313355445862
  zero_point: 64
  minval: -1.2286920547485352
  maxval: 3.6668779850006104
}

this is gemm requantize_op:
input: "/encoder/layer.7/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.7/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.7/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.7/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.7/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.7/output/dense/MatMul_output_0:0"
name: "/encoder/layer.7/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.019198313355445862
  zero_point: 64
  minval: -1.2286920547485352
  maxval: 3.6668779850006104
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1525"
output: "/encoder/layer.8/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03878064453601837
  zero_point: 127
  minval: -4.92514181137085
  maxval: 4.963922500610352
}

this is gemm op:
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1525"
output: "/encoder/layer.8/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03878064453601837
  zero_point: 127
  minval: -4.92514181137085
  maxval: 4.963922500610352
}

this is gemm requantize_op:
input: "/encoder/layer.8/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.8/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.8/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.8/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.8/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.8/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03878064453601837
  zero_point: 127
  minval: -4.92514181137085
  maxval: 4.963922500610352
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1526"
output: "/encoder/layer.8/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.0334072969853878
  zero_point: 127
  minval: -4.242726802825928
  maxval: 4.276134014129639
}

this is gemm op:
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1526"
output: "/encoder/layer.8/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.0334072969853878
  zero_point: 127
  minval: -4.242726802825928
  maxval: 4.276134014129639
}

this is gemm requantize_op:
input: "/encoder/layer.8/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.8/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.8/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.8/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.8/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.8/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0334072969853878
  zero_point: 127
  minval: -4.242726802825928
  maxval: 4.276134014129639
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.8/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.8/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.8/attention/self/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.34134015440940857
  zero_point: 67
  minval: -22.86979103088379
  maxval: 64.17195129394531
}

this is gemm op:
input: "/encoder/layer.8/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.8/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.8/attention/self/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.34134015440940857
  zero_point: 67
  minval: -22.86979103088379
  maxval: 64.17195129394531
}

this is gemm requantize_op:
input: "/encoder/layer.8/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.8/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.8/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.8/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.8/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.8/attention/self/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.34134015440940857
  zero_point: 67
  minval: -22.86979103088379
  maxval: 64.17195129394531
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1532"
output: "/encoder/layer.8/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.02117350324988365
  zero_point: 125
  minval: -2.6466879844665527
  maxval: 2.7525556087493896
}

this is gemm op:
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1532"
output: "/encoder/layer.8/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.02117350324988365
  zero_point: 125
  minval: -2.6466879844665527
  maxval: 2.7525556087493896
}

this is gemm requantize_op:
input: "/encoder/layer.8/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.8/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.8/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.8/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.8/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.8/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02117350324988365
  zero_point: 125
  minval: -2.6466879844665527
  maxval: 2.7525556087493896
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.8/attention/self/Softmax_output_0:0"
input: "/encoder/layer.8/attention/self/Transpose_output_0:0"
output: "/encoder/layer.8/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.8/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.011665240861475468
  zero_point: 143
  minval: -1.6681294441223145
  maxval: 1.3065069913864136
}

this is gemm op:
input: "/encoder/layer.8/attention/self/Softmax_output_0:0"
input: "/encoder/layer.8/attention/self/Transpose_output_0:0"
output: "/encoder/layer.8/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.8/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.011665240861475468
  zero_point: 143
  minval: -1.6681294441223145
  maxval: 1.3065069913864136
}

this is gemm requantize_op:
input: "/encoder/layer.8/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.8/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.8/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.8/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.8/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.8/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.8/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.011665240861475468
  zero_point: 143
  minval: -1.6681294441223145
  maxval: 1.3065069913864136
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 768]
this is op:
input: "/encoder/layer.8/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1547"
output: "/encoder/layer.8/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.8/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.01757514476776123
  zero_point: 173
  minval: -3.0404999256134033
  maxval: 1.441161870956421
}

this is gemm op:
input: "/encoder/layer.8/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1547"
output: "/encoder/layer.8/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.8/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.01757514476776123
  zero_point: 173
  minval: -3.0404999256134033
  maxval: 1.441161870956421
}

this is gemm requantize_op:
input: "/encoder/layer.8/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.8/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.8/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.8/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.8/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.8/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.8/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01757514476776123
  zero_point: 173
  minval: -3.0404999256134033
  maxval: 1.441161870956421
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1548"
output: "/encoder/layer.8/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.8/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.08149689435958862
  zero_point: 213
  minval: -17.35883903503418
  maxval: 3.4228696823120117
}

this is gemm op:
input: "/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1548"
output: "/encoder/layer.8/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.8/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.08149689435958862
  zero_point: 213
  minval: -17.35883903503418
  maxval: 3.4228696823120117
}

this is gemm requantize_op:
input: "/encoder/layer.8/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.8/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.8/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.8/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.8/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.8/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.8/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.08149689435958862
  zero_point: 213
  minval: -17.35883903503418
  maxval: 3.4228696823120117
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1549"
output: "/encoder/layer.8/output/dense/MatMul_output_0:0"
name: "/encoder/layer.8/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.022208763286471367
  zero_point: 61
  minval: -1.3547345399856567
  maxval: 4.308499813079834
}

this is gemm op:
input: "/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1549"
output: "/encoder/layer.8/output/dense/MatMul_output_0:0"
name: "/encoder/layer.8/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.022208763286471367
  zero_point: 61
  minval: -1.3547345399856567
  maxval: 4.308499813079834
}

this is gemm requantize_op:
input: "/encoder/layer.8/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.8/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.8/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.8/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.8/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.8/output/dense/MatMul_output_0:0"
name: "/encoder/layer.8/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.022208763286471367
  zero_point: 61
  minval: -1.3547345399856567
  maxval: 4.308499813079834
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1550"
output: "/encoder/layer.9/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.040860384702682495
  zero_point: 135
  minval: -5.5161519050598145
  maxval: 4.90324592590332
}

this is gemm op:
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1550"
output: "/encoder/layer.9/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.040860384702682495
  zero_point: 135
  minval: -5.5161519050598145
  maxval: 4.90324592590332
}

this is gemm requantize_op:
input: "/encoder/layer.9/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.9/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.9/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.9/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.9/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.9/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.040860384702682495
  zero_point: 135
  minval: -5.5161519050598145
  maxval: 4.90324592590332
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1551"
output: "/encoder/layer.9/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03000347502529621
  zero_point: 131
  minval: -3.930455446243286
  maxval: 3.720431089401245
}

this is gemm op:
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1551"
output: "/encoder/layer.9/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03000347502529621
  zero_point: 131
  minval: -3.930455446243286
  maxval: 3.720431089401245
}

this is gemm requantize_op:
input: "/encoder/layer.9/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.9/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.9/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.9/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.9/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.9/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03000347502529621
  zero_point: 131
  minval: -3.930455446243286
  maxval: 3.720431089401245
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.9/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.9/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.9/attention/self/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.34506726264953613
  zero_point: 100
  minval: -34.5067253112793
  maxval: 53.48542404174805
}

this is gemm op:
input: "/encoder/layer.9/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.9/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.9/attention/self/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.34506726264953613
  zero_point: 100
  minval: -34.5067253112793
  maxval: 53.48542404174805
}

this is gemm requantize_op:
input: "/encoder/layer.9/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.9/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.9/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.9/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.9/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.9/attention/self/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.34506726264953613
  zero_point: 100
  minval: -34.5067253112793
  maxval: 53.48542404174805
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1557"
output: "/encoder/layer.9/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.022493071854114532
  zero_point: 110
  minval: -2.4742379188537598
  maxval: 3.261495590209961
}

this is gemm op:
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1557"
output: "/encoder/layer.9/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.022493071854114532
  zero_point: 110
  minval: -2.4742379188537598
  maxval: 3.261495590209961
}

this is gemm requantize_op:
input: "/encoder/layer.9/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.9/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.9/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.9/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.9/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.9/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.022493071854114532
  zero_point: 110
  minval: -2.4742379188537598
  maxval: 3.261495590209961
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.9/attention/self/Softmax_output_0:0"
input: "/encoder/layer.9/attention/self/Transpose_output_0:0"
output: "/encoder/layer.9/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.9/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.01358900684863329
  zero_point: 106
  minval: -1.4404346942901611
  maxval: 2.024761915206909
}

this is gemm op:
input: "/encoder/layer.9/attention/self/Softmax_output_0:0"
input: "/encoder/layer.9/attention/self/Transpose_output_0:0"
output: "/encoder/layer.9/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.9/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.01358900684863329
  zero_point: 106
  minval: -1.4404346942901611
  maxval: 2.024761915206909
}

this is gemm requantize_op:
input: "/encoder/layer.9/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.9/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.9/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.9/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.9/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.9/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.9/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01358900684863329
  zero_point: 106
  minval: -1.4404346942901611
  maxval: 2.024761915206909
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 768]
this is op:
input: "/encoder/layer.9/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1572"
output: "/encoder/layer.9/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.9/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.010727767832577229
  zero_point: 125
  minval: -1.3409709930419922
  maxval: 1.394609808921814
}

this is gemm op:
input: "/encoder/layer.9/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1572"
output: "/encoder/layer.9/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.9/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.010727767832577229
  zero_point: 125
  minval: -1.3409709930419922
  maxval: 1.394609808921814
}

this is gemm requantize_op:
input: "/encoder/layer.9/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.9/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.9/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.9/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.9/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.9/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.9/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010727767832577229
  zero_point: 125
  minval: -1.3409709930419922
  maxval: 1.394609808921814
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1573"
output: "/encoder/layer.9/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.9/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.07669970393180847
  zero_point: 218
  minval: -16.720535278320312
  maxval: 2.8378889560699463
}

this is gemm op:
input: "/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1573"
output: "/encoder/layer.9/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.9/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.07669970393180847
  zero_point: 218
  minval: -16.720535278320312
  maxval: 2.8378889560699463
}

this is gemm requantize_op:
input: "/encoder/layer.9/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.9/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.9/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.9/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.9/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.9/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.9/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07669970393180847
  zero_point: 218
  minval: -16.720535278320312
  maxval: 2.8378889560699463
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1574"
output: "/encoder/layer.9/output/dense/MatMul_output_0:0"
name: "/encoder/layer.9/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.10220877826213837
  zero_point: 155
  minval: -15.842361450195312
  maxval: 10.220877647399902
}

this is gemm op:
input: "/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1574"
output: "/encoder/layer.9/output/dense/MatMul_output_0:0"
name: "/encoder/layer.9/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.10220877826213837
  zero_point: 155
  minval: -15.842361450195312
  maxval: 10.220877647399902
}

this is gemm requantize_op:
input: "/encoder/layer.9/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.9/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.9/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.9/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.9/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.9/output/dense/MatMul_output_0:0"
name: "/encoder/layer.9/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.10220877826213837
  zero_point: 155
  minval: -15.842361450195312
  maxval: 10.220877647399902
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1575"
output: "/encoder/layer.10/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.035721272230148315
  zero_point: 147
  minval: -5.2510271072387695
  maxval: 3.8578972816467285
}

this is gemm op:
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1575"
output: "/encoder/layer.10/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.035721272230148315
  zero_point: 147
  minval: -5.2510271072387695
  maxval: 3.8578972816467285
}

this is gemm requantize_op:
input: "/encoder/layer.10/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.10/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.10/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.10/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.10/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.10/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.035721272230148315
  zero_point: 147
  minval: -5.2510271072387695
  maxval: 3.8578972816467285
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1576"
output: "/encoder/layer.10/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03174690157175064
  zero_point: 120
  minval: -3.8096280097961426
  maxval: 4.285831451416016
}

this is gemm op:
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1576"
output: "/encoder/layer.10/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.03174690157175064
  zero_point: 120
  minval: -3.8096280097961426
  maxval: 4.285831451416016
}

this is gemm requantize_op:
input: "/encoder/layer.10/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.10/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.10/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.10/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.10/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.10/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03174690157175064
  zero_point: 120
  minval: -3.8096280097961426
  maxval: 4.285831451416016
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.10/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.10/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.10/attention/self/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.37985730171203613
  zero_point: 164
  minval: -62.29659652709961
  maxval: 34.567012786865234
}

this is gemm op:
input: "/encoder/layer.10/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.10/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.10/attention/self/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.37985730171203613
  zero_point: 164
  minval: -62.29659652709961
  maxval: 34.567012786865234
}

this is gemm requantize_op:
input: "/encoder/layer.10/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.10/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.10/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.10/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.10/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.10/attention/self/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.37985730171203613
  zero_point: 164
  minval: -62.29659652709961
  maxval: 34.567012786865234
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1582"
output: "/encoder/layer.10/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.018686113879084587
  zero_point: 140
  minval: -2.616055965423584
  maxval: 2.1489031314849854
}

this is gemm op:
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1582"
output: "/encoder/layer.10/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.018686113879084587
  zero_point: 140
  minval: -2.616055965423584
  maxval: 2.1489031314849854
}

this is gemm requantize_op:
input: "/encoder/layer.10/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.10/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.10/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.10/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.10/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.10/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018686113879084587
  zero_point: 140
  minval: -2.616055965423584
  maxval: 2.1489031314849854
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.10/attention/self/Softmax_output_0:0"
input: "/encoder/layer.10/attention/self/Transpose_output_0:0"
output: "/encoder/layer.10/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.10/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.013253866694867611
  zero_point: 120
  minval: -1.5904639959335327
  maxval: 1.7892719507217407
}

this is gemm op:
input: "/encoder/layer.10/attention/self/Softmax_output_0:0"
input: "/encoder/layer.10/attention/self/Transpose_output_0:0"
output: "/encoder/layer.10/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.10/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.013253866694867611
  zero_point: 120
  minval: -1.5904639959335327
  maxval: 1.7892719507217407
}

this is gemm requantize_op:
input: "/encoder/layer.10/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.10/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.10/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.10/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.10/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.10/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.10/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.013253866694867611
  zero_point: 120
  minval: -1.5904639959335327
  maxval: 1.7892719507217407
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 768]
this is op:
input: "/encoder/layer.10/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1597"
output: "/encoder/layer.10/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.10/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.011150236241519451
  zero_point: 127
  minval: -1.4160799980163574
  maxval: 1.4272302389144897
}

this is gemm op:
input: "/encoder/layer.10/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1597"
output: "/encoder/layer.10/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.10/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.011150236241519451
  zero_point: 127
  minval: -1.4160799980163574
  maxval: 1.4272302389144897
}

this is gemm requantize_op:
input: "/encoder/layer.10/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.10/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.10/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.10/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.10/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.10/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.10/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.011150236241519451
  zero_point: 127
  minval: -1.4160799980163574
  maxval: 1.4272302389144897
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1598"
output: "/encoder/layer.10/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.10/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.14899571239948273
  zero_point: 63
  minval: -9.38672924041748
  maxval: 28.607175827026367
}

this is gemm op:
input: "/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1598"
output: "/encoder/layer.10/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.10/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.14899571239948273
  zero_point: 63
  minval: -9.38672924041748
  maxval: 28.607175827026367
}

this is gemm requantize_op:
input: "/encoder/layer.10/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.10/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.10/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.10/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.10/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.10/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.10/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.14899571239948273
  zero_point: 63
  minval: -9.38672924041748
  maxval: 28.607175827026367
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1599"
output: "/encoder/layer.10/output/dense/MatMul_output_0:0"
name: "/encoder/layer.10/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.8073998093605042
  zero_point: 248
  minval: -200.2351531982422
  maxval: 5.651798725128174
}

this is gemm op:
input: "/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1599"
output: "/encoder/layer.10/output/dense/MatMul_output_0:0"
name: "/encoder/layer.10/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.8073998093605042
  zero_point: 248
  minval: -200.2351531982422
  maxval: 5.651798725128174
}

this is gemm requantize_op:
input: "/encoder/layer.10/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.10/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.10/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.10/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.10/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.10/output/dense/MatMul_output_0:0"
name: "/encoder/layer.10/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.8073998093605042
  zero_point: 248
  minval: -200.2351531982422
  maxval: 5.651798725128174
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1600"
output: "/encoder/layer.11/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.027746092528104782
  zero_point: 131
  minval: -3.634737968444824
  maxval: 3.4405152797698975
}

this is gemm op:
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1600"
output: "/encoder/layer.11/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/query/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.027746092528104782
  zero_point: 131
  minval: -3.634737968444824
  maxval: 3.4405152797698975
}

this is gemm requantize_op:
input: "/encoder/layer.11/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.11/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.11/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.11/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.11/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.11/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.027746092528104782
  zero_point: 131
  minval: -3.634737968444824
  maxval: 3.4405152797698975
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1601"
output: "/encoder/layer.11/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.027924062684178352
  zero_point: 129
  minval: -3.6022040843963623
  maxval: 3.5184319019317627
}

this is gemm op:
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1601"
output: "/encoder/layer.11/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/key/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.027924062684178352
  zero_point: 129
  minval: -3.6022040843963623
  maxval: 3.5184319019317627
}

this is gemm requantize_op:
input: "/encoder/layer.11/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.11/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.11/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.11/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.11/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.11/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.027924062684178352
  zero_point: 129
  minval: -3.6022040843963623
  maxval: 3.5184319019317627
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.11/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.11/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.11/attention/self/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.23882785439491272
  zero_point: 129
  minval: -30.808794021606445
  maxval: 30.092309951782227
}

this is gemm op:
input: "/encoder/layer.11/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.11/attention/self/Transpose_2_output_0:0"
output: "/encoder/layer.11/attention/self/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
quantize_info {
  scale: 0.23882785439491272
  zero_point: 129
  minval: -30.808794021606445
  maxval: 30.092309951782227
}

this is gemm requantize_op:
input: "/encoder/layer.11/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.11/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.11/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.11/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.11/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.11/attention/self/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.23882785439491272
  zero_point: 129
  minval: -30.808794021606445
  maxval: 30.092309951782227
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1607"
output: "/encoder/layer.11/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.020123830065131187
  zero_point: 124
  minval: -2.4953548908233643
  maxval: 2.6362218856811523
}

this is gemm op:
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1607"
output: "/encoder/layer.11/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/value/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.020123830065131187
  zero_point: 124
  minval: -2.4953548908233643
  maxval: 2.6362218856811523
}

this is gemm requantize_op:
input: "/encoder/layer.11/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.11/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.11/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.11/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.11/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.11/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.020123830065131187
  zero_point: 124
  minval: -2.4953548908233643
  maxval: 2.6362218856811523
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 12, 64]
this is op:
input: "/encoder/layer.11/attention/self/Softmax_output_0:0"
input: "/encoder/layer.11/attention/self/Transpose_output_0:0"
output: "/encoder/layer.11/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.11/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.013856226578354836
  zero_point: 128
  minval: -1.773597002029419
  maxval: 1.7597408294677734
}

this is gemm op:
input: "/encoder/layer.11/attention/self/Softmax_output_0:0"
input: "/encoder/layer.11/attention/self/Transpose_output_0:0"
output: "/encoder/layer.11/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.11/attention/self/MatMul_1"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
quantize_info {
  scale: 0.013856226578354836
  zero_point: 128
  minval: -1.773597002029419
  maxval: 1.7597408294677734
}

this is gemm requantize_op:
input: "/encoder/layer.11/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.11/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.11/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.11/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.11/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.11/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.11/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.013856226578354836
  zero_point: 128
  minval: -1.773597002029419
  maxval: 1.7597408294677734
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

reshape shape: [1, 6, 768]
this is op:
input: "/encoder/layer.11/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1622"
output: "/encoder/layer.11/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.11/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.013555709272623062
  zero_point: 124
  minval: -1.680907964706421
  maxval: 1.775797963142395
}

this is gemm op:
input: "/encoder/layer.11/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1622"
output: "/encoder/layer.11/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.11/attention/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.013555709272623062
  zero_point: 124
  minval: -1.680907964706421
  maxval: 1.775797963142395
}

this is gemm requantize_op:
input: "/encoder/layer.11/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.11/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.11/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.11/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.11/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.11/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.11/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.013555709272623062
  zero_point: 124
  minval: -1.680907964706421
  maxval: 1.775797963142395
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1623"
output: "/encoder/layer.11/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.11/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.031074268743395805
  zero_point: 125
  minval: -3.8842835426330566
  maxval: 4.0396552085876465
}

this is gemm op:
input: "/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1623"
output: "/encoder/layer.11/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.11/intermediate/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
quantize_info {
  scale: 0.031074268743395805
  zero_point: 125
  minval: -3.8842835426330566
  maxval: 4.0396552085876465
}

this is gemm requantize_op:
input: "/encoder/layer.11/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.11/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.11/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.11/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.11/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.11/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.11/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.031074268743395805
  zero_point: 125
  minval: -3.8842835426330566
  maxval: 4.0396552085876465
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4

this is op:
input: "/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1624"
output: "/encoder/layer.11/output/dense/MatMul_output_0:0"
name: "/encoder/layer.11/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.044259894639253616
  zero_point: 172
  minval: -7.612701892852783
  maxval: 3.6735713481903076
}

this is gemm op:
input: "/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1624"
output: "/encoder/layer.11/output/dense/MatMul_output_0:0"
name: "/encoder/layer.11/output/dense/MatMul"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
quantize_info {
  scale: 0.044259894639253616
  zero_point: 172
  minval: -7.612701892852783
  maxval: 3.6735713481903076
}

this is gemm requantize_op:
input: "/encoder/layer.11/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.11/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.11/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.11/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.11/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.11/output/dense/MatMul_output_0:0"
name: "/encoder/layer.11/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.044259894639253616
  zero_point: 172
  minval: -7.612701892852783
  maxval: 3.6735713481903076
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4

ipt_shape: [1, 6, 768], axis: [1], output_shape: [1, 768]
this is op:
input: "/pooler/Gather_output_0:0"
input: "pooler.dense.weight:0"
input: "pooler.dense.bias:0"
output: "/pooler/dense/Gemm_output_0:0"
name: "/pooler/dense/Gemm"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "transpose_a"
  i: 0
}
arg {
  name: "transpose_b"
  i: 1
}
output_shape {
  dims: 1
  dims: 768
}
quantize_info {
  scale: 0.02376180700957775
  zero_point: 124
  minval: -2.9464640617370605
  maxval: 3.1127965450286865
}

this is gemm op:
input: "/pooler/Gather_output_0:0"
input: "pooler.dense.weight:0"
output: "/pooler/dense/Gemm_output_0:0"
name: "/pooler/dense/Gemm"
type: "MatMul"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "transpose_a"
  i: 0
}
arg {
  name: "transpose_b"
  i: 1
}
output_shape {
  dims: 1
  dims: 768
}
quantize_info {
  scale: 0.02376180700957775
  zero_point: 124
  minval: -2.9464640617370605
  maxval: 3.1127965450286865
}

this is gemm requantize_op:
input: "/pooler/dense/Gemm_output_0_matmul:0"
input: "/pooler/dense/Gemm_output_0_matmul_min:0"
input: "/pooler/dense/Gemm_output_0_matmul_max:0"
input: "/pooler/dense/Gemm_output_0_min:0"
input: "/pooler/dense/Gemm_output_0_max:0"
output: "/pooler/dense/Gemm_output_0_requantize_op:0"
name: "/pooler/dense/Gemm_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "transpose_a"
  i: 0
}
arg {
  name: "transpose_b"
  i: 1
}
output_shape {
  dims: 1
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02376180700957775
  zero_point: 124
  minval: -2.9464640617370605
  maxval: 3.1127965450286865
}
padding: 0
out_max_byte_size: 768
out_max_byte_size: 4
out_max_byte_size: 4

this is gemm add op:
input: "/pooler/dense/Gemm_output_0_requantize_op:0"
input: "pooler.dense.bias:0"
input: "/pooler/dense/Gemm_output_0_requantize_op_min:0"
input: "/pooler/dense/Gemm_output_0_requantize_op_max:0"
input: "pooler.dense.bias_min:0"
input: "pooler.dense.bias_max:0"
output: "/pooler/dense/Gemm_output_0:0"
name: "/pooler/dense/Gemm_add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "transpose_a"
  i: 0
}
arg {
  name: "transpose_b"
  i: 1
}
output_shape {
  dims: 1
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02376180700957775
  zero_point: 124
  minval: -2.9464640617370605
  maxval: 3.1127965450286865
}
padding: 0
out_max_byte_size: 768
out_max_byte_size: 4
out_max_byte_size: 4

[input: "input_ids:0"
output: "mace_input_node_input_ids:0"
name: "mace_input_node_input_ids"
type: "QuantizeINPUT_f_to_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "data_format"
  i: 0
}
arg {
  name: "find_range_every_time"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0078125
  zero_point: 128
  minval: -1.0
  maxval: 0.9921875
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "attention_mask:0"
output: "mace_input_node_attention_mask:0"
name: "mace_input_node_attention_mask"
type: "QuantizeINPUT_f_to_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "data_format"
  i: 0
}
arg {
  name: "find_range_every_time"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0078125
  zero_point: 128
  minval: -1.0
  maxval: 0.9921875
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "mace_input_node_input_ids:0"
input: "mace_input_node_attention_mask:0"
input: "mace_input_node_input_ids:1"
input: "mace_input_node_input_ids:2"
input: "mace_input_node_attention_mask:1"
input: "mace_input_node_attention_mask:2"
input: "/embeddings/Add_output_0_min:0"
input: "/embeddings/Add_output_0_max:0"
output: "/embeddings/Add_output_0:0"
name: "/embeddings/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.006642164662480354
  zero_point: 152
  minval: -1.0096089839935303
  maxval: 0.6841429471969604
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/embeddings/Add_output_0:0"
input: "/embeddings/position_embeddings/Gather_output_0:0"
input: "/embeddings/Add_output_0:1"
input: "/embeddings/Add_output_0:2"
input: "/embeddings/position_embeddings/Gather_output_0_min:0"
input: "/embeddings/position_embeddings/Gather_output_0_max:0"
input: "/embeddings/Add_1_output_0_min:0"
input: "/embeddings/Add_1_output_0_max:0"
output: "/embeddings/Add_1_output_0:0"
name: "/embeddings/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.013235785067081451
  zero_point: 148
  minval: -1.9588961601257324
  maxval: 1.416229009628296
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/embeddings/Add_1_output_0:0"
input: "/embeddings/Add_1_output_0:1"
input: "/embeddings/Add_1_output_0:2"
input: "/embeddings/LayerNorm/ReduceMean/axes:0"
input: "/embeddings/LayerNorm/ReduceMean_output_0_min:0"
input: "/embeddings/LayerNorm/ReduceMean_output_0_max:0"
output: "/embeddings/LayerNorm/ReduceMean_output_0:0"
name: "/embeddings/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0001393360726069659
  zero_point: 244
  minval: -0.033998001366853714
  maxval: 0.0015326967695727944
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/embeddings/Add_1_output_0:0"
input: "/embeddings/LayerNorm/ReduceMean_output_0:0"
input: "/embeddings/Add_1_output_0:1"
input: "/embeddings/Add_1_output_0:2"
input: "/embeddings/LayerNorm/ReduceMean_output_0:1"
input: "/embeddings/LayerNorm/ReduceMean_output_0:2"
input: "/embeddings/LayerNorm/Sub_output_0_min:0"
input: "/embeddings/LayerNorm/Sub_output_0_max:0"
output: "/embeddings/LayerNorm/Sub_output_0:0"
name: "/embeddings/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.013241682201623917
  zero_point: 148
  minval: -1.9597690105438232
  maxval: 1.4168599843978882
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/embeddings/LayerNorm/Sub_output_0:0"
input: "/embeddings/LayerNorm/Sub_output_0:0"
input: "/embeddings/LayerNorm/Sub_output_0:1"
input: "/embeddings/LayerNorm/Sub_output_0:2"
input: "/embeddings/LayerNorm/Sub_output_0:1"
input: "/embeddings/LayerNorm/Sub_output_0:2"
input: "/embeddings/LayerNorm/Pow_output_0_min:0"
input: "/embeddings/LayerNorm/Pow_output_0_max:0"
output: "/embeddings/LayerNorm/Pow_output_0:0"
name: "/embeddings/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.015061548911035061
  zero_point: 0
  minval: 0.0
  maxval: 3.8406949043273926
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/embeddings/LayerNorm/Pow_output_0:0"
input: "/embeddings/LayerNorm/Pow_output_0:1"
input: "/embeddings/LayerNorm/Pow_output_0:2"
input: "/embeddings/LayerNorm/ReduceMean_1/axes:0"
input: "/embeddings/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/embeddings/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/embeddings/LayerNorm/ReduceMean_1_output_0:0"
name: "/embeddings/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 8.265490032499656e-05
  zero_point: 0
  minval: 0.0
  maxval: 0.021076999604701996
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/embeddings/LayerNorm/ReduceMean_1_output_0:0"
input: "/embeddings/LayerNorm/Add/b:0"
input: "/embeddings/LayerNorm/ReduceMean_1_output_0:1"
input: "/embeddings/LayerNorm/ReduceMean_1_output_0:2"
input: "/embeddings/LayerNorm/Add/b_min:0"
input: "/embeddings/LayerNorm/Add/b_max:0"
input: "/embeddings/LayerNorm/Add_output_0_min:0"
input: "/embeddings/LayerNorm/Add_output_0_max:0"
output: "/embeddings/LayerNorm/Add_output_0:0"
name: "/embeddings/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 8.265490032499656e-05
  zero_point: 0
  minval: 0.0
  maxval: 0.021076999604701996
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/embeddings/LayerNorm/Add_output_0:0"
input: "/embeddings/LayerNorm/Add_output_0:1"
input: "/embeddings/LayerNorm/Add_output_0:2"
output: "/embeddings/LayerNorm/Sqrt_output_0:0"
name: "/embeddings/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0005693294224329293
  zero_point: 0
  minval: 0.0
  maxval: 0.14517900347709656
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/embeddings/LayerNorm/Sub_output_0:0"
input: "/embeddings/LayerNorm/Sqrt_output_0:0"
input: "/embeddings/LayerNorm/Sub_output_0:1"
input: "/embeddings/LayerNorm/Sub_output_0:2"
input: "/embeddings/LayerNorm/Sqrt_output_0:1"
input: "/embeddings/LayerNorm/Sqrt_output_0:2"
input: "/embeddings/LayerNorm/Div_output_0_min:0"
input: "/embeddings/LayerNorm/Div_output_0_max:0"
output: "/embeddings/LayerNorm/Div_output_0:0"
name: "/embeddings/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0975840762257576
  zero_point: 155
  minval: -15.125532150268555
  maxval: 9.758407592773438
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/embeddings/LayerNorm/Div_output_0:0"
input: "embeddings.LayerNorm.weight:0"
input: "/embeddings/LayerNorm/Div_output_0:1"
input: "/embeddings/LayerNorm/Div_output_0:2"
input: "embeddings.LayerNorm.weight_min:0"
input: "embeddings.LayerNorm.weight_max:0"
output: "/embeddings/LayerNorm/Mul_output_0:0"
name: "/embeddings/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.061710815876722336
  zero_point: 189
  minval: -11.663344383239746
  maxval: 4.072913646697998
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/embeddings/LayerNorm/Mul_output_0:0"
input: "embeddings.LayerNorm.bias:0"
input: "/embeddings/LayerNorm/Mul_output_0:1"
input: "/embeddings/LayerNorm/Mul_output_0:2"
input: "embeddings.LayerNorm.bias_min:0"
input: "embeddings.LayerNorm.bias_max:0"
input: "/embeddings/LayerNorm/Add_1_output_0_min:0"
input: "/embeddings/LayerNorm/Add_1_output_0_max:0"
output: "/embeddings/LayerNorm/Add_1_output_0:0"
name: "/embeddings/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.05934906005859375
  zero_point: 183
  minval: -10.860877990722656
  maxval: 4.27313232421875
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/embeddings/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1325"
input: "/embeddings/LayerNorm/Add_1_output_0:1"
input: "/embeddings/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1325_min:0"
input: "onnx::MatMul_1325_max:0"
output: "/encoder/layer.0/attention/self/query/MatMul_output_0_matmul:0"
name: "/encoder/layer.0/attention/self/query/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03517516702413559
  zero_point: 127
  minval: -4.467246055603027
  maxval: 4.5024213790893555
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.0/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.0/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.0/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.0/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.0/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03517516702413559
  zero_point: 127
  minval: -4.467246055603027
  maxval: 4.5024213790893555
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.0.attention.self.query.bias:0"
input: "/encoder/layer.0/attention/self/query/MatMul_output_0:0"
input: "encoder.layer.0.attention.self.query.bias_min:0"
input: "encoder.layer.0.attention.self.query.bias_max:0"
input: "/encoder/layer.0/attention/self/query/MatMul_output_0:1"
input: "/encoder/layer.0/attention/self/query/MatMul_output_0:2"
input: "/encoder/layer.0/attention/self/query/Add_output_0_min:0"
input: "/encoder/layer.0/attention/self/query/Add_output_0_max:0"
output: "/encoder/layer.0/attention/self/query/Add_output_0:0"
name: "/encoder/layer.0/attention/self/query/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03553340956568718
  zero_point: 130
  minval: -4.619342803955078
  maxval: 4.441676139831543
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/query/Add_output_0:0"
input: "/encoder/layer.0/attention/self/Reshape_2/shape:0"
input: "/encoder/layer.0/attention/self/query/Add_output_0:1"
input: "/encoder/layer.0/attention/self/query/Add_output_0:2"
output: "/encoder/layer.0/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.0/attention/self/Reshape_2"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03553340956568718
  zero_point: 130
  minval: -4.619342803955078
  maxval: 4.441676139831543
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/Reshape_2_output_0:0"
input: "/encoder/layer.0/attention/self/Transpose_1/shape:0"
input: "/encoder/layer.0/attention/self/Reshape_2_output_0_min:0"
input: "/encoder/layer.0/attention/self/Reshape_2_output_0_max:0"
output: "/encoder/layer.0/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.0/attention/self/Transpose_1"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03553340956568718
  zero_point: 130
  minval: -4.619342803955078
  maxval: 4.441676139831543
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/embeddings/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1326"
input: "/embeddings/LayerNorm/Add_1_output_0:1"
input: "/embeddings/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1326_min:0"
input: "onnx::MatMul_1326_max:0"
output: "/encoder/layer.0/attention/self/key/MatMul_output_0_matmul:0"
name: "/encoder/layer.0/attention/self/key/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03920615836977959
  zero_point: 132
  minval: -5.175212860107422
  maxval: 4.822357654571533
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.0/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.0/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.0/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.0/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.0/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03920615836977959
  zero_point: 132
  minval: -5.175212860107422
  maxval: 4.822357654571533
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.0.attention.self.key.bias:0"
input: "/encoder/layer.0/attention/self/key/MatMul_output_0:0"
input: "encoder.layer.0.attention.self.key.bias_min:0"
input: "encoder.layer.0.attention.self.key.bias_max:0"
input: "/encoder/layer.0/attention/self/key/MatMul_output_0:1"
input: "/encoder/layer.0/attention/self/key/MatMul_output_0:2"
input: "/encoder/layer.0/attention/self/key/Add_output_0_min:0"
input: "/encoder/layer.0/attention/self/key/Add_output_0_max:0"
output: "/encoder/layer.0/attention/self/key/Add_output_0:0"
name: "/encoder/layer.0/attention/self/key/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.038939692080020905
  zero_point: 133
  minval: -5.17897891998291
  maxval: 4.7506422996521
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/key/Add_output_0:0"
input: "/encoder/layer.0/attention/self/Reshape/shape:0"
input: "/encoder/layer.0/attention/self/key/Add_output_0:1"
input: "/encoder/layer.0/attention/self/key/Add_output_0:2"
output: "/encoder/layer.0/attention/self/Reshape_output_0:0"
name: "/encoder/layer.0/attention/self/Reshape"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.038939692080020905
  zero_point: 133
  minval: -5.17897891998291
  maxval: 4.7506422996521
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/Reshape_output_0:0"
input: "/encoder/layer.0/attention/self/Transpose_2/shape:0"
input: "/encoder/layer.0/attention/self/Reshape_output_0_min:0"
input: "/encoder/layer.0/attention/self/Reshape_output_0_max:0"
output: "/encoder/layer.0/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.0/attention/self/Transpose_2"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.038939692080020905
  zero_point: 133
  minval: -5.17897891998291
  maxval: 4.7506422996521
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.0/attention/self/Transpose_2_output_0:0"
input: "/encoder/layer.0/attention/self/Transpose_1_output_0:1"
input: "/encoder/layer.0/attention/self/Transpose_1_output_0:2"
input: "/encoder/layer.0/attention/self/Transpose_2_output_0:1"
input: "/encoder/layer.0/attention/self/Transpose_2_output_0:2"
output: "/encoder/layer.0/attention/self/MatMul_output_0_batchmatmul:0"
name: "/encoder/layer.0/attention/self/MatMul_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.4610340893268585
  zero_point: 73
  minval: -33.655487060546875
  maxval: 83.908203125
}
padding: 0
out_max_byte_size: 1728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.0/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.0/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.0/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.0/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.0/attention/self/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.4610340893268585
  zero_point: 73
  minval: -33.655487060546875
  maxval: 83.908203125
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/MatMul_output_0:0"
input: "/encoder/layer.0/attention/self/Div/b:0"
input: "/encoder/layer.0/attention/self/MatMul_output_0:1"
input: "/encoder/layer.0/attention/self/MatMul_output_0:2"
input: "/encoder/layer.0/attention/self/Div/b_min:0"
input: "/encoder/layer.0/attention/self/Div/b_max:0"
input: "/encoder/layer.0/attention/self/Div_output_0_min:0"
input: "/encoder/layer.0/attention/self/Div_output_0_max:0"
output: "/encoder/layer.0/attention/self/Div_output_0:0"
name: "/encoder/layer.0/attention/self/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.05762925744056702
  zero_point: 73
  minval: -4.206935882568359
  maxval: 10.488525390625
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "token_type_ids:0"
output: "mace_input_node_token_type_ids:0"
name: "mace_input_node_token_type_ids"
type: "QuantizeINPUT_f_to_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "data_format"
  i: 0
}
arg {
  name: "find_range_every_time"
  i: 1
}
output_shape {
  dims: 1
  dims: 1
  dims: 1
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0078125
  zero_point: 128
  minval: -1.0
  maxval: 0.9921875
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "mace_input_node_token_type_ids:0"
input: "/Sub/b:0"
input: "mace_input_node_token_type_ids:1"
input: "mace_input_node_token_type_ids:2"
input: "/Sub/b_min:0"
input: "/Sub/b_max:0"
input: "/Sub_output_0_min:0"
input: "/Sub_output_0_max:0"
output: "/Sub_output_0:0"
name: "/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
arg {
  name: "scalar_input"
  f: 1.0
}
arg {
  name: "scalar_input_index"
  i: 0
}
output_shape {
  dims: 1
  dims: 1
  dims: 1
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/Sub_output_0:0"
input: "/Mul/b:0"
input: "/Sub_output_0:1"
input: "/Sub_output_0:2"
input: "/Mul/b_min:0"
input: "/Mul/b_max:0"
output: "/Mul_output_0:0"
name: "/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: -3.4028234663852886e+38
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 1
  dims: 1
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 1.334439148946129e+36
  zero_point: 255
  minval: -3.402820018375656e+38
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/Div_output_0:0"
input: "/Mul_output_0:0"
input: "/encoder/layer.0/attention/self/Div_output_0:1"
input: "/encoder/layer.0/attention/self/Div_output_0:2"
input: "/Mul_output_0:1"
input: "/Mul_output_0:2"
input: "/encoder/layer.0/attention/self/Add_output_0_min:0"
input: "/encoder/layer.0/attention/self/Add_output_0_max:0"
output: "/encoder/layer.0/attention/self/Add_output_0:0"
name: "/encoder/layer.0/attention/self/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/Add_output_0:0"
input: "/encoder/layer.0/attention/self/Add_output_0:1"
input: "/encoder/layer.0/attention/self/Add_output_0:2"
output: "/encoder/layer.0/attention/self/Softmax_output_0:0"
name: "/encoder/layer.0/attention/self/Softmax"
type: "QuantizedSoftmax_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/embeddings/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1332"
input: "/embeddings/LayerNorm/Add_1_output_0:1"
input: "/embeddings/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1332_min:0"
input: "onnx::MatMul_1332_max:0"
output: "/encoder/layer.0/attention/self/value/MatMul_output_0_matmul:0"
name: "/encoder/layer.0/attention/self/value/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.020430883392691612
  zero_point: 129
  minval: -2.6355841159820557
  maxval: 2.574291467666626
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.0/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.0/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.0/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.0/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.0/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.0/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.020430883392691612
  zero_point: 129
  minval: -2.6355841159820557
  maxval: 2.574291467666626
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.0.attention.self.value.bias:0"
input: "/encoder/layer.0/attention/self/value/MatMul_output_0:0"
input: "encoder.layer.0.attention.self.value.bias_min:0"
input: "encoder.layer.0.attention.self.value.bias_max:0"
input: "/encoder/layer.0/attention/self/value/MatMul_output_0:1"
input: "/encoder/layer.0/attention/self/value/MatMul_output_0:2"
input: "/encoder/layer.0/attention/self/value/Add_output_0_min:0"
input: "/encoder/layer.0/attention/self/value/Add_output_0_max:0"
output: "/encoder/layer.0/attention/self/value/Add_output_0:0"
name: "/encoder/layer.0/attention/self/value/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02018621936440468
  zero_point: 128
  minval: -2.583836078643799
  maxval: 2.563649892807007
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/value/Add_output_0:0"
input: "/encoder/layer.0/attention/self/Reshape_1/shape:0"
input: "/encoder/layer.0/attention/self/value/Add_output_0:1"
input: "/encoder/layer.0/attention/self/value/Add_output_0:2"
output: "/encoder/layer.0/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.0/attention/self/Reshape_1"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02018621936440468
  zero_point: 128
  minval: -2.583836078643799
  maxval: 2.563649892807007
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/Reshape_1_output_0:0"
input: "/encoder/layer.0/attention/self/Transpose/shape:0"
input: "/encoder/layer.0/attention/self/Reshape_1_output_0_min:0"
input: "/encoder/layer.0/attention/self/Reshape_1_output_0_max:0"
output: "/encoder/layer.0/attention/self/Transpose_output_0:0"
name: "/encoder/layer.0/attention/self/Transpose"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02018621936440468
  zero_point: 128
  minval: -2.583836078643799
  maxval: 2.563649892807007
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/Softmax_output_0:0"
input: "/encoder/layer.0/attention/self/Transpose_output_0:0"
input: "/encoder/layer.0/attention/self/Softmax_output_0:1"
input: "/encoder/layer.0/attention/self/Softmax_output_0:2"
input: "/encoder/layer.0/attention/self/Transpose_output_0:1"
input: "/encoder/layer.0/attention/self/Transpose_output_0:2"
output: "/encoder/layer.0/attention/self/MatMul_1_output_0_batchmatmul:0"
name: "/encoder/layer.0/attention/self/MatMul_1_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010315447114408016
  zero_point: 105
  minval: -1.0831218957901
  maxval: 1.5473170280456543
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.0/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.0/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.0/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.0/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.0/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.0/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010315447114408016
  zero_point: 105
  minval: -1.0831218957901
  maxval: 1.5473170280456543
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/MatMul_1_output_0:0"
input: "/encoder/layer.0/attention/self/Transpose_3/shape:0"
input: "/encoder/layer.0/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.0/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.0/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.0/attention/self/Transpose_3"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010315447114408016
  zero_point: 105
  minval: -1.0831218957901
  maxval: 1.5473170280456543
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/Transpose_3_output_0:0"
input: "/encoder/layer.0/attention/self/Reshape_3/shape:0"
input: "/encoder/layer.0/attention/self/Transpose_3_output_0:1"
input: "/encoder/layer.0/attention/self/Transpose_3_output_0:2"
output: "/encoder/layer.0/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.0/attention/self/Reshape_3"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010315447114408016
  zero_point: 105
  minval: -1.0831218957901
  maxval: 1.5473170280456543
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1347"
input: "/encoder/layer.0/attention/self/Reshape_3_output_0:1"
input: "/encoder/layer.0/attention/self/Reshape_3_output_0:2"
input: "onnx::MatMul_1347_min:0"
input: "onnx::MatMul_1347_max:0"
output: "/encoder/layer.0/attention/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.0/attention/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.009964870288968086
  zero_point: 132
  minval: -1.315362811088562
  maxval: 1.2256790399551392
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.0/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.0/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.0/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.0/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.0/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.0/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.009964870288968086
  zero_point: 132
  minval: -1.315362811088562
  maxval: 1.2256790399551392
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.0.attention.output.dense.bias:0"
input: "/encoder/layer.0/attention/output/dense/MatMul_output_0:0"
input: "encoder.layer.0.attention.output.dense.bias_min:0"
input: "encoder.layer.0.attention.output.dense.bias_max:0"
input: "/encoder/layer.0/attention/output/dense/MatMul_output_0:1"
input: "/encoder/layer.0/attention/output/dense/MatMul_output_0:2"
input: "/encoder/layer.0/attention/output/dense/Add_output_0_min:0"
input: "/encoder/layer.0/attention/output/dense/Add_output_0_max:0"
output: "/encoder/layer.0/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.0/attention/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010293197818100452
  zero_point: 139
  minval: -1.430754542350769
  maxval: 1.1940109729766846
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/output/dense/Add_output_0:0"
input: "/embeddings/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.0/attention/output/dense/Add_output_0:1"
input: "/encoder/layer.0/attention/output/dense/Add_output_0:2"
input: "/embeddings/LayerNorm/Add_1_output_0:1"
input: "/embeddings/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.0/attention/output/Add_output_0_min:0"
input: "/encoder/layer.0/attention/output/Add_output_0_max:0"
output: "/encoder/layer.0/attention/output/Add_output_0:0"
name: "/encoder/layer.0/attention/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06361788511276245
  zero_point: 188
  minval: -11.960162162780762
  maxval: 4.2623982429504395
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/output/Add_output_0:0"
input: "/encoder/layer.0/attention/output/Add_output_0:1"
input: "/encoder/layer.0/attention/output/Add_output_0:2"
input: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0001986449642572552
  zero_point: 169
  minval: -0.03357100114226341
  maxval: 0.017083467915654182
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/output/Add_output_0:0"
input: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.0/attention/output/Add_output_0:1"
input: "/encoder/layer.0/attention/output/Add_output_0:2"
input: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.0/attention/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.0/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06373735517263412
  zero_point: 188
  minval: -11.982623100280762
  maxval: 4.270402908325195
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.0/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.0/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.0/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.0/attention/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.0/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.5578179359436035
  zero_point: 0
  minval: 0.0
  maxval: 142.2435760498047
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.0/attention/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0018497842829674482
  zero_point: 0
  minval: 0.0
  maxval: 0.4716950058937073
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Add/b:0"
input: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.0/attention/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.0/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0018497842829674482
  zero_point: 0
  minval: 0.0
  maxval: 0.4716950058937073
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.0/attention/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0026933334302157164
  zero_point: 0
  minval: 0.0
  maxval: 0.6868000030517578
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.0/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.0/attention/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.0/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.10432182252407074
  zero_point: 188
  minval: -19.612503051757812
  maxval: 6.989562034606934
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.0.attention.output.LayerNorm.weight:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.0/attention/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.0.attention.output.LayerNorm.weight_min:0"
input: "encoder.layer.0.attention.output.LayerNorm.weight_max:0"
output: "/encoder/layer.0/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.257788747549057
  zero_point: 227
  minval: -58.51804733276367
  maxval: 7.218085289001465
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.0.attention.output.LayerNorm.bias:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.0/attention/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.0.attention.output.LayerNorm.bias_min:0"
input: "encoder.layer.0.attention.output.LayerNorm.bias_max:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.0/attention/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.27152684330940247
  zero_point: 231
  minval: -62.72270202636719
  maxval: 6.516644477844238
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1348"
input: "/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1348_min:0"
input: "onnx::MatMul_1348_max:0"
output: "/encoder/layer.0/intermediate/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.0/intermediate/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.10121992975473404
  zero_point: 167
  minval: -16.903728485107422
  maxval: 8.907354354858398
}
padding: 0
out_max_byte_size: 73728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.0/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.0/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.0/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.0/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.0/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.0/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.10121992975473404
  zero_point: 167
  minval: -16.903728485107422
  maxval: 8.907354354858398
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/intermediate/dense/MatMul_output_0:0"
input: "/encoder/layer.0/intermediate/dense/MatMul_output_0:1"
input: "/encoder/layer.0/intermediate/dense/MatMul_output_0:2"
output: "/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1"
type: "QuantizedGelu_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03518608585000038
  zero_point: 5
  minval: -0.1759304255247116
  maxval: 8.796521186828613
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1349"
input: "/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0:1"
input: "/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0:2"
input: "onnx::MatMul_1349_min:0"
input: "onnx::MatMul_1349_max:0"
output: "/encoder/layer.0/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.0/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06505445390939713
  zero_point: 218
  minval: -14.18187141418457
  maxval: 2.407014846801758
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.0/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.0/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.0/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.0/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.0/output/dense/MatMul_output_0:0"
name: "/encoder/layer.0/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06505445390939713
  zero_point: 218
  minval: -14.18187141418457
  maxval: 2.407014846801758
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.0.output.dense.bias:0"
input: "/encoder/layer.0/output/dense/MatMul_output_0:0"
input: "encoder.layer.0.output.dense.bias_min:0"
input: "encoder.layer.0.output.dense.bias_max:0"
input: "/encoder/layer.0/output/dense/MatMul_output_0:1"
input: "/encoder/layer.0/output/dense/MatMul_output_0:2"
input: "/encoder/layer.0/output/dense/Add_output_0_min:0"
input: "/encoder/layer.0/output/dense/Add_output_0_max:0"
output: "/encoder/layer.0/output/dense/Add_output_0:0"
name: "/encoder/layer.0/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0642833262681961
  zero_point: 220
  minval: -14.142332077026367
  maxval: 2.2499165534973145
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/output/dense/Add_output_0:0"
input: "/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.0/output/dense/Add_output_0:1"
input: "/encoder/layer.0/output/dense/Add_output_0:2"
input: "/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.0/output/Add_output_0_min:0"
input: "/encoder/layer.0/output/Add_output_0_max:0"
output: "/encoder/layer.0/output/Add_output_0:0"
name: "/encoder/layer.0/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.27091291546821594
  zero_point: 228
  minval: -61.76814651489258
  maxval: 7.3146491050720215
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/output/Add_output_0:0"
input: "/encoder/layer.0/output/Add_output_0:1"
input: "/encoder/layer.0/output/Add_output_0:2"
input: "/encoder/layer.0/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.0/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.0/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.0/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.00031935295555740595
  zero_point: 255
  minval: -0.08143500238656998
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/output/Add_output_0:0"
input: "/encoder/layer.0/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.0/output/Add_output_0:1"
input: "/encoder/layer.0/output/Add_output_0:2"
input: "/encoder/layer.0/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.0/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.0/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.0/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.0/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2705557346343994
  zero_point: 228
  minval: -61.686710357666016
  maxval: 7.305005073547363
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.0/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.0/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.0/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.0/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.0/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.0/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.0/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.0/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 14.922550201416016
  zero_point: 0
  minval: 0.0
  maxval: 3805.250244140625
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.0/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.0/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.0/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02292449399828911
  zero_point: 0
  minval: 0.0
  maxval: 5.845746040344238
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.0/output/LayerNorm/Add/b:0"
input: "/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.0/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.0/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.0/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.0/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.0/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02292449399828911
  zero_point: 0
  minval: 0.0
  maxval: 5.845746040344238
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.0/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.0/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.0/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.009481560438871384
  zero_point: 0
  minval: 0.0
  maxval: 2.4177980422973633
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.0/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.0/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.0/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.0/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.0/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.0/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.0/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.0/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.11190173029899597
  zero_point: 228
  minval: -25.513593673706055
  maxval: 3.0213465690612793
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.0.output.LayerNorm.weight:0"
input: "/encoder/layer.0/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.0/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.0.output.LayerNorm.weight_min:0"
input: "encoder.layer.0.output.LayerNorm.weight_max:0"
output: "/encoder/layer.0/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04254244267940521
  zero_point: 206
  minval: -8.76374340057373
  maxval: 2.0845797061920166
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.0.output.LayerNorm.bias:0"
input: "/encoder/layer.0/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.0/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.0.output.LayerNorm.bias_min:0"
input: "encoder.layer.0.output.LayerNorm.bias_max:0"
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.0/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04804582893848419
  zero_point: 210
  minval: -10.089624404907227
  maxval: 2.162062168121338
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1350"
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1350_min:0"
input: "onnx::MatMul_1350_max:0"
output: "/encoder/layer.1/attention/self/query/MatMul_output_0_matmul:0"
name: "/encoder/layer.1/attention/self/query/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.036228954792022705
  zero_point: 133
  minval: -4.818450927734375
  maxval: 4.4199323654174805
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.1/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.1/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.1/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.1/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.1/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.036228954792022705
  zero_point: 133
  minval: -4.818450927734375
  maxval: 4.4199323654174805
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.1.attention.self.query.bias:0"
input: "/encoder/layer.1/attention/self/query/MatMul_output_0:0"
input: "encoder.layer.1.attention.self.query.bias_min:0"
input: "encoder.layer.1.attention.self.query.bias_max:0"
input: "/encoder/layer.1/attention/self/query/MatMul_output_0:1"
input: "/encoder/layer.1/attention/self/query/MatMul_output_0:2"
input: "/encoder/layer.1/attention/self/query/Add_output_0_min:0"
input: "/encoder/layer.1/attention/self/query/Add_output_0_max:0"
output: "/encoder/layer.1/attention/self/query/Add_output_0:0"
name: "/encoder/layer.1/attention/self/query/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03851192817091942
  zero_point: 126
  minval: -4.852502822875977
  maxval: 4.968038558959961
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/query/Add_output_0:0"
input: "/encoder/layer.1/attention/self/Reshape_2/shape:0"
input: "/encoder/layer.1/attention/self/query/Add_output_0:1"
input: "/encoder/layer.1/attention/self/query/Add_output_0:2"
output: "/encoder/layer.1/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.1/attention/self/Reshape_2"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03851192817091942
  zero_point: 126
  minval: -4.852502822875977
  maxval: 4.968038558959961
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/Reshape_2_output_0:0"
input: "/encoder/layer.1/attention/self/Transpose_1/shape:0"
input: "/encoder/layer.1/attention/self/Reshape_2_output_0_min:0"
input: "/encoder/layer.1/attention/self/Reshape_2_output_0_max:0"
output: "/encoder/layer.1/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.1/attention/self/Transpose_1"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03851192817091942
  zero_point: 126
  minval: -4.852502822875977
  maxval: 4.968038558959961
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1351"
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1351_min:0"
input: "onnx::MatMul_1351_max:0"
output: "/encoder/layer.1/attention/self/key/MatMul_output_0_matmul:0"
name: "/encoder/layer.1/attention/self/key/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.041271936148405075
  zero_point: 129
  minval: -5.324079990386963
  maxval: 5.200263977050781
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.1/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.1/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.1/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.1/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.1/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.041271936148405075
  zero_point: 129
  minval: -5.324079990386963
  maxval: 5.200263977050781
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.1.attention.self.key.bias:0"
input: "/encoder/layer.1/attention/self/key/MatMul_output_0:0"
input: "encoder.layer.1.attention.self.key.bias_min:0"
input: "encoder.layer.1.attention.self.key.bias_max:0"
input: "/encoder/layer.1/attention/self/key/MatMul_output_0:1"
input: "/encoder/layer.1/attention/self/key/MatMul_output_0:2"
input: "/encoder/layer.1/attention/self/key/Add_output_0_min:0"
input: "/encoder/layer.1/attention/self/key/Add_output_0_max:0"
output: "/encoder/layer.1/attention/self/key/Add_output_0:0"
name: "/encoder/layer.1/attention/self/key/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0412733294069767
  zero_point: 128
  minval: -5.282986164093018
  maxval: 5.24171257019043
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/key/Add_output_0:0"
input: "/encoder/layer.1/attention/self/Reshape/shape:0"
input: "/encoder/layer.1/attention/self/key/Add_output_0:1"
input: "/encoder/layer.1/attention/self/key/Add_output_0:2"
output: "/encoder/layer.1/attention/self/Reshape_output_0:0"
name: "/encoder/layer.1/attention/self/Reshape"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0412733294069767
  zero_point: 128
  minval: -5.282986164093018
  maxval: 5.24171257019043
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/Reshape_output_0:0"
input: "/encoder/layer.1/attention/self/Transpose_2/shape:0"
input: "/encoder/layer.1/attention/self/Reshape_output_0_min:0"
input: "/encoder/layer.1/attention/self/Reshape_output_0_max:0"
output: "/encoder/layer.1/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.1/attention/self/Transpose_2"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0412733294069767
  zero_point: 128
  minval: -5.282986164093018
  maxval: 5.24171257019043
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.1/attention/self/Transpose_2_output_0:0"
input: "/encoder/layer.1/attention/self/Transpose_1_output_0:1"
input: "/encoder/layer.1/attention/self/Transpose_1_output_0:2"
input: "/encoder/layer.1/attention/self/Transpose_2_output_0:1"
input: "/encoder/layer.1/attention/self/Transpose_2_output_0:2"
output: "/encoder/layer.1/attention/self/MatMul_output_0_batchmatmul:0"
name: "/encoder/layer.1/attention/self/MatMul_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.5172810554504395
  zero_point: 75
  minval: -38.796077728271484
  maxval: 93.11058807373047
}
padding: 0
out_max_byte_size: 1728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.1/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.1/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.1/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.1/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.1/attention/self/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.5172810554504395
  zero_point: 75
  minval: -38.796077728271484
  maxval: 93.11058807373047
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/MatMul_output_0:0"
input: "/encoder/layer.1/attention/self/Div/b:0"
input: "/encoder/layer.1/attention/self/MatMul_output_0:1"
input: "/encoder/layer.1/attention/self/MatMul_output_0:2"
input: "/encoder/layer.1/attention/self/Div/b_min:0"
input: "/encoder/layer.1/attention/self/Div/b_max:0"
input: "/encoder/layer.1/attention/self/Div_output_0_min:0"
input: "/encoder/layer.1/attention/self/Div_output_0_max:0"
output: "/encoder/layer.1/attention/self/Div_output_0:0"
name: "/encoder/layer.1/attention/self/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06466013193130493
  zero_point: 75
  minval: -4.849510192871094
  maxval: 11.638824462890625
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/Div_output_0:0"
input: "/Mul_output_0:0"
input: "/encoder/layer.1/attention/self/Div_output_0:1"
input: "/encoder/layer.1/attention/self/Div_output_0:2"
input: "/Mul_output_0:1"
input: "/Mul_output_0:2"
input: "/encoder/layer.1/attention/self/Add_output_0_min:0"
input: "/encoder/layer.1/attention/self/Add_output_0_max:0"
output: "/encoder/layer.1/attention/self/Add_output_0:0"
name: "/encoder/layer.1/attention/self/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/Add_output_0:0"
input: "/encoder/layer.1/attention/self/Add_output_0:1"
input: "/encoder/layer.1/attention/self/Add_output_0:2"
output: "/encoder/layer.1/attention/self/Softmax_output_0:0"
name: "/encoder/layer.1/attention/self/Softmax"
type: "QuantizedSoftmax_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1357"
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1357_min:0"
input: "onnx::MatMul_1357_max:0"
output: "/encoder/layer.1/attention/self/value/MatMul_output_0_matmul:0"
name: "/encoder/layer.1/attention/self/value/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01952419988811016
  zero_point: 115
  minval: -2.2452828884124756
  maxval: 2.7333879470825195
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.1/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.1/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.1/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.1/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.1/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.1/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01952419988811016
  zero_point: 115
  minval: -2.2452828884124756
  maxval: 2.7333879470825195
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.1.attention.self.value.bias:0"
input: "/encoder/layer.1/attention/self/value/MatMul_output_0:0"
input: "encoder.layer.1.attention.self.value.bias_min:0"
input: "encoder.layer.1.attention.self.value.bias_max:0"
input: "/encoder/layer.1/attention/self/value/MatMul_output_0:1"
input: "/encoder/layer.1/attention/self/value/MatMul_output_0:2"
input: "/encoder/layer.1/attention/self/value/Add_output_0_min:0"
input: "/encoder/layer.1/attention/self/value/Add_output_0_max:0"
output: "/encoder/layer.1/attention/self/value/Add_output_0:0"
name: "/encoder/layer.1/attention/self/value/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.019675493240356445
  zero_point: 113
  minval: -2.2233307361602783
  maxval: 2.7939200401306152
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/value/Add_output_0:0"
input: "/encoder/layer.1/attention/self/Reshape_1/shape:0"
input: "/encoder/layer.1/attention/self/value/Add_output_0:1"
input: "/encoder/layer.1/attention/self/value/Add_output_0:2"
output: "/encoder/layer.1/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.1/attention/self/Reshape_1"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.019675493240356445
  zero_point: 113
  minval: -2.2233307361602783
  maxval: 2.7939200401306152
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/Reshape_1_output_0:0"
input: "/encoder/layer.1/attention/self/Transpose/shape:0"
input: "/encoder/layer.1/attention/self/Reshape_1_output_0_min:0"
input: "/encoder/layer.1/attention/self/Reshape_1_output_0_max:0"
output: "/encoder/layer.1/attention/self/Transpose_output_0:0"
name: "/encoder/layer.1/attention/self/Transpose"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.019675493240356445
  zero_point: 113
  minval: -2.2233307361602783
  maxval: 2.7939200401306152
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/Softmax_output_0:0"
input: "/encoder/layer.1/attention/self/Transpose_output_0:0"
input: "/encoder/layer.1/attention/self/Softmax_output_0:1"
input: "/encoder/layer.1/attention/self/Softmax_output_0:2"
input: "/encoder/layer.1/attention/self/Transpose_output_0:1"
input: "/encoder/layer.1/attention/self/Transpose_output_0:2"
output: "/encoder/layer.1/attention/self/MatMul_1_output_0_batchmatmul:0"
name: "/encoder/layer.1/attention/self/MatMul_1_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.011402285657823086
  zero_point: 122
  minval: -1.3910788297653198
  maxval: 1.5165040493011475
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.1/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.1/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.1/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.1/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.1/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.1/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.011402285657823086
  zero_point: 122
  minval: -1.3910788297653198
  maxval: 1.5165040493011475
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/MatMul_1_output_0:0"
input: "/encoder/layer.1/attention/self/Transpose_3/shape:0"
input: "/encoder/layer.1/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.1/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.1/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.1/attention/self/Transpose_3"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.011402285657823086
  zero_point: 122
  minval: -1.3910788297653198
  maxval: 1.5165040493011475
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/Transpose_3_output_0:0"
input: "/encoder/layer.1/attention/self/Reshape_3/shape:0"
input: "/encoder/layer.1/attention/self/Transpose_3_output_0:1"
input: "/encoder/layer.1/attention/self/Transpose_3_output_0:2"
output: "/encoder/layer.1/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.1/attention/self/Reshape_3"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.011402285657823086
  zero_point: 122
  minval: -1.3910788297653198
  maxval: 1.5165040493011475
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1372"
input: "/encoder/layer.1/attention/self/Reshape_3_output_0:1"
input: "/encoder/layer.1/attention/self/Reshape_3_output_0:2"
input: "onnx::MatMul_1372_min:0"
input: "onnx::MatMul_1372_max:0"
output: "/encoder/layer.1/attention/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.1/attention/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.008185404352843761
  zero_point: 104
  minval: -0.851282000541687
  maxval: 1.2359960079193115
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.1/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.1/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.1/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.1/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.1/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.1/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.008185404352843761
  zero_point: 104
  minval: -0.851282000541687
  maxval: 1.2359960079193115
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.1.attention.output.dense.bias:0"
input: "/encoder/layer.1/attention/output/dense/MatMul_output_0:0"
input: "encoder.layer.1.attention.output.dense.bias_min:0"
input: "encoder.layer.1.attention.output.dense.bias_max:0"
input: "/encoder/layer.1/attention/output/dense/MatMul_output_0:1"
input: "/encoder/layer.1/attention/output/dense/MatMul_output_0:2"
input: "/encoder/layer.1/attention/output/dense/Add_output_0_min:0"
input: "/encoder/layer.1/attention/output/dense/Add_output_0_max:0"
output: "/encoder/layer.1/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.1/attention/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0076732337474823
  zero_point: 101
  minval: -0.7749966382980347
  maxval: 1.181678056716919
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/output/dense/Add_output_0:0"
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.1/attention/output/dense/Add_output_0:1"
input: "/encoder/layer.1/attention/output/dense/Add_output_0:2"
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.0/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.1/attention/output/Add_output_0_min:0"
input: "/encoder/layer.1/attention/output/Add_output_0_max:0"
output: "/encoder/layer.1/attention/output/Add_output_0:0"
name: "/encoder/layer.1/attention/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.050185151398181915
  zero_point: 210
  minval: -10.5388822555542
  maxval: 2.258331775665283
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/output/Add_output_0:0"
input: "/encoder/layer.1/attention/output/Add_output_0:1"
input: "/encoder/layer.1/attention/output/Add_output_0:2"
input: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 8.013725164346397e-05
  zero_point: 255
  minval: -0.020434999838471413
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/output/Add_output_0:0"
input: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.1/attention/output/Add_output_0:1"
input: "/encoder/layer.1/attention/output/Add_output_0:2"
input: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.1/attention/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.1/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.05023377761244774
  zero_point: 210
  minval: -10.549093246459961
  maxval: 2.2605199813842773
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.1/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.1/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.1/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.1/attention/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.1/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.4344174265861511
  zero_point: 0
  minval: 0.0
  maxval: 110.77644348144531
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.1/attention/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.002213074592873454
  zero_point: 0
  minval: 0.0
  maxval: 0.564333975315094
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Add/b:0"
input: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.1/attention/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.1/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.002213074592873454
  zero_point: 0
  minval: 0.0
  maxval: 0.564333975315094
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.1/attention/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.002945968648418784
  zero_point: 0
  minval: 0.0
  maxval: 0.7512220144271851
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.1/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.1/attention/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.1/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.09657789766788483
  zero_point: 215
  minval: -20.76424789428711
  maxval: 3.8631160259246826
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.1.attention.output.LayerNorm.weight:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.1/attention/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.1.attention.output.LayerNorm.weight_min:0"
input: "encoder.layer.1.attention.output.LayerNorm.weight_max:0"
output: "/encoder/layer.1/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2592984139919281
  zero_point: 243
  minval: -63.009517669677734
  maxval: 3.1115810871124268
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.1.attention.output.LayerNorm.bias:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.1/attention/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.1.attention.output.LayerNorm.bias_min:0"
input: "encoder.layer.1.attention.output.LayerNorm.bias_max:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.1/attention/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2705458998680115
  zero_point: 242
  minval: -65.47210693359375
  maxval: 3.517096757888794
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1373"
input: "/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1373_min:0"
input: "onnx::MatMul_1373_max:0"
output: "/encoder/layer.1/intermediate/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.1/intermediate/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.08946271240711212
  zero_point: 164
  minval: -14.671884536743164
  maxval: 8.141106605529785
}
padding: 0
out_max_byte_size: 73728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.1/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.1/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.1/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.1/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.1/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.1/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.08946271240711212
  zero_point: 164
  minval: -14.671884536743164
  maxval: 8.141106605529785
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/intermediate/dense/MatMul_output_0:0"
input: "/encoder/layer.1/intermediate/dense/MatMul_output_0:1"
input: "/encoder/layer.1/intermediate/dense/MatMul_output_0:2"
output: "/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1"
type: "QuantizedGelu_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03194340318441391
  zero_point: 6
  minval: -0.19166040420532227
  maxval: 7.953907012939453
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1374"
input: "/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0:1"
input: "/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0:2"
input: "onnx::MatMul_1374_min:0"
input: "onnx::MatMul_1374_max:0"
output: "/encoder/layer.1/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.1/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.069577157497406
  zero_point: 217
  minval: -15.09824275970459
  maxval: 2.6439318656921387
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.1/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.1/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.1/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.1/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.1/output/dense/MatMul_output_0:0"
name: "/encoder/layer.1/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.069577157497406
  zero_point: 217
  minval: -15.09824275970459
  maxval: 2.6439318656921387
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.1.output.dense.bias:0"
input: "/encoder/layer.1/output/dense/MatMul_output_0:0"
input: "encoder.layer.1.output.dense.bias_min:0"
input: "encoder.layer.1.output.dense.bias_max:0"
input: "/encoder/layer.1/output/dense/MatMul_output_0:1"
input: "/encoder/layer.1/output/dense/MatMul_output_0:2"
input: "/encoder/layer.1/output/dense/Add_output_0_min:0"
input: "/encoder/layer.1/output/dense/Add_output_0_max:0"
output: "/encoder/layer.1/output/dense/Add_output_0:0"
name: "/encoder/layer.1/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06840097159147263
  zero_point: 221
  minval: -15.11661434173584
  maxval: 2.3256328105926514
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/output/dense/Add_output_0:0"
input: "/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.1/output/dense/Add_output_0:1"
input: "/encoder/layer.1/output/dense/Add_output_0:2"
input: "/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.1/output/Add_output_0_min:0"
input: "/encoder/layer.1/output/Add_output_0_max:0"
output: "/encoder/layer.1/output/Add_output_0:0"
name: "/encoder/layer.1/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.28321373462677
  zero_point: 243
  minval: -68.82093811035156
  maxval: 3.3985648155212402
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/output/Add_output_0:0"
input: "/encoder/layer.1/output/Add_output_0:1"
input: "/encoder/layer.1/output/Add_output_0:2"
input: "/encoder/layer.1/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.1/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.1/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.1/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0003665372496470809
  zero_point: 255
  minval: -0.09346699714660645
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/output/Add_output_0:0"
input: "/encoder/layer.1/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.1/output/Add_output_0:1"
input: "/encoder/layer.1/output/Add_output_0:2"
input: "/encoder/layer.1/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.1/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.1/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.1/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.1/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2839978039264679
  zero_point: 242
  minval: -68.72747039794922
  maxval: 3.69197154045105
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.1/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.1/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.1/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.1/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.1/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.1/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.1/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.1/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 18.523393630981445
  zero_point: 0
  minval: 0.0
  maxval: 4723.46533203125
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.1/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.1/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.1/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02659711427986622
  zero_point: 0
  minval: 0.0
  maxval: 6.782264232635498
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.1/output/LayerNorm/Add/b:0"
input: "/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.1/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.1/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.1/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.1/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.1/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02659711427986622
  zero_point: 0
  minval: 0.0
  maxval: 6.782264232635498
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.1/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.1/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.1/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010212854482233524
  zero_point: 0
  minval: 0.0
  maxval: 2.604278087615967
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.1/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.1/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.1/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.1/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.1/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.1/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.1/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.1/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.11424338817596436
  zero_point: 231
  minval: -26.390222549438477
  maxval: 2.7418413162231445
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.1.output.LayerNorm.weight:0"
input: "/encoder/layer.1/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.1/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.1.output.LayerNorm.weight_min:0"
input: "encoder.layer.1.output.LayerNorm.weight_max:0"
output: "/encoder/layer.1/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.049781642854213715
  zero_point: 212
  minval: -10.55370807647705
  maxval: 2.140610694885254
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.1.output.LayerNorm.bias:0"
input: "/encoder/layer.1/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.1/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.1.output.LayerNorm.bias_min:0"
input: "encoder.layer.1.output.LayerNorm.bias_max:0"
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.1/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.05199756845831871
  zero_point: 216
  minval: -11.231474876403809
  maxval: 2.027905225753784
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1375"
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1375_min:0"
input: "onnx::MatMul_1375_max:0"
output: "/encoder/layer.2/attention/self/query/MatMul_output_0_matmul:0"
name: "/encoder/layer.2/attention/self/query/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04154577851295471
  zero_point: 138
  minval: -5.7333173751831055
  maxval: 4.860856056213379
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.2/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.2/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.2/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.2/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.2/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04154577851295471
  zero_point: 138
  minval: -5.7333173751831055
  maxval: 4.860856056213379
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.2.attention.self.query.bias:0"
input: "/encoder/layer.2/attention/self/query/MatMul_output_0:0"
input: "encoder.layer.2.attention.self.query.bias_min:0"
input: "encoder.layer.2.attention.self.query.bias_max:0"
input: "/encoder/layer.2/attention/self/query/MatMul_output_0:1"
input: "/encoder/layer.2/attention/self/query/MatMul_output_0:2"
input: "/encoder/layer.2/attention/self/query/Add_output_0_min:0"
input: "/encoder/layer.2/attention/self/query/Add_output_0_max:0"
output: "/encoder/layer.2/attention/self/query/Add_output_0:0"
name: "/encoder/layer.2/attention/self/query/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04506297782063484
  zero_point: 145
  minval: -6.53413200378418
  maxval: 4.95692777633667
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/query/Add_output_0:0"
input: "/encoder/layer.2/attention/self/Reshape_2/shape:0"
input: "/encoder/layer.2/attention/self/query/Add_output_0:1"
input: "/encoder/layer.2/attention/self/query/Add_output_0:2"
output: "/encoder/layer.2/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.2/attention/self/Reshape_2"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04506297782063484
  zero_point: 145
  minval: -6.53413200378418
  maxval: 4.95692777633667
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/Reshape_2_output_0:0"
input: "/encoder/layer.2/attention/self/Transpose_1/shape:0"
input: "/encoder/layer.2/attention/self/Reshape_2_output_0_min:0"
input: "/encoder/layer.2/attention/self/Reshape_2_output_0_max:0"
output: "/encoder/layer.2/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.2/attention/self/Transpose_1"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04506297782063484
  zero_point: 145
  minval: -6.53413200378418
  maxval: 4.95692777633667
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1376"
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1376_min:0"
input: "onnx::MatMul_1376_max:0"
output: "/encoder/layer.2/attention/self/key/MatMul_output_0_matmul:0"
name: "/encoder/layer.2/attention/self/key/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04573328047990799
  zero_point: 138
  minval: -6.311192989349365
  maxval: 5.350793838500977
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.2/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.2/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.2/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.2/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.2/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04573328047990799
  zero_point: 138
  minval: -6.311192989349365
  maxval: 5.350793838500977
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.2.attention.self.key.bias:0"
input: "/encoder/layer.2/attention/self/key/MatMul_output_0:0"
input: "encoder.layer.2.attention.self.key.bias_min:0"
input: "encoder.layer.2.attention.self.key.bias_max:0"
input: "/encoder/layer.2/attention/self/key/MatMul_output_0:1"
input: "/encoder/layer.2/attention/self/key/MatMul_output_0:2"
input: "/encoder/layer.2/attention/self/key/Add_output_0_min:0"
input: "/encoder/layer.2/attention/self/key/Add_output_0_max:0"
output: "/encoder/layer.2/attention/self/key/Add_output_0:0"
name: "/encoder/layer.2/attention/self/key/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.045686282217502594
  zero_point: 138
  minval: -6.304707050323486
  maxval: 5.345294952392578
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/key/Add_output_0:0"
input: "/encoder/layer.2/attention/self/Reshape/shape:0"
input: "/encoder/layer.2/attention/self/key/Add_output_0:1"
input: "/encoder/layer.2/attention/self/key/Add_output_0:2"
output: "/encoder/layer.2/attention/self/Reshape_output_0:0"
name: "/encoder/layer.2/attention/self/Reshape"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.045686282217502594
  zero_point: 138
  minval: -6.304707050323486
  maxval: 5.345294952392578
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/Reshape_output_0:0"
input: "/encoder/layer.2/attention/self/Transpose_2/shape:0"
input: "/encoder/layer.2/attention/self/Reshape_output_0_min:0"
input: "/encoder/layer.2/attention/self/Reshape_output_0_max:0"
output: "/encoder/layer.2/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.2/attention/self/Transpose_2"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.045686282217502594
  zero_point: 138
  minval: -6.304707050323486
  maxval: 5.345294952392578
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.2/attention/self/Transpose_2_output_0:0"
input: "/encoder/layer.2/attention/self/Transpose_1_output_0:1"
input: "/encoder/layer.2/attention/self/Transpose_1_output_0:2"
input: "/encoder/layer.2/attention/self/Transpose_2_output_0:1"
input: "/encoder/layer.2/attention/self/Transpose_2_output_0:2"
output: "/encoder/layer.2/attention/self/MatMul_output_0_batchmatmul:0"
name: "/encoder/layer.2/attention/self/MatMul_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.5811166763305664
  zero_point: 59
  minval: -34.285884857177734
  maxval: 113.89887237548828
}
padding: 0
out_max_byte_size: 1728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.2/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.2/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.2/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.2/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.2/attention/self/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.5811166763305664
  zero_point: 59
  minval: -34.285884857177734
  maxval: 113.89887237548828
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/MatMul_output_0:0"
input: "/encoder/layer.2/attention/self/Div/b:0"
input: "/encoder/layer.2/attention/self/MatMul_output_0:1"
input: "/encoder/layer.2/attention/self/MatMul_output_0:2"
input: "/encoder/layer.2/attention/self/Div/b_min:0"
input: "/encoder/layer.2/attention/self/Div/b_max:0"
input: "/encoder/layer.2/attention/self/Div_output_0_min:0"
input: "/encoder/layer.2/attention/self/Div_output_0_max:0"
output: "/encoder/layer.2/attention/self/Div_output_0:0"
name: "/encoder/layer.2/attention/self/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0726395919919014
  zero_point: 59
  minval: -4.285736083984375
  maxval: 14.237360000610352
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/Div_output_0:0"
input: "/Mul_output_0:0"
input: "/encoder/layer.2/attention/self/Div_output_0:1"
input: "/encoder/layer.2/attention/self/Div_output_0:2"
input: "/Mul_output_0:1"
input: "/Mul_output_0:2"
input: "/encoder/layer.2/attention/self/Add_output_0_min:0"
input: "/encoder/layer.2/attention/self/Add_output_0_max:0"
output: "/encoder/layer.2/attention/self/Add_output_0:0"
name: "/encoder/layer.2/attention/self/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/Add_output_0:0"
input: "/encoder/layer.2/attention/self/Add_output_0:1"
input: "/encoder/layer.2/attention/self/Add_output_0:2"
output: "/encoder/layer.2/attention/self/Softmax_output_0:0"
name: "/encoder/layer.2/attention/self/Softmax"
type: "QuantizedSoftmax_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1382"
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1382_min:0"
input: "onnx::MatMul_1382_max:0"
output: "/encoder/layer.2/attention/self/value/MatMul_output_0_matmul:0"
name: "/encoder/layer.2/attention/self/value/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018187351524829865
  zero_point: 124
  minval: -2.2552316188812256
  maxval: 2.3825430870056152
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.2/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.2/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.2/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.2/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.2/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.2/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018187351524829865
  zero_point: 124
  minval: -2.2552316188812256
  maxval: 2.3825430870056152
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.2.attention.self.value.bias:0"
input: "/encoder/layer.2/attention/self/value/MatMul_output_0:0"
input: "encoder.layer.2.attention.self.value.bias_min:0"
input: "encoder.layer.2.attention.self.value.bias_max:0"
input: "/encoder/layer.2/attention/self/value/MatMul_output_0:1"
input: "/encoder/layer.2/attention/self/value/MatMul_output_0:2"
input: "/encoder/layer.2/attention/self/value/Add_output_0_min:0"
input: "/encoder/layer.2/attention/self/value/Add_output_0_max:0"
output: "/encoder/layer.2/attention/self/value/Add_output_0:0"
name: "/encoder/layer.2/attention/self/value/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018353644758462906
  zero_point: 124
  minval: -2.2758519649505615
  maxval: 2.404327630996704
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/value/Add_output_0:0"
input: "/encoder/layer.2/attention/self/Reshape_1/shape:0"
input: "/encoder/layer.2/attention/self/value/Add_output_0:1"
input: "/encoder/layer.2/attention/self/value/Add_output_0:2"
output: "/encoder/layer.2/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.2/attention/self/Reshape_1"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018353644758462906
  zero_point: 124
  minval: -2.2758519649505615
  maxval: 2.404327630996704
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/Reshape_1_output_0:0"
input: "/encoder/layer.2/attention/self/Transpose/shape:0"
input: "/encoder/layer.2/attention/self/Reshape_1_output_0_min:0"
input: "/encoder/layer.2/attention/self/Reshape_1_output_0_max:0"
output: "/encoder/layer.2/attention/self/Transpose_output_0:0"
name: "/encoder/layer.2/attention/self/Transpose"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018353644758462906
  zero_point: 124
  minval: -2.2758519649505615
  maxval: 2.404327630996704
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/Softmax_output_0:0"
input: "/encoder/layer.2/attention/self/Transpose_output_0:0"
input: "/encoder/layer.2/attention/self/Softmax_output_0:1"
input: "/encoder/layer.2/attention/self/Softmax_output_0:2"
input: "/encoder/layer.2/attention/self/Transpose_output_0:1"
input: "/encoder/layer.2/attention/self/Transpose_output_0:2"
output: "/encoder/layer.2/attention/self/MatMul_1_output_0_batchmatmul:0"
name: "/encoder/layer.2/attention/self/MatMul_1_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.00788026675581932
  zero_point: 105
  minval: -0.8274279832839966
  maxval: 1.1820399761199951
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.2/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.2/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.2/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.2/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.2/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.2/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.00788026675581932
  zero_point: 105
  minval: -0.8274279832839966
  maxval: 1.1820399761199951
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/MatMul_1_output_0:0"
input: "/encoder/layer.2/attention/self/Transpose_3/shape:0"
input: "/encoder/layer.2/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.2/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.2/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.2/attention/self/Transpose_3"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.00788026675581932
  zero_point: 105
  minval: -0.8274279832839966
  maxval: 1.1820399761199951
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/Transpose_3_output_0:0"
input: "/encoder/layer.2/attention/self/Reshape_3/shape:0"
input: "/encoder/layer.2/attention/self/Transpose_3_output_0:1"
input: "/encoder/layer.2/attention/self/Transpose_3_output_0:2"
output: "/encoder/layer.2/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.2/attention/self/Reshape_3"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.00788026675581932
  zero_point: 105
  minval: -0.8274279832839966
  maxval: 1.1820399761199951
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1397"
input: "/encoder/layer.2/attention/self/Reshape_3_output_0:1"
input: "/encoder/layer.2/attention/self/Reshape_3_output_0:2"
input: "onnx::MatMul_1397_min:0"
input: "onnx::MatMul_1397_max:0"
output: "/encoder/layer.2/attention/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.2/attention/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.006788904778659344
  zero_point: 129
  minval: -0.8757687211036682
  maxval: 0.8554019927978516
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.2/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.2/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.2/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.2/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.2/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.2/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.006788904778659344
  zero_point: 129
  minval: -0.8757687211036682
  maxval: 0.8554019927978516
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.2.attention.output.dense.bias:0"
input: "/encoder/layer.2/attention/output/dense/MatMul_output_0:0"
input: "encoder.layer.2.attention.output.dense.bias_min:0"
input: "encoder.layer.2.attention.output.dense.bias_max:0"
input: "/encoder/layer.2/attention/output/dense/MatMul_output_0:1"
input: "/encoder/layer.2/attention/output/dense/MatMul_output_0:2"
input: "/encoder/layer.2/attention/output/dense/Add_output_0_min:0"
input: "/encoder/layer.2/attention/output/dense/Add_output_0_max:0"
output: "/encoder/layer.2/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.2/attention/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0055724442936480045
  zero_point: 126
  minval: -0.702127993106842
  maxval: 0.7188453078269958
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/output/dense/Add_output_0:0"
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.2/attention/output/dense/Add_output_0:1"
input: "/encoder/layer.2/attention/output/dense/Add_output_0:2"
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.1/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.2/attention/output/Add_output_0_min:0"
input: "/encoder/layer.2/attention/output/Add_output_0_max:0"
output: "/encoder/layer.2/attention/output/Add_output_0:0"
name: "/encoder/layer.2/attention/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.054488345980644226
  zero_point: 214
  minval: -11.660506248474121
  maxval: 2.2340221405029297
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/output/Add_output_0:0"
input: "/encoder/layer.2/attention/output/Add_output_0:1"
input: "/encoder/layer.2/attention/output/Add_output_0:2"
input: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 6.870196375530213e-05
  zero_point: 255
  minval: -0.01751900091767311
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/output/Add_output_0:0"
input: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.2/attention/output/Add_output_0:1"
input: "/encoder/layer.2/attention/output/Add_output_0:2"
input: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.2/attention/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.2/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.054434746503829956
  zero_point: 214
  minval: -11.649036407470703
  maxval: 2.2318246364593506
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.2/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.2/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.2/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.2/attention/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.2/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.5321570038795471
  zero_point: 0
  minval: 0.0
  maxval: 135.70004272460938
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.2/attention/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0025045648217201233
  zero_point: 0
  minval: 0.0
  maxval: 0.6386640071868896
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Add/b:0"
input: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.2/attention/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.2/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0025045648217201233
  zero_point: 0
  minval: 0.0
  maxval: 0.6386640071868896
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.2/attention/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0031339803244918585
  zero_point: 0
  minval: 0.0
  maxval: 0.7991650104522705
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.2/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.2/attention/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.2/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.09967236965894699
  zero_point: 227
  minval: -22.625627517700195
  maxval: 2.7908263206481934
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.2.attention.output.LayerNorm.weight:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.2/attention/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.2.attention.output.LayerNorm.weight_min:0"
input: "encoder.layer.2.attention.output.LayerNorm.weight_max:0"
output: "/encoder/layer.2/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.21263140439987183
  zero_point: 243
  minval: -51.669429779052734
  maxval: 2.551576852798462
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.2.attention.output.LayerNorm.bias:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.2/attention/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.2.attention.output.LayerNorm.bias_min:0"
input: "encoder.layer.2.attention.output.LayerNorm.bias_max:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.2/attention/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.22093814611434937
  zero_point: 243
  minval: -53.68796920776367
  maxval: 2.6512577533721924
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1398"
input: "/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1398_min:0"
input: "onnx::MatMul_1398_max:0"
output: "/encoder/layer.2/intermediate/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.2/intermediate/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2867799997329712
  zero_point: 69
  minval: -19.78782081604004
  maxval: 53.34107971191406
}
padding: 0
out_max_byte_size: 73728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.2/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.2/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.2/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.2/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.2/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.2/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2867799997329712
  zero_point: 69
  minval: -19.78782081604004
  maxval: 53.34107971191406
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/intermediate/dense/MatMul_output_0:0"
input: "/encoder/layer.2/intermediate/dense/MatMul_output_0:1"
input: "/encoder/layer.2/intermediate/dense/MatMul_output_0:2"
output: "/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1"
type: "QuantizedGelu_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2089047133922577
  zero_point: 1
  minval: -0.2089047133922577
  maxval: 53.061798095703125
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1399"
input: "/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0:1"
input: "/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0:2"
input: "onnx::MatMul_1399_min:0"
input: "onnx::MatMul_1399_max:0"
output: "/encoder/layer.2/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.2/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.8529177308082581
  zero_point: 251
  minval: -214.0823516845703
  maxval: 3.4116709232330322
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.2/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.2/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.2/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.2/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.2/output/dense/MatMul_output_0:0"
name: "/encoder/layer.2/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.8529177308082581
  zero_point: 251
  minval: -214.0823516845703
  maxval: 3.4116709232330322
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.2.output.dense.bias:0"
input: "/encoder/layer.2/output/dense/MatMul_output_0:0"
input: "encoder.layer.2.output.dense.bias_min:0"
input: "encoder.layer.2.output.dense.bias_max:0"
input: "/encoder/layer.2/output/dense/MatMul_output_0:1"
input: "/encoder/layer.2/output/dense/MatMul_output_0:2"
input: "/encoder/layer.2/output/dense/Add_output_0_min:0"
input: "/encoder/layer.2/output/dense/Add_output_0_max:0"
output: "/encoder/layer.2/output/dense/Add_output_0:0"
name: "/encoder/layer.2/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.8531507253646851
  zero_point: 251
  minval: -214.14083862304688
  maxval: 3.4126029014587402
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/output/dense/Add_output_0:0"
input: "/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.2/output/dense/Add_output_0:1"
input: "/encoder/layer.2/output/dense/Add_output_0:2"
input: "/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.2/output/Add_output_0_min:0"
input: "/encoder/layer.2/output/Add_output_0_max:0"
output: "/encoder/layer.2/output/Add_output_0:0"
name: "/encoder/layer.2/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.8699726462364197
  zero_point: 251
  minval: -218.36312866210938
  maxval: 3.4798905849456787
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/output/Add_output_0:0"
input: "/encoder/layer.2/output/Add_output_0:1"
input: "/encoder/layer.2/output/Add_output_0:2"
input: "/encoder/layer.2/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.2/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.2/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.2/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0012147293891757727
  zero_point: 255
  minval: -0.30975601077079773
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/output/Add_output_0:0"
input: "/encoder/layer.2/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.2/output/Add_output_0:1"
input: "/encoder/layer.2/output/Add_output_0:2"
input: "/encoder/layer.2/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.2/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.2/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.2/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.2/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.8687385320663452
  zero_point: 251
  minval: -218.05337524414062
  maxval: 3.474954128265381
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.2/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.2/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.2/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.2/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.2/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.2/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.2/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.2/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 186.45989990234375
  zero_point: 0
  minval: 0.0
  maxval: 47547.2734375
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.2/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.2/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.2/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.25768864154815674
  zero_point: 0
  minval: 0.0
  maxval: 65.71060180664062
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.2/output/LayerNorm/Add/b:0"
input: "/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.2/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.2/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.2/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.2/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.2/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.25768864154815674
  zero_point: 0
  minval: 0.0
  maxval: 65.71060180664062
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.2/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.2/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.2/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03178904950618744
  zero_point: 0
  minval: 0.0
  maxval: 8.106207847595215
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.2/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.2/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.2/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.2/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.2/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.2/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.2/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.2/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.1149553582072258
  zero_point: 234
  minval: -26.899553298950195
  maxval: 2.4140625
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.2.output.LayerNorm.weight:0"
input: "/encoder/layer.2/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.2/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.2.output.LayerNorm.weight_min:0"
input: "encoder.layer.2.output.LayerNorm.weight_max:0"
output: "/encoder/layer.2/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06626202166080475
  zero_point: 223
  minval: -14.776430130004883
  maxval: 2.120384693145752
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.2.output.LayerNorm.bias:0"
input: "/encoder/layer.2/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.2/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.2.output.LayerNorm.bias_min:0"
input: "encoder.layer.2.output.LayerNorm.bias_max:0"
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.2/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06543660163879395
  zero_point: 224
  minval: -14.657797813415527
  maxval: 2.0285346508026123
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1400"
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1400_min:0"
input: "onnx::MatMul_1400_max:0"
output: "/encoder/layer.3/attention/self/query/MatMul_output_0_matmul:0"
name: "/encoder/layer.3/attention/self/query/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03683091327548027
  zero_point: 141
  minval: -5.1931586265563965
  maxval: 4.198723793029785
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.3/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.3/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.3/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.3/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.3/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03683091327548027
  zero_point: 141
  minval: -5.1931586265563965
  maxval: 4.198723793029785
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.3.attention.self.query.bias:0"
input: "/encoder/layer.3/attention/self/query/MatMul_output_0:0"
input: "encoder.layer.3.attention.self.query.bias_min:0"
input: "encoder.layer.3.attention.self.query.bias_max:0"
input: "/encoder/layer.3/attention/self/query/MatMul_output_0:1"
input: "/encoder/layer.3/attention/self/query/MatMul_output_0:2"
input: "/encoder/layer.3/attention/self/query/Add_output_0_min:0"
input: "/encoder/layer.3/attention/self/query/Add_output_0_max:0"
output: "/encoder/layer.3/attention/self/query/Add_output_0:0"
name: "/encoder/layer.3/attention/self/query/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.038776081055402756
  zero_point: 137
  minval: -5.312323093414307
  maxval: 4.575577259063721
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/query/Add_output_0:0"
input: "/encoder/layer.3/attention/self/Reshape_2/shape:0"
input: "/encoder/layer.3/attention/self/query/Add_output_0:1"
input: "/encoder/layer.3/attention/self/query/Add_output_0:2"
output: "/encoder/layer.3/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.3/attention/self/Reshape_2"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.038776081055402756
  zero_point: 137
  minval: -5.312323093414307
  maxval: 4.575577259063721
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/Reshape_2_output_0:0"
input: "/encoder/layer.3/attention/self/Transpose_1/shape:0"
input: "/encoder/layer.3/attention/self/Reshape_2_output_0_min:0"
input: "/encoder/layer.3/attention/self/Reshape_2_output_0_max:0"
output: "/encoder/layer.3/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.3/attention/self/Transpose_1"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.038776081055402756
  zero_point: 137
  minval: -5.312323093414307
  maxval: 4.575577259063721
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1401"
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1401_min:0"
input: "onnx::MatMul_1401_max:0"
output: "/encoder/layer.3/attention/self/key/MatMul_output_0_matmul:0"
name: "/encoder/layer.3/attention/self/key/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04226052016019821
  zero_point: 120
  minval: -5.071262359619141
  maxval: 5.705170154571533
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.3/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.3/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.3/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.3/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.3/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04226052016019821
  zero_point: 120
  minval: -5.071262359619141
  maxval: 5.705170154571533
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.3.attention.self.key.bias:0"
input: "/encoder/layer.3/attention/self/key/MatMul_output_0:0"
input: "encoder.layer.3.attention.self.key.bias_min:0"
input: "encoder.layer.3.attention.self.key.bias_max:0"
input: "/encoder/layer.3/attention/self/key/MatMul_output_0:1"
input: "/encoder/layer.3/attention/self/key/MatMul_output_0:2"
input: "/encoder/layer.3/attention/self/key/Add_output_0_min:0"
input: "/encoder/layer.3/attention/self/key/Add_output_0_max:0"
output: "/encoder/layer.3/attention/self/key/Add_output_0:0"
name: "/encoder/layer.3/attention/self/key/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04216812551021576
  zero_point: 120
  minval: -5.060174942016602
  maxval: 5.692697048187256
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/key/Add_output_0:0"
input: "/encoder/layer.3/attention/self/Reshape/shape:0"
input: "/encoder/layer.3/attention/self/key/Add_output_0:1"
input: "/encoder/layer.3/attention/self/key/Add_output_0:2"
output: "/encoder/layer.3/attention/self/Reshape_output_0:0"
name: "/encoder/layer.3/attention/self/Reshape"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04216812551021576
  zero_point: 120
  minval: -5.060174942016602
  maxval: 5.692697048187256
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/Reshape_output_0:0"
input: "/encoder/layer.3/attention/self/Transpose_2/shape:0"
input: "/encoder/layer.3/attention/self/Reshape_output_0_min:0"
input: "/encoder/layer.3/attention/self/Reshape_output_0_max:0"
output: "/encoder/layer.3/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.3/attention/self/Transpose_2"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04216812551021576
  zero_point: 120
  minval: -5.060174942016602
  maxval: 5.692697048187256
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.3/attention/self/Transpose_2_output_0:0"
input: "/encoder/layer.3/attention/self/Transpose_1_output_0:1"
input: "/encoder/layer.3/attention/self/Transpose_1_output_0:2"
input: "/encoder/layer.3/attention/self/Transpose_2_output_0:1"
input: "/encoder/layer.3/attention/self/Transpose_2_output_0:2"
output: "/encoder/layer.3/attention/self/MatMul_output_0_batchmatmul:0"
name: "/encoder/layer.3/attention/self/MatMul_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.4197385907173157
  zero_point: 30
  minval: -12.592158317565918
  maxval: 94.4411849975586
}
padding: 0
out_max_byte_size: 1728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.3/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.3/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.3/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.3/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.3/attention/self/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.4197385907173157
  zero_point: 30
  minval: -12.592158317565918
  maxval: 94.4411849975586
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/MatMul_output_0:0"
input: "/encoder/layer.3/attention/self/Div/b:0"
input: "/encoder/layer.3/attention/self/MatMul_output_0:1"
input: "/encoder/layer.3/attention/self/MatMul_output_0:2"
input: "/encoder/layer.3/attention/self/Div/b_min:0"
input: "/encoder/layer.3/attention/self/Div/b_max:0"
input: "/encoder/layer.3/attention/self/Div_output_0_min:0"
input: "/encoder/layer.3/attention/self/Div_output_0_max:0"
output: "/encoder/layer.3/attention/self/Div_output_0:0"
name: "/encoder/layer.3/attention/self/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.05246732383966446
  zero_point: 30
  minval: -1.5740197896957397
  maxval: 11.805148124694824
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/Div_output_0:0"
input: "/Mul_output_0:0"
input: "/encoder/layer.3/attention/self/Div_output_0:1"
input: "/encoder/layer.3/attention/self/Div_output_0:2"
input: "/Mul_output_0:1"
input: "/Mul_output_0:2"
input: "/encoder/layer.3/attention/self/Add_output_0_min:0"
input: "/encoder/layer.3/attention/self/Add_output_0_max:0"
output: "/encoder/layer.3/attention/self/Add_output_0:0"
name: "/encoder/layer.3/attention/self/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/Add_output_0:0"
input: "/encoder/layer.3/attention/self/Add_output_0:1"
input: "/encoder/layer.3/attention/self/Add_output_0:2"
output: "/encoder/layer.3/attention/self/Softmax_output_0:0"
name: "/encoder/layer.3/attention/self/Softmax"
type: "QuantizedSoftmax_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1407"
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1407_min:0"
input: "onnx::MatMul_1407_max:0"
output: "/encoder/layer.3/attention/self/value/MatMul_output_0_matmul:0"
name: "/encoder/layer.3/attention/self/value/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.017904654145240784
  zero_point: 124
  minval: -2.220176935195923
  maxval: 2.3455095291137695
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.3/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.3/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.3/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.3/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.3/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.3/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.017904654145240784
  zero_point: 124
  minval: -2.220176935195923
  maxval: 2.3455095291137695
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.3.attention.self.value.bias:0"
input: "/encoder/layer.3/attention/self/value/MatMul_output_0:0"
input: "encoder.layer.3.attention.self.value.bias_min:0"
input: "encoder.layer.3.attention.self.value.bias_max:0"
input: "/encoder/layer.3/attention/self/value/MatMul_output_0:1"
input: "/encoder/layer.3/attention/self/value/MatMul_output_0:2"
input: "/encoder/layer.3/attention/self/value/Add_output_0_min:0"
input: "/encoder/layer.3/attention/self/value/Add_output_0_max:0"
output: "/encoder/layer.3/attention/self/value/Add_output_0:0"
name: "/encoder/layer.3/attention/self/value/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01786927506327629
  zero_point: 124
  minval: -2.215790033340454
  maxval: 2.3408749103546143
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/value/Add_output_0:0"
input: "/encoder/layer.3/attention/self/Reshape_1/shape:0"
input: "/encoder/layer.3/attention/self/value/Add_output_0:1"
input: "/encoder/layer.3/attention/self/value/Add_output_0:2"
output: "/encoder/layer.3/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.3/attention/self/Reshape_1"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01786927506327629
  zero_point: 124
  minval: -2.215790033340454
  maxval: 2.3408749103546143
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/Reshape_1_output_0:0"
input: "/encoder/layer.3/attention/self/Transpose/shape:0"
input: "/encoder/layer.3/attention/self/Reshape_1_output_0_min:0"
input: "/encoder/layer.3/attention/self/Reshape_1_output_0_max:0"
output: "/encoder/layer.3/attention/self/Transpose_output_0:0"
name: "/encoder/layer.3/attention/self/Transpose"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01786927506327629
  zero_point: 124
  minval: -2.215790033340454
  maxval: 2.3408749103546143
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/Softmax_output_0:0"
input: "/encoder/layer.3/attention/self/Transpose_output_0:0"
input: "/encoder/layer.3/attention/self/Softmax_output_0:1"
input: "/encoder/layer.3/attention/self/Softmax_output_0:2"
input: "/encoder/layer.3/attention/self/Transpose_output_0:1"
input: "/encoder/layer.3/attention/self/Transpose_output_0:2"
output: "/encoder/layer.3/attention/self/MatMul_1_output_0_batchmatmul:0"
name: "/encoder/layer.3/attention/self/MatMul_1_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0067507983185350895
  zero_point: 129
  minval: -0.8708530068397522
  maxval: 0.8506006002426147
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.3/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.3/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.3/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.3/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.3/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.3/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0067507983185350895
  zero_point: 129
  minval: -0.8708530068397522
  maxval: 0.8506006002426147
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/MatMul_1_output_0:0"
input: "/encoder/layer.3/attention/self/Transpose_3/shape:0"
input: "/encoder/layer.3/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.3/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.3/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.3/attention/self/Transpose_3"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0067507983185350895
  zero_point: 129
  minval: -0.8708530068397522
  maxval: 0.8506006002426147
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/Transpose_3_output_0:0"
input: "/encoder/layer.3/attention/self/Reshape_3/shape:0"
input: "/encoder/layer.3/attention/self/Transpose_3_output_0:1"
input: "/encoder/layer.3/attention/self/Transpose_3_output_0:2"
output: "/encoder/layer.3/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.3/attention/self/Reshape_3"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0067507983185350895
  zero_point: 129
  minval: -0.8708530068397522
  maxval: 0.8506006002426147
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1422"
input: "/encoder/layer.3/attention/self/Reshape_3_output_0:1"
input: "/encoder/layer.3/attention/self/Reshape_3_output_0:2"
input: "onnx::MatMul_1422_min:0"
input: "onnx::MatMul_1422_max:0"
output: "/encoder/layer.3/attention/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.3/attention/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.005419538356363773
  zero_point: 151
  minval: -0.8183503150939941
  maxval: 0.5636320114135742
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.3/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.3/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.3/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.3/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.3/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.3/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.005419538356363773
  zero_point: 151
  minval: -0.8183503150939941
  maxval: 0.5636320114135742
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.3.attention.output.dense.bias:0"
input: "/encoder/layer.3/attention/output/dense/MatMul_output_0:0"
input: "encoder.layer.3.attention.output.dense.bias_min:0"
input: "encoder.layer.3.attention.output.dense.bias_max:0"
input: "/encoder/layer.3/attention/output/dense/MatMul_output_0:1"
input: "/encoder/layer.3/attention/output/dense/MatMul_output_0:2"
input: "/encoder/layer.3/attention/output/dense/Add_output_0_min:0"
input: "/encoder/layer.3/attention/output/dense/Add_output_0_max:0"
output: "/encoder/layer.3/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.3/attention/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.005509603768587112
  zero_point: 154
  minval: -0.8484790325164795
  maxval: 0.5564699769020081
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/output/dense/Add_output_0:0"
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.3/attention/output/dense/Add_output_0:1"
input: "/encoder/layer.3/attention/output/dense/Add_output_0:2"
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.2/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.3/attention/output/Add_output_0_min:0"
input: "/encoder/layer.3/attention/output/Add_output_0_max:0"
output: "/encoder/layer.3/attention/output/Add_output_0:0"
name: "/encoder/layer.3/attention/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06544771790504456
  zero_point: 225
  minval: -14.725735664367676
  maxval: 1.963431477546692
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/output/Add_output_0:0"
input: "/encoder/layer.3/attention/output/Add_output_0:1"
input: "/encoder/layer.3/attention/output/Add_output_0:2"
input: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 7.37803929951042e-05
  zero_point: 255
  minval: -0.018813999369740486
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/output/Add_output_0:0"
input: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.3/attention/output/Add_output_0:1"
input: "/encoder/layer.3/attention/output/Add_output_0:2"
input: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.3/attention/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.3/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06567302346229553
  zero_point: 224
  minval: -14.7107572555542
  maxval: 2.0358636379241943
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.3/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.3/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.3/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.3/attention/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.3/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.8486524224281311
  zero_point: 0
  minval: 0.0
  maxval: 216.4063720703125
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.3/attention/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0022478157188743353
  zero_point: 0
  minval: 0.0
  maxval: 0.5731930136680603
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Add/b:0"
input: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.3/attention/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.3/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0022478157188743353
  zero_point: 0
  minval: 0.0
  maxval: 0.5731930136680603
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.3/attention/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0029690000228583813
  zero_point: 0
  minval: 0.0
  maxval: 0.7570949792861938
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.3/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.3/attention/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.3/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.11074970662593842
  zero_point: 231
  minval: -25.58318328857422
  maxval: 2.6579930782318115
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.3.attention.output.LayerNorm.weight:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.3/attention/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.3.attention.output.LayerNorm.weight_min:0"
input: "encoder.layer.3.attention.output.LayerNorm.weight_max:0"
output: "/encoder/layer.3/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.3597131669521332
  zero_point: 248
  minval: -89.2088623046875
  maxval: 2.5179920196533203
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.3.attention.output.LayerNorm.bias:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.3/attention/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.3.attention.output.LayerNorm.bias_min:0"
input: "encoder.layer.3.attention.output.LayerNorm.bias_max:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.3/attention/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.3632200360298157
  zero_point: 248
  minval: -90.07856750488281
  maxval: 2.5425403118133545
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1423"
input: "/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1423_min:0"
input: "onnx::MatMul_1423_max:0"
output: "/encoder/layer.3/intermediate/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.3/intermediate/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2499488741159439
  zero_point: 232
  minval: -57.988136291503906
  maxval: 5.748824119567871
}
padding: 0
out_max_byte_size: 73728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.3/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.3/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.3/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.3/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.3/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.3/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2499488741159439
  zero_point: 232
  minval: -57.988136291503906
  maxval: 5.748824119567871
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/intermediate/dense/MatMul_output_0:0"
input: "/encoder/layer.3/intermediate/dense/MatMul_output_0:1"
input: "/encoder/layer.3/intermediate/dense/MatMul_output_0:2"
output: "/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1"
type: "QuantizedGelu_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02169569954276085
  zero_point: 8
  minval: -0.1735655963420868
  maxval: 5.358838081359863
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1424"
input: "/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0:1"
input: "/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0:2"
input: "onnx::MatMul_1424_min:0"
input: "onnx::MatMul_1424_max:0"
output: "/encoder/layer.3/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.3/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2377270609140396
  zero_point: 240
  minval: -57.05449295043945
  maxval: 3.565905809402466
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.3/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.3/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.3/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.3/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.3/output/dense/MatMul_output_0:0"
name: "/encoder/layer.3/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2377270609140396
  zero_point: 240
  minval: -57.05449295043945
  maxval: 3.565905809402466
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.3.output.dense.bias:0"
input: "/encoder/layer.3/output/dense/MatMul_output_0:0"
input: "encoder.layer.3.output.dense.bias_min:0"
input: "encoder.layer.3.output.dense.bias_max:0"
input: "/encoder/layer.3/output/dense/MatMul_output_0:1"
input: "/encoder/layer.3/output/dense/MatMul_output_0:2"
input: "/encoder/layer.3/output/dense/Add_output_0_min:0"
input: "/encoder/layer.3/output/dense/Add_output_0_max:0"
output: "/encoder/layer.3/output/dense/Add_output_0:0"
name: "/encoder/layer.3/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.23652197420597076
  zero_point: 242
  minval: -57.238319396972656
  maxval: 3.0747857093811035
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/output/dense/Add_output_0:0"
input: "/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.3/output/dense/Add_output_0:1"
input: "/encoder/layer.3/output/dense/Add_output_0:2"
input: "/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.3/output/Add_output_0_min:0"
input: "/encoder/layer.3/output/Add_output_0_max:0"
output: "/encoder/layer.3/output/Add_output_0:0"
name: "/encoder/layer.3/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.5892675518989563
  zero_point: 250
  minval: -147.31689453125
  maxval: 2.946337938308716
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/output/Add_output_0:0"
input: "/encoder/layer.3/output/Add_output_0:1"
input: "/encoder/layer.3/output/Add_output_0:2"
input: "/encoder/layer.3/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.3/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.3/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.3/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0006990980473347008
  zero_point: 255
  minval: -0.17826999723911285
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/output/Add_output_0:0"
input: "/encoder/layer.3/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.3/output/Add_output_0:1"
input: "/encoder/layer.3/output/Add_output_0:2"
input: "/encoder/layer.3/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.3/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.3/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.3/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.3/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.5885545015335083
  zero_point: 250
  minval: -147.1386260986328
  maxval: 2.942772626876831
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.3/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.3/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.3/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.3/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.3/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.3/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.3/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.3/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 84.90107727050781
  zero_point: 0
  minval: 0.0
  maxval: 21649.775390625
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.3/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.3/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.3/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.11154637485742569
  zero_point: 0
  minval: 0.0
  maxval: 28.444326400756836
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.3/output/LayerNorm/Add/b:0"
input: "/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.3/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.3/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.3/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.3/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.3/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.11154637485742569
  zero_point: 0
  minval: 0.0
  maxval: 28.444326400756836
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.3/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.3/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.3/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.020914988592267036
  zero_point: 0
  minval: 0.0
  maxval: 5.333322048187256
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.3/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.3/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.3/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.3/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.3/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.3/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.3/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.3/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.11995021998882294
  zero_point: 230
  minval: -27.588550567626953
  maxval: 2.99875545501709
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.3.output.LayerNorm.weight:0"
input: "/encoder/layer.3/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.3/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.3.output.LayerNorm.weight_min:0"
input: "encoder.layer.3.output.LayerNorm.weight_max:0"
output: "/encoder/layer.3/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06441094726324081
  zero_point: 218
  minval: -14.041586875915527
  maxval: 2.3832051753997803
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.3.output.LayerNorm.bias:0"
input: "/encoder/layer.3/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.3/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.3.output.LayerNorm.bias_min:0"
input: "encoder.layer.3.output.LayerNorm.bias_max:0"
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.3/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06357957422733307
  zero_point: 220
  minval: -13.987505912780762
  maxval: 2.225285053253174
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1425"
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1425_min:0"
input: "onnx::MatMul_1425_max:0"
output: "/encoder/layer.4/attention/self/query/MatMul_output_0_matmul:0"
name: "/encoder/layer.4/attention/self/query/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03810853511095047
  zero_point: 144
  minval: -5.487628936767578
  maxval: 4.230047225952148
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.4/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.4/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.4/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.4/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.4/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03810853511095047
  zero_point: 144
  minval: -5.487628936767578
  maxval: 4.230047225952148
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.4.attention.self.query.bias:0"
input: "/encoder/layer.4/attention/self/query/MatMul_output_0:0"
input: "encoder.layer.4.attention.self.query.bias_min:0"
input: "encoder.layer.4.attention.self.query.bias_max:0"
input: "/encoder/layer.4/attention/self/query/MatMul_output_0:1"
input: "/encoder/layer.4/attention/self/query/MatMul_output_0:2"
input: "/encoder/layer.4/attention/self/query/Add_output_0_min:0"
input: "/encoder/layer.4/attention/self/query/Add_output_0_max:0"
output: "/encoder/layer.4/attention/self/query/Add_output_0:0"
name: "/encoder/layer.4/attention/self/query/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0408809520304203
  zero_point: 147
  minval: -6.009500026702881
  maxval: 4.415143013000488
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/query/Add_output_0:0"
input: "/encoder/layer.4/attention/self/Reshape_2/shape:0"
input: "/encoder/layer.4/attention/self/query/Add_output_0:1"
input: "/encoder/layer.4/attention/self/query/Add_output_0:2"
output: "/encoder/layer.4/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.4/attention/self/Reshape_2"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0408809520304203
  zero_point: 147
  minval: -6.009500026702881
  maxval: 4.415143013000488
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/Reshape_2_output_0:0"
input: "/encoder/layer.4/attention/self/Transpose_1/shape:0"
input: "/encoder/layer.4/attention/self/Reshape_2_output_0_min:0"
input: "/encoder/layer.4/attention/self/Reshape_2_output_0_max:0"
output: "/encoder/layer.4/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.4/attention/self/Transpose_1"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0408809520304203
  zero_point: 147
  minval: -6.009500026702881
  maxval: 4.415143013000488
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1426"
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1426_min:0"
input: "onnx::MatMul_1426_max:0"
output: "/encoder/layer.4/attention/self/key/MatMul_output_0_matmul:0"
name: "/encoder/layer.4/attention/self/key/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.035824548453092575
  zero_point: 142
  minval: -5.087086200714111
  maxval: 4.048173904418945
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.4/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.4/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.4/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.4/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.4/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.035824548453092575
  zero_point: 142
  minval: -5.087086200714111
  maxval: 4.048173904418945
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.4.attention.self.key.bias:0"
input: "/encoder/layer.4/attention/self/key/MatMul_output_0:0"
input: "encoder.layer.4.attention.self.key.bias_min:0"
input: "encoder.layer.4.attention.self.key.bias_max:0"
input: "/encoder/layer.4/attention/self/key/MatMul_output_0:1"
input: "/encoder/layer.4/attention/self/key/MatMul_output_0:2"
input: "/encoder/layer.4/attention/self/key/Add_output_0_min:0"
input: "/encoder/layer.4/attention/self/key/Add_output_0_max:0"
output: "/encoder/layer.4/attention/self/key/Add_output_0:0"
name: "/encoder/layer.4/attention/self/key/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.035851430147886276
  zero_point: 142
  minval: -5.090902805328369
  maxval: 4.051211357116699
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/key/Add_output_0:0"
input: "/encoder/layer.4/attention/self/Reshape/shape:0"
input: "/encoder/layer.4/attention/self/key/Add_output_0:1"
input: "/encoder/layer.4/attention/self/key/Add_output_0:2"
output: "/encoder/layer.4/attention/self/Reshape_output_0:0"
name: "/encoder/layer.4/attention/self/Reshape"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.035851430147886276
  zero_point: 142
  minval: -5.090902805328369
  maxval: 4.051211357116699
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/Reshape_output_0:0"
input: "/encoder/layer.4/attention/self/Transpose_2/shape:0"
input: "/encoder/layer.4/attention/self/Reshape_output_0_min:0"
input: "/encoder/layer.4/attention/self/Reshape_output_0_max:0"
output: "/encoder/layer.4/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.4/attention/self/Transpose_2"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.035851430147886276
  zero_point: 142
  minval: -5.090902805328369
  maxval: 4.051211357116699
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.4/attention/self/Transpose_2_output_0:0"
input: "/encoder/layer.4/attention/self/Transpose_1_output_0:1"
input: "/encoder/layer.4/attention/self/Transpose_1_output_0:2"
input: "/encoder/layer.4/attention/self/Transpose_2_output_0:1"
input: "/encoder/layer.4/attention/self/Transpose_2_output_0:2"
output: "/encoder/layer.4/attention/self/MatMul_output_0_batchmatmul:0"
name: "/encoder/layer.4/attention/self/MatMul_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.40570372343063354
  zero_point: 72
  minval: -29.210668563842773
  maxval: 74.24378204345703
}
padding: 0
out_max_byte_size: 1728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.4/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.4/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.4/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.4/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.4/attention/self/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.40570372343063354
  zero_point: 72
  minval: -29.210668563842773
  maxval: 74.24378204345703
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/MatMul_output_0:0"
input: "/encoder/layer.4/attention/self/Div/b:0"
input: "/encoder/layer.4/attention/self/MatMul_output_0:1"
input: "/encoder/layer.4/attention/self/MatMul_output_0:2"
input: "/encoder/layer.4/attention/self/Div/b_min:0"
input: "/encoder/layer.4/attention/self/Div/b_max:0"
input: "/encoder/layer.4/attention/self/Div_output_0_min:0"
input: "/encoder/layer.4/attention/self/Div_output_0_max:0"
output: "/encoder/layer.4/attention/self/Div_output_0:0"
name: "/encoder/layer.4/attention/self/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.05071296542882919
  zero_point: 72
  minval: -3.6513335704803467
  maxval: 9.280472755432129
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/Div_output_0:0"
input: "/Mul_output_0:0"
input: "/encoder/layer.4/attention/self/Div_output_0:1"
input: "/encoder/layer.4/attention/self/Div_output_0:2"
input: "/Mul_output_0:1"
input: "/Mul_output_0:2"
input: "/encoder/layer.4/attention/self/Add_output_0_min:0"
input: "/encoder/layer.4/attention/self/Add_output_0_max:0"
output: "/encoder/layer.4/attention/self/Add_output_0:0"
name: "/encoder/layer.4/attention/self/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/Add_output_0:0"
input: "/encoder/layer.4/attention/self/Add_output_0:1"
input: "/encoder/layer.4/attention/self/Add_output_0:2"
output: "/encoder/layer.4/attention/self/Softmax_output_0:0"
name: "/encoder/layer.4/attention/self/Softmax"
type: "QuantizedSoftmax_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1432"
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1432_min:0"
input: "onnx::MatMul_1432_max:0"
output: "/encoder/layer.4/attention/self/value/MatMul_output_0_matmul:0"
name: "/encoder/layer.4/attention/self/value/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.021970756351947784
  zero_point: 103
  minval: -2.2629880905151367
  maxval: 3.339555025100708
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.4/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.4/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.4/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.4/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.4/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.4/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.021970756351947784
  zero_point: 103
  minval: -2.2629880905151367
  maxval: 3.339555025100708
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.4.attention.self.value.bias:0"
input: "/encoder/layer.4/attention/self/value/MatMul_output_0:0"
input: "encoder.layer.4.attention.self.value.bias_min:0"
input: "encoder.layer.4.attention.self.value.bias_max:0"
input: "/encoder/layer.4/attention/self/value/MatMul_output_0:1"
input: "/encoder/layer.4/attention/self/value/MatMul_output_0:2"
input: "/encoder/layer.4/attention/self/value/Add_output_0_min:0"
input: "/encoder/layer.4/attention/self/value/Add_output_0_max:0"
output: "/encoder/layer.4/attention/self/value/Add_output_0:0"
name: "/encoder/layer.4/attention/self/value/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.022308770567178726
  zero_point: 103
  minval: -2.2978034019470215
  maxval: 3.390933036804199
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/value/Add_output_0:0"
input: "/encoder/layer.4/attention/self/Reshape_1/shape:0"
input: "/encoder/layer.4/attention/self/value/Add_output_0:1"
input: "/encoder/layer.4/attention/self/value/Add_output_0:2"
output: "/encoder/layer.4/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.4/attention/self/Reshape_1"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.022308770567178726
  zero_point: 103
  minval: -2.2978034019470215
  maxval: 3.390933036804199
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/Reshape_1_output_0:0"
input: "/encoder/layer.4/attention/self/Transpose/shape:0"
input: "/encoder/layer.4/attention/self/Reshape_1_output_0_min:0"
input: "/encoder/layer.4/attention/self/Reshape_1_output_0_max:0"
output: "/encoder/layer.4/attention/self/Transpose_output_0:0"
name: "/encoder/layer.4/attention/self/Transpose"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.022308770567178726
  zero_point: 103
  minval: -2.2978034019470215
  maxval: 3.390933036804199
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/Softmax_output_0:0"
input: "/encoder/layer.4/attention/self/Transpose_output_0:0"
input: "/encoder/layer.4/attention/self/Softmax_output_0:1"
input: "/encoder/layer.4/attention/self/Softmax_output_0:2"
input: "/encoder/layer.4/attention/self/Transpose_output_0:1"
input: "/encoder/layer.4/attention/self/Transpose_output_0:2"
output: "/encoder/layer.4/attention/self/MatMul_1_output_0_batchmatmul:0"
name: "/encoder/layer.4/attention/self/MatMul_1_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007573618553578854
  zero_point: 137
  minval: -1.037585735321045
  maxval: 0.8936870098114014
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.4/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.4/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.4/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.4/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.4/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.4/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007573618553578854
  zero_point: 137
  minval: -1.037585735321045
  maxval: 0.8936870098114014
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/MatMul_1_output_0:0"
input: "/encoder/layer.4/attention/self/Transpose_3/shape:0"
input: "/encoder/layer.4/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.4/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.4/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.4/attention/self/Transpose_3"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007573618553578854
  zero_point: 137
  minval: -1.037585735321045
  maxval: 0.8936870098114014
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/Transpose_3_output_0:0"
input: "/encoder/layer.4/attention/self/Reshape_3/shape:0"
input: "/encoder/layer.4/attention/self/Transpose_3_output_0:1"
input: "/encoder/layer.4/attention/self/Transpose_3_output_0:2"
output: "/encoder/layer.4/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.4/attention/self/Reshape_3"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007573618553578854
  zero_point: 137
  minval: -1.037585735321045
  maxval: 0.8936870098114014
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1447"
input: "/encoder/layer.4/attention/self/Reshape_3_output_0:1"
input: "/encoder/layer.4/attention/self/Reshape_3_output_0:2"
input: "onnx::MatMul_1447_min:0"
input: "onnx::MatMul_1447_max:0"
output: "/encoder/layer.4/attention/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.4/attention/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.008231732062995434
  zero_point: 157
  minval: -1.292382001876831
  maxval: 0.8067097663879395
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.4/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.4/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.4/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.4/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.4/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.4/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.008231732062995434
  zero_point: 157
  minval: -1.292382001876831
  maxval: 0.8067097663879395
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.4.attention.output.dense.bias:0"
input: "/encoder/layer.4/attention/output/dense/MatMul_output_0:0"
input: "encoder.layer.4.attention.output.dense.bias_min:0"
input: "encoder.layer.4.attention.output.dense.bias_max:0"
input: "/encoder/layer.4/attention/output/dense/MatMul_output_0:1"
input: "/encoder/layer.4/attention/output/dense/MatMul_output_0:2"
input: "/encoder/layer.4/attention/output/dense/Add_output_0_min:0"
input: "/encoder/layer.4/attention/output/dense/Add_output_0_max:0"
output: "/encoder/layer.4/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.4/attention/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.005933646112680435
  zero_point: 130
  minval: -0.771373987197876
  maxval: 0.7417057752609253
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/output/dense/Add_output_0:0"
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.4/attention/output/dense/Add_output_0:1"
input: "/encoder/layer.4/attention/output/dense/Add_output_0:2"
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.3/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.4/attention/output/Add_output_0_min:0"
input: "/encoder/layer.4/attention/output/Add_output_0_max:0"
output: "/encoder/layer.4/attention/output/Add_output_0:0"
name: "/encoder/layer.4/attention/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06699128448963165
  zero_point: 220
  minval: -14.738081932067871
  maxval: 2.3446948528289795
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/output/Add_output_0:0"
input: "/encoder/layer.4/attention/output/Add_output_0:1"
input: "/encoder/layer.4/attention/output/Add_output_0:2"
input: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0001027019607136026
  zero_point: 255
  minval: -0.02618899941444397
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/output/Add_output_0:0"
input: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.4/attention/output/Add_output_0:1"
input: "/encoder/layer.4/attention/output/Add_output_0:2"
input: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.4/attention/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.4/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06687942147254944
  zero_point: 220
  minval: -14.713473320007324
  maxval: 2.3407797813415527
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.4/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.4/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.4/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.4/attention/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.4/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.8489658832550049
  zero_point: 0
  minval: 0.0
  maxval: 216.48629760742188
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.4/attention/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.002525490242987871
  zero_point: 0
  minval: 0.0
  maxval: 0.6439999938011169
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Add/b:0"
input: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.4/attention/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.4/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.002525490242987871
  zero_point: 0
  minval: 0.0
  maxval: 0.6439999938011169
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.4/attention/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003147043054923415
  zero_point: 0
  minval: 0.0
  maxval: 0.8024960160255432
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.4/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.4/attention/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.4/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.1050056740641594
  zero_point: 227
  minval: -23.836288452148438
  maxval: 2.9401588439941406
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.4.attention.output.LayerNorm.weight:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.4/attention/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.4.attention.output.LayerNorm.weight_min:0"
input: "encoder.layer.4.attention.output.LayerNorm.weight_max:0"
output: "/encoder/layer.4/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.3592655658721924
  zero_point: 248
  minval: -89.09786224365234
  maxval: 2.5148589611053467
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.4.attention.output.LayerNorm.bias:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.4/attention/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.4.attention.output.LayerNorm.bias_min:0"
input: "encoder.layer.4.attention.output.LayerNorm.bias_max:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.4/attention/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.3636661469936371
  zero_point: 248
  minval: -90.18920135498047
  maxval: 2.5456628799438477
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1448"
input: "/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1448_min:0"
input: "onnx::MatMul_1448_max:0"
output: "/encoder/layer.4/intermediate/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.4/intermediate/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2427986115217209
  zero_point: 226
  minval: -54.87248611450195
  maxval: 7.041159629821777
}
padding: 0
out_max_byte_size: 73728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.4/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.4/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.4/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.4/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.4/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.4/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2427986115217209
  zero_point: 226
  minval: -54.87248611450195
  maxval: 7.041159629821777
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/intermediate/dense/MatMul_output_0:0"
input: "/encoder/layer.4/intermediate/dense/MatMul_output_0:1"
input: "/encoder/layer.4/intermediate/dense/MatMul_output_0:2"
output: "/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1"
type: "QuantizedGelu_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02645285800099373
  zero_point: 7
  minval: -0.1851700097322464
  maxval: 6.560308933258057
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1449"
input: "/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0:1"
input: "/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0:2"
input: "onnx::MatMul_1449_min:0"
input: "onnx::MatMul_1449_max:0"
output: "/encoder/layer.4/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.4/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.19222192466259003
  zero_point: 233
  minval: -44.7877082824707
  maxval: 4.228882312774658
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.4/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.4/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.4/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.4/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.4/output/dense/MatMul_output_0:0"
name: "/encoder/layer.4/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.19222192466259003
  zero_point: 233
  minval: -44.7877082824707
  maxval: 4.228882312774658
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.4.output.dense.bias:0"
input: "/encoder/layer.4/output/dense/MatMul_output_0:0"
input: "encoder.layer.4.output.dense.bias_min:0"
input: "encoder.layer.4.output.dense.bias_max:0"
input: "/encoder/layer.4/output/dense/MatMul_output_0:1"
input: "/encoder/layer.4/output/dense/MatMul_output_0:2"
input: "/encoder/layer.4/output/dense/Add_output_0_min:0"
input: "/encoder/layer.4/output/dense/Add_output_0_max:0"
output: "/encoder/layer.4/output/dense/Add_output_0:0"
name: "/encoder/layer.4/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.1910017430782318
  zero_point: 235
  minval: -44.88541030883789
  maxval: 3.820034980773926
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/output/dense/Add_output_0:0"
input: "/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.4/output/dense/Add_output_0:1"
input: "/encoder/layer.4/output/dense/Add_output_0:2"
input: "/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.4/output/Add_output_0_min:0"
input: "/encoder/layer.4/output/Add_output_0_max:0"
output: "/encoder/layer.4/output/Add_output_0:0"
name: "/encoder/layer.4/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.5424368977546692
  zero_point: 249
  minval: -135.06678771972656
  maxval: 3.2546215057373047
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/output/Add_output_0:0"
input: "/encoder/layer.4/output/Add_output_0:1"
input: "/encoder/layer.4/output/Add_output_0:2"
input: "/encoder/layer.4/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.4/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.4/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.4/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0006619372288696468
  zero_point: 255
  minval: -0.16879400610923767
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/output/Add_output_0:0"
input: "/encoder/layer.4/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.4/output/Add_output_0:1"
input: "/encoder/layer.4/output/Add_output_0:2"
input: "/encoder/layer.4/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.4/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.4/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.4/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.4/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.5417590141296387
  zero_point: 249
  minval: -134.8979949951172
  maxval: 3.250554084777832
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.4/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.4/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.4/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.4/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.4/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.4/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.4/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.4/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 71.36262512207031
  zero_point: 0
  minval: 0.0
  maxval: 18197.46875
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.4/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.4/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.4/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.09394069761037827
  zero_point: 0
  minval: 0.0
  maxval: 23.954877853393555
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.4/output/LayerNorm/Add/b:0"
input: "/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.4/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.4/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.4/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.4/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.4/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.09394069761037827
  zero_point: 0
  minval: 0.0
  maxval: 23.954877853393555
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.4/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.4/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.4/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0191936157643795
  zero_point: 0
  minval: 0.0
  maxval: 4.89437198638916
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.4/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.4/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.4/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.4/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.4/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.4/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.4/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.4/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.11880111694335938
  zero_point: 232
  minval: -27.561859130859375
  maxval: 2.7324256896972656
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.4.output.LayerNorm.weight:0"
input: "/encoder/layer.4/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.4/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.4.output.LayerNorm.weight_min:0"
input: "encoder.layer.4.output.LayerNorm.weight_max:0"
output: "/encoder/layer.4/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06785056740045547
  zero_point: 222
  minval: -15.062826156616211
  maxval: 2.2390687465667725
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.4.output.LayerNorm.bias:0"
input: "/encoder/layer.4/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.4/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.4.output.LayerNorm.bias_min:0"
input: "encoder.layer.4.output.LayerNorm.bias_max:0"
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.4/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06664929538965225
  zero_point: 223
  minval: -14.86279296875
  maxval: 2.132777452468872
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1450"
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1450_min:0"
input: "onnx::MatMul_1450_max:0"
output: "/encoder/layer.5/attention/self/query/MatMul_output_0_matmul:0"
name: "/encoder/layer.5/attention/self/query/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04121337831020355
  zero_point: 151
  minval: -6.223219871520996
  maxval: 4.286191463470459
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.5/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.5/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.5/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.5/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.5/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04121337831020355
  zero_point: 151
  minval: -6.223219871520996
  maxval: 4.286191463470459
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.5.attention.self.query.bias:0"
input: "/encoder/layer.5/attention/self/query/MatMul_output_0:0"
input: "encoder.layer.5.attention.self.query.bias_min:0"
input: "encoder.layer.5.attention.self.query.bias_max:0"
input: "/encoder/layer.5/attention/self/query/MatMul_output_0:1"
input: "/encoder/layer.5/attention/self/query/MatMul_output_0:2"
input: "/encoder/layer.5/attention/self/query/Add_output_0_min:0"
input: "/encoder/layer.5/attention/self/query/Add_output_0_max:0"
output: "/encoder/layer.5/attention/self/query/Add_output_0:0"
name: "/encoder/layer.5/attention/self/query/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04385722801089287
  zero_point: 150
  minval: -6.57858419418335
  maxval: 4.605009078979492
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/query/Add_output_0:0"
input: "/encoder/layer.5/attention/self/Reshape_2/shape:0"
input: "/encoder/layer.5/attention/self/query/Add_output_0:1"
input: "/encoder/layer.5/attention/self/query/Add_output_0:2"
output: "/encoder/layer.5/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.5/attention/self/Reshape_2"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04385722801089287
  zero_point: 150
  minval: -6.57858419418335
  maxval: 4.605009078979492
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/Reshape_2_output_0:0"
input: "/encoder/layer.5/attention/self/Transpose_1/shape:0"
input: "/encoder/layer.5/attention/self/Reshape_2_output_0_min:0"
input: "/encoder/layer.5/attention/self/Reshape_2_output_0_max:0"
output: "/encoder/layer.5/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.5/attention/self/Transpose_1"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04385722801089287
  zero_point: 150
  minval: -6.57858419418335
  maxval: 4.605009078979492
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1451"
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1451_min:0"
input: "onnx::MatMul_1451_max:0"
output: "/encoder/layer.5/attention/self/key/MatMul_output_0_matmul:0"
name: "/encoder/layer.5/attention/self/key/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03027612902224064
  zero_point: 131
  minval: -3.966172933578491
  maxval: 3.754240036010742
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.5/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.5/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.5/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.5/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.5/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03027612902224064
  zero_point: 131
  minval: -3.966172933578491
  maxval: 3.754240036010742
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.5.attention.self.key.bias:0"
input: "/encoder/layer.5/attention/self/key/MatMul_output_0:0"
input: "encoder.layer.5.attention.self.key.bias_min:0"
input: "encoder.layer.5.attention.self.key.bias_max:0"
input: "/encoder/layer.5/attention/self/key/MatMul_output_0:1"
input: "/encoder/layer.5/attention/self/key/MatMul_output_0:2"
input: "/encoder/layer.5/attention/self/key/Add_output_0_min:0"
input: "/encoder/layer.5/attention/self/key/Add_output_0_max:0"
output: "/encoder/layer.5/attention/self/key/Add_output_0:0"
name: "/encoder/layer.5/attention/self/key/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.030347755178809166
  zero_point: 132
  minval: -4.005903720855713
  maxval: 3.732774019241333
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/key/Add_output_0:0"
input: "/encoder/layer.5/attention/self/Reshape/shape:0"
input: "/encoder/layer.5/attention/self/key/Add_output_0:1"
input: "/encoder/layer.5/attention/self/key/Add_output_0:2"
output: "/encoder/layer.5/attention/self/Reshape_output_0:0"
name: "/encoder/layer.5/attention/self/Reshape"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.030347755178809166
  zero_point: 132
  minval: -4.005903720855713
  maxval: 3.732774019241333
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/Reshape_output_0:0"
input: "/encoder/layer.5/attention/self/Transpose_2/shape:0"
input: "/encoder/layer.5/attention/self/Reshape_output_0_min:0"
input: "/encoder/layer.5/attention/self/Reshape_output_0_max:0"
output: "/encoder/layer.5/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.5/attention/self/Transpose_2"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.030347755178809166
  zero_point: 132
  minval: -4.005903720855713
  maxval: 3.732774019241333
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.5/attention/self/Transpose_2_output_0:0"
input: "/encoder/layer.5/attention/self/Transpose_1_output_0:1"
input: "/encoder/layer.5/attention/self/Transpose_1_output_0:2"
input: "/encoder/layer.5/attention/self/Transpose_2_output_0:1"
input: "/encoder/layer.5/attention/self/Transpose_2_output_0:2"
output: "/encoder/layer.5/attention/self/MatMul_output_0_batchmatmul:0"
name: "/encoder/layer.5/attention/self/MatMul_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.3326273262500763
  zero_point: 54
  minval: -17.961875915527344
  maxval: 66.85809326171875
}
padding: 0
out_max_byte_size: 1728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.5/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.5/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.5/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.5/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.5/attention/self/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.3326273262500763
  zero_point: 54
  minval: -17.961875915527344
  maxval: 66.85809326171875
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/MatMul_output_0:0"
input: "/encoder/layer.5/attention/self/Div/b:0"
input: "/encoder/layer.5/attention/self/MatMul_output_0:1"
input: "/encoder/layer.5/attention/self/MatMul_output_0:2"
input: "/encoder/layer.5/attention/self/Div/b_min:0"
input: "/encoder/layer.5/attention/self/Div/b_max:0"
input: "/encoder/layer.5/attention/self/Div_output_0_min:0"
input: "/encoder/layer.5/attention/self/Div_output_0_max:0"
output: "/encoder/layer.5/attention/self/Div_output_0:0"
name: "/encoder/layer.5/attention/self/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.041578419506549835
  zero_point: 54
  minval: -2.245234489440918
  maxval: 8.357261657714844
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/Div_output_0:0"
input: "/Mul_output_0:0"
input: "/encoder/layer.5/attention/self/Div_output_0:1"
input: "/encoder/layer.5/attention/self/Div_output_0:2"
input: "/Mul_output_0:1"
input: "/Mul_output_0:2"
input: "/encoder/layer.5/attention/self/Add_output_0_min:0"
input: "/encoder/layer.5/attention/self/Add_output_0_max:0"
output: "/encoder/layer.5/attention/self/Add_output_0:0"
name: "/encoder/layer.5/attention/self/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/Add_output_0:0"
input: "/encoder/layer.5/attention/self/Add_output_0:1"
input: "/encoder/layer.5/attention/self/Add_output_0:2"
output: "/encoder/layer.5/attention/self/Softmax_output_0:0"
name: "/encoder/layer.5/attention/self/Softmax"
type: "QuantizedSoftmax_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1457"
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1457_min:0"
input: "onnx::MatMul_1457_max:0"
output: "/encoder/layer.5/attention/self/value/MatMul_output_0_matmul:0"
name: "/encoder/layer.5/attention/self/value/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018208399415016174
  zero_point: 117
  minval: -2.130382537841797
  maxval: 2.51275897026062
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.5/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.5/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.5/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.5/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.5/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.5/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018208399415016174
  zero_point: 117
  minval: -2.130382537841797
  maxval: 2.51275897026062
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.5.attention.self.value.bias:0"
input: "/encoder/layer.5/attention/self/value/MatMul_output_0:0"
input: "encoder.layer.5.attention.self.value.bias_min:0"
input: "encoder.layer.5.attention.self.value.bias_max:0"
input: "/encoder/layer.5/attention/self/value/MatMul_output_0:1"
input: "/encoder/layer.5/attention/self/value/MatMul_output_0:2"
input: "/encoder/layer.5/attention/self/value/Add_output_0_min:0"
input: "/encoder/layer.5/attention/self/value/Add_output_0_max:0"
output: "/encoder/layer.5/attention/self/value/Add_output_0:0"
name: "/encoder/layer.5/attention/self/value/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018352163955569267
  zero_point: 116
  minval: -2.1288509368896484
  maxval: 2.550950765609741
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/value/Add_output_0:0"
input: "/encoder/layer.5/attention/self/Reshape_1/shape:0"
input: "/encoder/layer.5/attention/self/value/Add_output_0:1"
input: "/encoder/layer.5/attention/self/value/Add_output_0:2"
output: "/encoder/layer.5/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.5/attention/self/Reshape_1"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018352163955569267
  zero_point: 116
  minval: -2.1288509368896484
  maxval: 2.550950765609741
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/Reshape_1_output_0:0"
input: "/encoder/layer.5/attention/self/Transpose/shape:0"
input: "/encoder/layer.5/attention/self/Reshape_1_output_0_min:0"
input: "/encoder/layer.5/attention/self/Reshape_1_output_0_max:0"
output: "/encoder/layer.5/attention/self/Transpose_output_0:0"
name: "/encoder/layer.5/attention/self/Transpose"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018352163955569267
  zero_point: 116
  minval: -2.1288509368896484
  maxval: 2.550950765609741
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/Softmax_output_0:0"
input: "/encoder/layer.5/attention/self/Transpose_output_0:0"
input: "/encoder/layer.5/attention/self/Softmax_output_0:1"
input: "/encoder/layer.5/attention/self/Softmax_output_0:2"
input: "/encoder/layer.5/attention/self/Transpose_output_0:1"
input: "/encoder/layer.5/attention/self/Transpose_output_0:2"
output: "/encoder/layer.5/attention/self/MatMul_1_output_0_batchmatmul:0"
name: "/encoder/layer.5/attention/self/MatMul_1_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007289385888725519
  zero_point: 141
  minval: -1.0278034210205078
  maxval: 0.8309900164604187
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.5/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.5/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.5/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.5/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.5/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.5/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007289385888725519
  zero_point: 141
  minval: -1.0278034210205078
  maxval: 0.8309900164604187
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/MatMul_1_output_0:0"
input: "/encoder/layer.5/attention/self/Transpose_3/shape:0"
input: "/encoder/layer.5/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.5/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.5/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.5/attention/self/Transpose_3"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007289385888725519
  zero_point: 141
  minval: -1.0278034210205078
  maxval: 0.8309900164604187
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/Transpose_3_output_0:0"
input: "/encoder/layer.5/attention/self/Reshape_3/shape:0"
input: "/encoder/layer.5/attention/self/Transpose_3_output_0:1"
input: "/encoder/layer.5/attention/self/Transpose_3_output_0:2"
output: "/encoder/layer.5/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.5/attention/self/Reshape_3"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007289385888725519
  zero_point: 141
  minval: -1.0278034210205078
  maxval: 0.8309900164604187
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1472"
input: "/encoder/layer.5/attention/self/Reshape_3_output_0:1"
input: "/encoder/layer.5/attention/self/Reshape_3_output_0:2"
input: "onnx::MatMul_1472_min:0"
input: "onnx::MatMul_1472_max:0"
output: "/encoder/layer.5/attention/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.5/attention/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007264192681759596
  zero_point: 140
  minval: -1.0169869661331177
  maxval: 0.8353821635246277
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.5/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.5/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.5/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.5/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.5/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.5/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007264192681759596
  zero_point: 140
  minval: -1.0169869661331177
  maxval: 0.8353821635246277
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.5.attention.output.dense.bias:0"
input: "/encoder/layer.5/attention/output/dense/MatMul_output_0:0"
input: "encoder.layer.5.attention.output.dense.bias_min:0"
input: "encoder.layer.5.attention.output.dense.bias_max:0"
input: "/encoder/layer.5/attention/output/dense/MatMul_output_0:1"
input: "/encoder/layer.5/attention/output/dense/MatMul_output_0:2"
input: "/encoder/layer.5/attention/output/dense/Add_output_0_min:0"
input: "/encoder/layer.5/attention/output/dense/Add_output_0_max:0"
output: "/encoder/layer.5/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.5/attention/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.006811340339481831
  zero_point: 141
  minval: -0.9603989720344543
  maxval: 0.7764928340911865
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/output/dense/Add_output_0:0"
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.5/attention/output/dense/Add_output_0:1"
input: "/encoder/layer.5/attention/output/dense/Add_output_0:2"
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.4/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.5/attention/output/Add_output_0_min:0"
input: "/encoder/layer.5/attention/output/Add_output_0_max:0"
output: "/encoder/layer.5/attention/output/Add_output_0:0"
name: "/encoder/layer.5/attention/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06836176663637161
  zero_point: 221
  minval: -15.107950210571289
  maxval: 2.3243000507354736
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/output/Add_output_0:0"
input: "/encoder/layer.5/attention/output/Add_output_0:1"
input: "/encoder/layer.5/attention/output/Add_output_0:2"
input: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.00010129019938176498
  zero_point: 255
  minval: -0.025829000398516655
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/output/Add_output_0:0"
input: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.5/attention/output/Add_output_0:1"
input: "/encoder/layer.5/attention/output/Add_output_0:2"
input: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.5/attention/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.5/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06855965405702591
  zero_point: 220
  minval: -15.083124160766602
  maxval: 2.399587869644165
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.5/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.5/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.5/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.5/attention/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.5/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.8921594023704529
  zero_point: 0
  minval: 0.0
  maxval: 227.50064086914062
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.5/attention/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0026996235828846693
  zero_point: 0
  minval: 0.0
  maxval: 0.6884040236473083
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Add/b:0"
input: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.5/attention/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.5/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0026996235828846693
  zero_point: 0
  minval: 0.0
  maxval: 0.6884040236473083
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.5/attention/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0032537293154746294
  zero_point: 0
  minval: 0.0
  maxval: 0.8297010064125061
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.5/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.5/attention/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.5/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.09705068171024323
  zero_point: 224
  minval: -21.73935317993164
  maxval: 3.008571147918701
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.5.attention.output.LayerNorm.weight:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.5/attention/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.5.attention.output.LayerNorm.weight_min:0"
input: "encoder.layer.5.attention.output.LayerNorm.weight_max:0"
output: "/encoder/layer.5/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.3000943660736084
  zero_point: 246
  minval: -73.82321166992188
  maxval: 2.7008492946624756
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.5.attention.output.LayerNorm.bias:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.5/attention/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.5.attention.output.LayerNorm.bias_min:0"
input: "encoder.layer.5.attention.output.LayerNorm.bias_max:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.5/attention/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.30701619386672974
  zero_point: 245
  minval: -75.2189712524414
  maxval: 3.070162057876587
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1473"
input: "/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1473_min:0"
input: "onnx::MatMul_1473_max:0"
output: "/encoder/layer.5/intermediate/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.5/intermediate/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.1768578439950943
  zero_point: 236
  minval: -41.73844909667969
  maxval: 3.3602991104125977
}
padding: 0
out_max_byte_size: 73728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.5/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.5/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.5/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.5/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.5/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.5/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.1768578439950943
  zero_point: 236
  minval: -41.73844909667969
  maxval: 3.3602991104125977
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/intermediate/dense/MatMul_output_0:0"
input: "/encoder/layer.5/intermediate/dense/MatMul_output_0:1"
input: "/encoder/layer.5/intermediate/dense/MatMul_output_0:2"
output: "/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1"
type: "QuantizedGelu_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01231791265308857
  zero_point: 14
  minval: -0.17245078086853027
  maxval: 2.9686169624328613
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1474"
input: "/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0:1"
input: "/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0:2"
input: "onnx::MatMul_1474_min:0"
input: "onnx::MatMul_1474_max:0"
output: "/encoder/layer.5/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.5/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.08409030735492706
  zero_point: 214
  minval: -17.995325088500977
  maxval: 3.447702407836914
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.5/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.5/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.5/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.5/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.5/output/dense/MatMul_output_0:0"
name: "/encoder/layer.5/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.08409030735492706
  zero_point: 214
  minval: -17.995325088500977
  maxval: 3.447702407836914
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.5.output.dense.bias:0"
input: "/encoder/layer.5/output/dense/MatMul_output_0:0"
input: "encoder.layer.5.output.dense.bias_min:0"
input: "encoder.layer.5.output.dense.bias_max:0"
input: "/encoder/layer.5/output/dense/MatMul_output_0:1"
input: "/encoder/layer.5/output/dense/MatMul_output_0:2"
input: "/encoder/layer.5/output/dense/Add_output_0_min:0"
input: "/encoder/layer.5/output/dense/Add_output_0_max:0"
output: "/encoder/layer.5/output/dense/Add_output_0:0"
name: "/encoder/layer.5/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.08303789794445038
  zero_point: 220
  minval: -18.26833724975586
  maxval: 2.9063262939453125
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/output/dense/Add_output_0:0"
input: "/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.5/output/dense/Add_output_0:1"
input: "/encoder/layer.5/output/dense/Add_output_0:2"
input: "/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.5/output/Add_output_0_min:0"
input: "/encoder/layer.5/output/Add_output_0_max:0"
output: "/encoder/layer.5/output/Add_output_0:0"
name: "/encoder/layer.5/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.38002970814704895
  zero_point: 246
  minval: -93.4873046875
  maxval: 3.420267343521118
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/output/Add_output_0:0"
input: "/encoder/layer.5/output/Add_output_0:1"
input: "/encoder/layer.5/output/Add_output_0:2"
input: "/encoder/layer.5/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.5/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.5/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.5/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.00043829018250107765
  zero_point: 255
  minval: -0.11176399886608124
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/output/Add_output_0:0"
input: "/encoder/layer.5/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.5/output/Add_output_0:1"
input: "/encoder/layer.5/output/Add_output_0:2"
input: "/encoder/layer.5/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.5/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.5/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.5/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.5/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.37957537174224854
  zero_point: 246
  minval: -93.37554168701172
  maxval: 3.4161784648895264
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.5/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.5/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.5/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.5/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.5/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.5/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.5/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.5/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 34.1921272277832
  zero_point: 0
  minval: 0.0
  maxval: 8718.9921875
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.5/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.5/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.5/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.045663971453905106
  zero_point: 0
  minval: 0.0
  maxval: 11.644312858581543
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.5/output/LayerNorm/Add/b:0"
input: "/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.5/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.5/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.5/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.5/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.5/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.045663971453905106
  zero_point: 0
  minval: 0.0
  maxval: 11.644312858581543
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.5/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.5/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.5/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.013381866738200188
  zero_point: 0
  minval: 0.0
  maxval: 3.4123759269714355
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.5/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.5/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.5/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.5/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.5/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.5/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.5/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.5/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.11845795065164566
  zero_point: 231
  minval: -27.363786697387695
  maxval: 2.8429908752441406
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.5.output.LayerNorm.weight:0"
input: "/encoder/layer.5/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.5/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.5.output.LayerNorm.weight_min:0"
input: "encoder.layer.5.output.LayerNorm.weight_max:0"
output: "/encoder/layer.5/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07036226242780685
  zero_point: 222
  minval: -15.620423316955566
  maxval: 2.3219547271728516
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.5.output.LayerNorm.bias:0"
input: "/encoder/layer.5/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.5/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.5.output.LayerNorm.bias_min:0"
input: "encoder.layer.5.output.LayerNorm.bias_max:0"
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.5/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06854751706123352
  zero_point: 222
  minval: -15.217549324035645
  maxval: 2.262068033218384
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1475"
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1475_min:0"
input: "onnx::MatMul_1475_max:0"
output: "/encoder/layer.6/attention/self/query/MatMul_output_0_matmul:0"
name: "/encoder/layer.6/attention/self/query/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04819261282682419
  zero_point: 144
  minval: -6.939736366271973
  maxval: 5.349380016326904
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.6/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.6/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.6/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.6/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.6/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04819261282682419
  zero_point: 144
  minval: -6.939736366271973
  maxval: 5.349380016326904
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.6.attention.self.query.bias:0"
input: "/encoder/layer.6/attention/self/query/MatMul_output_0:0"
input: "encoder.layer.6.attention.self.query.bias_min:0"
input: "encoder.layer.6.attention.self.query.bias_max:0"
input: "/encoder/layer.6/attention/self/query/MatMul_output_0:1"
input: "/encoder/layer.6/attention/self/query/MatMul_output_0:2"
input: "/encoder/layer.6/attention/self/query/Add_output_0_min:0"
input: "/encoder/layer.6/attention/self/query/Add_output_0_max:0"
output: "/encoder/layer.6/attention/self/query/Add_output_0:0"
name: "/encoder/layer.6/attention/self/query/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.051366306841373444
  zero_point: 144
  minval: -7.396748065948486
  maxval: 5.701659679412842
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/query/Add_output_0:0"
input: "/encoder/layer.6/attention/self/Reshape_2/shape:0"
input: "/encoder/layer.6/attention/self/query/Add_output_0:1"
input: "/encoder/layer.6/attention/self/query/Add_output_0:2"
output: "/encoder/layer.6/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.6/attention/self/Reshape_2"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.051366306841373444
  zero_point: 144
  minval: -7.396748065948486
  maxval: 5.701659679412842
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/Reshape_2_output_0:0"
input: "/encoder/layer.6/attention/self/Transpose_1/shape:0"
input: "/encoder/layer.6/attention/self/Reshape_2_output_0_min:0"
input: "/encoder/layer.6/attention/self/Reshape_2_output_0_max:0"
output: "/encoder/layer.6/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.6/attention/self/Transpose_1"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.051366306841373444
  zero_point: 144
  minval: -7.396748065948486
  maxval: 5.701659679412842
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1476"
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1476_min:0"
input: "onnx::MatMul_1476_max:0"
output: "/encoder/layer.6/attention/self/key/MatMul_output_0_matmul:0"
name: "/encoder/layer.6/attention/self/key/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03172209858894348
  zero_point: 140
  minval: -4.441093921661377
  maxval: 3.6480414867401123
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.6/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.6/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.6/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.6/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.6/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03172209858894348
  zero_point: 140
  minval: -4.441093921661377
  maxval: 3.6480414867401123
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.6.attention.self.key.bias:0"
input: "/encoder/layer.6/attention/self/key/MatMul_output_0:0"
input: "encoder.layer.6.attention.self.key.bias_min:0"
input: "encoder.layer.6.attention.self.key.bias_max:0"
input: "/encoder/layer.6/attention/self/key/MatMul_output_0:1"
input: "/encoder/layer.6/attention/self/key/MatMul_output_0:2"
input: "/encoder/layer.6/attention/self/key/Add_output_0_min:0"
input: "/encoder/layer.6/attention/self/key/Add_output_0_max:0"
output: "/encoder/layer.6/attention/self/key/Add_output_0:0"
name: "/encoder/layer.6/attention/self/key/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.031865593045949936
  zero_point: 139
  minval: -4.429317474365234
  maxval: 3.696408987045288
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/key/Add_output_0:0"
input: "/encoder/layer.6/attention/self/Reshape/shape:0"
input: "/encoder/layer.6/attention/self/key/Add_output_0:1"
input: "/encoder/layer.6/attention/self/key/Add_output_0:2"
output: "/encoder/layer.6/attention/self/Reshape_output_0:0"
name: "/encoder/layer.6/attention/self/Reshape"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.031865593045949936
  zero_point: 139
  minval: -4.429317474365234
  maxval: 3.696408987045288
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/Reshape_output_0:0"
input: "/encoder/layer.6/attention/self/Transpose_2/shape:0"
input: "/encoder/layer.6/attention/self/Reshape_output_0_min:0"
input: "/encoder/layer.6/attention/self/Reshape_output_0_max:0"
output: "/encoder/layer.6/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.6/attention/self/Transpose_2"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.031865593045949936
  zero_point: 139
  minval: -4.429317474365234
  maxval: 3.696408987045288
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.6/attention/self/Transpose_2_output_0:0"
input: "/encoder/layer.6/attention/self/Transpose_1_output_0:1"
input: "/encoder/layer.6/attention/self/Transpose_1_output_0:2"
input: "/encoder/layer.6/attention/self/Transpose_2_output_0:1"
input: "/encoder/layer.6/attention/self/Transpose_2_output_0:2"
output: "/encoder/layer.6/attention/self/MatMul_output_0_batchmatmul:0"
name: "/encoder/layer.6/attention/self/MatMul_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.34057220816612244
  zero_point: 44
  minval: -14.985177040100098
  maxval: 71.86073303222656
}
padding: 0
out_max_byte_size: 1728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.6/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.6/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.6/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.6/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.6/attention/self/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.34057220816612244
  zero_point: 44
  minval: -14.985177040100098
  maxval: 71.86073303222656
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/MatMul_output_0:0"
input: "/encoder/layer.6/attention/self/Div/b:0"
input: "/encoder/layer.6/attention/self/MatMul_output_0:1"
input: "/encoder/layer.6/attention/self/MatMul_output_0:2"
input: "/encoder/layer.6/attention/self/Div/b_min:0"
input: "/encoder/layer.6/attention/self/Div/b_max:0"
input: "/encoder/layer.6/attention/self/Div_output_0_min:0"
input: "/encoder/layer.6/attention/self/Div_output_0_max:0"
output: "/encoder/layer.6/attention/self/Div_output_0:0"
name: "/encoder/layer.6/attention/self/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.042571522295475006
  zero_point: 44
  minval: -1.8731470108032227
  maxval: 8.98259162902832
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/Div_output_0:0"
input: "/Mul_output_0:0"
input: "/encoder/layer.6/attention/self/Div_output_0:1"
input: "/encoder/layer.6/attention/self/Div_output_0:2"
input: "/Mul_output_0:1"
input: "/Mul_output_0:2"
input: "/encoder/layer.6/attention/self/Add_output_0_min:0"
input: "/encoder/layer.6/attention/self/Add_output_0_max:0"
output: "/encoder/layer.6/attention/self/Add_output_0:0"
name: "/encoder/layer.6/attention/self/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/Add_output_0:0"
input: "/encoder/layer.6/attention/self/Add_output_0:1"
input: "/encoder/layer.6/attention/self/Add_output_0:2"
output: "/encoder/layer.6/attention/self/Softmax_output_0:0"
name: "/encoder/layer.6/attention/self/Softmax"
type: "QuantizedSoftmax_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1482"
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1482_min:0"
input: "onnx::MatMul_1482_max:0"
output: "/encoder/layer.6/attention/self/value/MatMul_output_0_matmul:0"
name: "/encoder/layer.6/attention/self/value/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018793268129229546
  zero_point: 128
  minval: -2.405538320541382
  maxval: 2.386744976043701
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.6/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.6/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.6/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.6/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.6/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.6/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018793268129229546
  zero_point: 128
  minval: -2.405538320541382
  maxval: 2.386744976043701
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.6.attention.self.value.bias:0"
input: "/encoder/layer.6/attention/self/value/MatMul_output_0:0"
input: "encoder.layer.6.attention.self.value.bias_min:0"
input: "encoder.layer.6.attention.self.value.bias_max:0"
input: "/encoder/layer.6/attention/self/value/MatMul_output_0:1"
input: "/encoder/layer.6/attention/self/value/MatMul_output_0:2"
input: "/encoder/layer.6/attention/self/value/Add_output_0_min:0"
input: "/encoder/layer.6/attention/self/value/Add_output_0_max:0"
output: "/encoder/layer.6/attention/self/value/Add_output_0:0"
name: "/encoder/layer.6/attention/self/value/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01886012591421604
  zero_point: 128
  minval: -2.4140961170196533
  maxval: 2.395236015319824
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/value/Add_output_0:0"
input: "/encoder/layer.6/attention/self/Reshape_1/shape:0"
input: "/encoder/layer.6/attention/self/value/Add_output_0:1"
input: "/encoder/layer.6/attention/self/value/Add_output_0:2"
output: "/encoder/layer.6/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.6/attention/self/Reshape_1"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01886012591421604
  zero_point: 128
  minval: -2.4140961170196533
  maxval: 2.395236015319824
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/Reshape_1_output_0:0"
input: "/encoder/layer.6/attention/self/Transpose/shape:0"
input: "/encoder/layer.6/attention/self/Reshape_1_output_0_min:0"
input: "/encoder/layer.6/attention/self/Reshape_1_output_0_max:0"
output: "/encoder/layer.6/attention/self/Transpose_output_0:0"
name: "/encoder/layer.6/attention/self/Transpose"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01886012591421604
  zero_point: 128
  minval: -2.4140961170196533
  maxval: 2.395236015319824
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/Softmax_output_0:0"
input: "/encoder/layer.6/attention/self/Transpose_output_0:0"
input: "/encoder/layer.6/attention/self/Softmax_output_0:1"
input: "/encoder/layer.6/attention/self/Softmax_output_0:2"
input: "/encoder/layer.6/attention/self/Transpose_output_0:1"
input: "/encoder/layer.6/attention/self/Transpose_output_0:2"
output: "/encoder/layer.6/attention/self/MatMul_1_output_0_batchmatmul:0"
name: "/encoder/layer.6/attention/self/MatMul_1_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010126526467502117
  zero_point: 124
  minval: -1.255689263343811
  maxval: 1.3265750408172607
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.6/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.6/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.6/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.6/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.6/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.6/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010126526467502117
  zero_point: 124
  minval: -1.255689263343811
  maxval: 1.3265750408172607
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/MatMul_1_output_0:0"
input: "/encoder/layer.6/attention/self/Transpose_3/shape:0"
input: "/encoder/layer.6/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.6/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.6/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.6/attention/self/Transpose_3"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010126526467502117
  zero_point: 124
  minval: -1.255689263343811
  maxval: 1.3265750408172607
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/Transpose_3_output_0:0"
input: "/encoder/layer.6/attention/self/Reshape_3/shape:0"
input: "/encoder/layer.6/attention/self/Transpose_3_output_0:1"
input: "/encoder/layer.6/attention/self/Transpose_3_output_0:2"
output: "/encoder/layer.6/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.6/attention/self/Reshape_3"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010126526467502117
  zero_point: 124
  minval: -1.255689263343811
  maxval: 1.3265750408172607
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1497"
input: "/encoder/layer.6/attention/self/Reshape_3_output_0:1"
input: "/encoder/layer.6/attention/self/Reshape_3_output_0:2"
input: "onnx::MatMul_1497_min:0"
input: "onnx::MatMul_1497_max:0"
output: "/encoder/layer.6/attention/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.6/attention/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010015870444476604
  zero_point: 108
  minval: -1.0817140340805054
  maxval: 1.4723329544067383
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.6/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.6/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.6/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.6/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.6/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.6/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010015870444476604
  zero_point: 108
  minval: -1.0817140340805054
  maxval: 1.4723329544067383
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.6.attention.output.dense.bias:0"
input: "/encoder/layer.6/attention/output/dense/MatMul_output_0:0"
input: "encoder.layer.6.attention.output.dense.bias_min:0"
input: "encoder.layer.6.attention.output.dense.bias_max:0"
input: "/encoder/layer.6/attention/output/dense/MatMul_output_0:1"
input: "/encoder/layer.6/attention/output/dense/MatMul_output_0:2"
input: "/encoder/layer.6/attention/output/dense/Add_output_0_min:0"
input: "/encoder/layer.6/attention/output/dense/Add_output_0_max:0"
output: "/encoder/layer.6/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.6/attention/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.009534415788948536
  zero_point: 106
  minval: -1.0106481313705444
  maxval: 1.4206279516220093
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/output/dense/Add_output_0:0"
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.6/attention/output/dense/Add_output_0:1"
input: "/encoder/layer.6/attention/output/dense/Add_output_0:2"
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.5/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.6/attention/output/Add_output_0_min:0"
input: "/encoder/layer.6/attention/output/Add_output_0_max:0"
output: "/encoder/layer.6/attention/output/Add_output_0:0"
name: "/encoder/layer.6/attention/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07113279402256012
  zero_point: 215
  minval: -15.293551445007324
  maxval: 2.8453118801116943
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/output/Add_output_0:0"
input: "/encoder/layer.6/attention/output/Add_output_0:1"
input: "/encoder/layer.6/attention/output/Add_output_0:2"
input: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 8.529411570634693e-05
  zero_point: 255
  minval: -0.02174999937415123
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/output/Add_output_0:0"
input: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.6/attention/output/Add_output_0:1"
input: "/encoder/layer.6/attention/output/Add_output_0:2"
input: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.6/attention/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.6/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07103818655014038
  zero_point: 215
  minval: -15.273209571838379
  maxval: 2.8415274620056152
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.6/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.6/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.6/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.6/attention/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.6/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.914788007736206
  zero_point: 0
  minval: 0.0
  maxval: 233.27093505859375
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.6/attention/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0029960430692881346
  zero_point: 0
  minval: 0.0
  maxval: 0.7639909982681274
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Add/b:0"
input: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.6/attention/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.6/attention/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.6/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0029960430692881346
  zero_point: 0
  minval: 0.0
  maxval: 0.7639909982681274
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.6/attention/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.6/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0034277099184691906
  zero_point: 0
  minval: 0.0
  maxval: 0.8740659952163696
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.6/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.6/attention/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.6/attention/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.6/attention/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.6/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.09561571478843689
  zero_point: 221
  minval: -21.131072998046875
  maxval: 3.250934362411499
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.6.attention.output.LayerNorm.weight:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.6/attention/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.6.attention.output.LayerNorm.weight_min:0"
input: "encoder.layer.6.attention.output.LayerNorm.weight_max:0"
output: "/encoder/layer.6/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.28843748569488525
  zero_point: 245
  minval: -70.66718292236328
  maxval: 2.8843748569488525
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.6.attention.output.LayerNorm.bias:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.6/attention/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.6.attention.output.LayerNorm.bias_min:0"
input: "encoder.layer.6.attention.output.LayerNorm.bias_max:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.6/attention/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.29661065340042114
  zero_point: 245
  minval: -72.66960906982422
  maxval: 2.966106414794922
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1498"
input: "/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1498_min:0"
input: "onnx::MatMul_1498_max:0"
output: "/encoder/layer.6/intermediate/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.6/intermediate/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0957103744149208
  zero_point: 213
  minval: -20.386308670043945
  maxval: 4.019835472106934
}
padding: 0
out_max_byte_size: 73728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.6/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.6/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.6/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.6/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.6/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.6/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0957103744149208
  zero_point: 213
  minval: -20.386308670043945
  maxval: 4.019835472106934
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/intermediate/dense/MatMul_output_0:0"
input: "/encoder/layer.6/intermediate/dense/MatMul_output_0:1"
input: "/encoder/layer.6/intermediate/dense/MatMul_output_0:2"
output: "/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1"
type: "QuantizedGelu_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.015826361253857613
  zero_point: 11
  minval: -0.1740899682044983
  maxval: 3.8616321086883545
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1499"
input: "/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1_output_0:1"
input: "/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1_output_0:2"
input: "onnx::MatMul_1499_min:0"
input: "onnx::MatMul_1499_max:0"
output: "/encoder/layer.6/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.6/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07174398005008698
  zero_point: 219
  minval: -15.711932182312012
  maxval: 2.5827834606170654
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.6/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.6/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.6/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.6/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.6/output/dense/MatMul_output_0:0"
name: "/encoder/layer.6/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07174398005008698
  zero_point: 219
  minval: -15.711932182312012
  maxval: 2.5827834606170654
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.6.output.dense.bias:0"
input: "/encoder/layer.6/output/dense/MatMul_output_0:0"
input: "encoder.layer.6.output.dense.bias_min:0"
input: "encoder.layer.6.output.dense.bias_max:0"
input: "/encoder/layer.6/output/dense/MatMul_output_0:1"
input: "/encoder/layer.6/output/dense/MatMul_output_0:2"
input: "/encoder/layer.6/output/dense/Add_output_0_min:0"
input: "/encoder/layer.6/output/dense/Add_output_0_max:0"
output: "/encoder/layer.6/output/dense/Add_output_0:0"
name: "/encoder/layer.6/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07195455580949783
  zero_point: 226
  minval: -16.261730194091797
  maxval: 2.086682081222534
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/output/dense/Add_output_0:0"
input: "/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.6/output/dense/Add_output_0:1"
input: "/encoder/layer.6/output/dense/Add_output_0:2"
input: "/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.6/output/Add_output_0_min:0"
input: "/encoder/layer.6/output/Add_output_0_max:0"
output: "/encoder/layer.6/output/Add_output_0:0"
name: "/encoder/layer.6/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.3627967834472656
  zero_point: 246
  minval: -89.24800872802734
  maxval: 3.2651710510253906
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/output/Add_output_0:0"
input: "/encoder/layer.6/output/Add_output_0:1"
input: "/encoder/layer.6/output/Add_output_0:2"
input: "/encoder/layer.6/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.6/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.6/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.6/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.000435094116255641
  zero_point: 255
  minval: -0.11094900220632553
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/output/Add_output_0:0"
input: "/encoder/layer.6/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.6/output/Add_output_0:1"
input: "/encoder/layer.6/output/Add_output_0:2"
input: "/encoder/layer.6/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.6/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.6/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.6/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.6/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.3610585033893585
  zero_point: 246
  minval: -88.82038879394531
  maxval: 3.2495265007019043
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.6/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.6/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.6/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.6/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.6/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.6/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.6/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.6/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 30.937496185302734
  zero_point: 0
  minval: 0.0
  maxval: 7889.0615234375
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.6/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.6/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.6/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.6/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.6/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.6/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04150957241654396
  zero_point: 0
  minval: 0.0
  maxval: 10.584940910339355
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.6/output/LayerNorm/Add/b:0"
input: "/encoder/layer.6/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.6/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.6/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.6/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.6/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.6/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.6/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04150957241654396
  zero_point: 0
  minval: 0.0
  maxval: 10.584940910339355
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.6/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.6/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.6/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.012758631259202957
  zero_point: 0
  minval: 0.0
  maxval: 3.253451108932495
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.6/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.6/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.6/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.6/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.6/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.6/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.6/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.6/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.11900883913040161
  zero_point: 230
  minval: -27.372034072875977
  maxval: 2.9752209186553955
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.6.output.LayerNorm.weight:0"
input: "/encoder/layer.6/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.6/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.6.output.LayerNorm.weight_min:0"
input: "encoder.layer.6.output.LayerNorm.weight_max:0"
output: "/encoder/layer.6/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06669235229492188
  zero_point: 219
  minval: -14.60562515258789
  maxval: 2.4009246826171875
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.6.output.LayerNorm.bias:0"
input: "/encoder/layer.6/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.6/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.6.output.LayerNorm.bias_min:0"
input: "encoder.layer.6.output.LayerNorm.bias_max:0"
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.6/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06310923397541046
  zero_point: 219
  minval: -13.820921897888184
  maxval: 2.271932363510132
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1500"
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1500_min:0"
input: "onnx::MatMul_1500_max:0"
output: "/encoder/layer.7/attention/self/query/MatMul_output_0_matmul:0"
name: "/encoder/layer.7/attention/self/query/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04076783359050751
  zero_point: 139
  minval: -5.666728973388672
  maxval: 4.729068756103516
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.7/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.7/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.7/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.7/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.7/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04076783359050751
  zero_point: 139
  minval: -5.666728973388672
  maxval: 4.729068756103516
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.7.attention.self.query.bias:0"
input: "/encoder/layer.7/attention/self/query/MatMul_output_0:0"
input: "encoder.layer.7.attention.self.query.bias_min:0"
input: "encoder.layer.7.attention.self.query.bias_max:0"
input: "/encoder/layer.7/attention/self/query/MatMul_output_0:1"
input: "/encoder/layer.7/attention/self/query/MatMul_output_0:2"
input: "/encoder/layer.7/attention/self/query/Add_output_0_min:0"
input: "/encoder/layer.7/attention/self/query/Add_output_0_max:0"
output: "/encoder/layer.7/attention/self/query/Add_output_0:0"
name: "/encoder/layer.7/attention/self/query/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04643896594643593
  zero_point: 141
  minval: -6.54789400100708
  maxval: 5.294042110443115
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/query/Add_output_0:0"
input: "/encoder/layer.7/attention/self/Reshape_2/shape:0"
input: "/encoder/layer.7/attention/self/query/Add_output_0:1"
input: "/encoder/layer.7/attention/self/query/Add_output_0:2"
output: "/encoder/layer.7/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.7/attention/self/Reshape_2"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04643896594643593
  zero_point: 141
  minval: -6.54789400100708
  maxval: 5.294042110443115
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/Reshape_2_output_0:0"
input: "/encoder/layer.7/attention/self/Transpose_1/shape:0"
input: "/encoder/layer.7/attention/self/Reshape_2_output_0_min:0"
input: "/encoder/layer.7/attention/self/Reshape_2_output_0_max:0"
output: "/encoder/layer.7/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.7/attention/self/Transpose_1"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04643896594643593
  zero_point: 141
  minval: -6.54789400100708
  maxval: 5.294042110443115
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1501"
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1501_min:0"
input: "onnx::MatMul_1501_max:0"
output: "/encoder/layer.7/attention/self/key/MatMul_output_0_matmul:0"
name: "/encoder/layer.7/attention/self/key/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04032149165868759
  zero_point: 137
  minval: -5.524044513702393
  maxval: 4.757936000823975
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.7/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.7/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.7/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.7/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.7/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04032149165868759
  zero_point: 137
  minval: -5.524044513702393
  maxval: 4.757936000823975
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.7.attention.self.key.bias:0"
input: "/encoder/layer.7/attention/self/key/MatMul_output_0:0"
input: "encoder.layer.7.attention.self.key.bias_min:0"
input: "encoder.layer.7.attention.self.key.bias_max:0"
input: "/encoder/layer.7/attention/self/key/MatMul_output_0:1"
input: "/encoder/layer.7/attention/self/key/MatMul_output_0:2"
input: "/encoder/layer.7/attention/self/key/Add_output_0_min:0"
input: "/encoder/layer.7/attention/self/key/Add_output_0_max:0"
output: "/encoder/layer.7/attention/self/key/Add_output_0:0"
name: "/encoder/layer.7/attention/self/key/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04019321873784065
  zero_point: 137
  minval: -5.506471157073975
  maxval: 4.742799758911133
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/key/Add_output_0:0"
input: "/encoder/layer.7/attention/self/Reshape/shape:0"
input: "/encoder/layer.7/attention/self/key/Add_output_0:1"
input: "/encoder/layer.7/attention/self/key/Add_output_0:2"
output: "/encoder/layer.7/attention/self/Reshape_output_0:0"
name: "/encoder/layer.7/attention/self/Reshape"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04019321873784065
  zero_point: 137
  minval: -5.506471157073975
  maxval: 4.742799758911133
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/Reshape_output_0:0"
input: "/encoder/layer.7/attention/self/Transpose_2/shape:0"
input: "/encoder/layer.7/attention/self/Reshape_output_0_min:0"
input: "/encoder/layer.7/attention/self/Reshape_output_0_max:0"
output: "/encoder/layer.7/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.7/attention/self/Transpose_2"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04019321873784065
  zero_point: 137
  minval: -5.506471157073975
  maxval: 4.742799758911133
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.7/attention/self/Transpose_2_output_0:0"
input: "/encoder/layer.7/attention/self/Transpose_1_output_0:1"
input: "/encoder/layer.7/attention/self/Transpose_1_output_0:2"
input: "/encoder/layer.7/attention/self/Transpose_2_output_0:1"
input: "/encoder/layer.7/attention/self/Transpose_2_output_0:2"
output: "/encoder/layer.7/attention/self/MatMul_output_0_batchmatmul:0"
name: "/encoder/layer.7/attention/self/MatMul_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.34224170446395874
  zero_point: 66
  minval: -22.58795166015625
  maxval: 64.68367767333984
}
padding: 0
out_max_byte_size: 1728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.7/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.7/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.7/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.7/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.7/attention/self/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.34224170446395874
  zero_point: 66
  minval: -22.58795166015625
  maxval: 64.68367767333984
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/MatMul_output_0:0"
input: "/encoder/layer.7/attention/self/Div/b:0"
input: "/encoder/layer.7/attention/self/MatMul_output_0:1"
input: "/encoder/layer.7/attention/self/MatMul_output_0:2"
input: "/encoder/layer.7/attention/self/Div/b_min:0"
input: "/encoder/layer.7/attention/self/Div/b_max:0"
input: "/encoder/layer.7/attention/self/Div_output_0_min:0"
input: "/encoder/layer.7/attention/self/Div_output_0_max:0"
output: "/encoder/layer.7/attention/self/Div_output_0:0"
name: "/encoder/layer.7/attention/self/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04278021305799484
  zero_point: 66
  minval: -2.8234939575195312
  maxval: 8.08545970916748
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/Div_output_0:0"
input: "/Mul_output_0:0"
input: "/encoder/layer.7/attention/self/Div_output_0:1"
input: "/encoder/layer.7/attention/self/Div_output_0:2"
input: "/Mul_output_0:1"
input: "/Mul_output_0:2"
input: "/encoder/layer.7/attention/self/Add_output_0_min:0"
input: "/encoder/layer.7/attention/self/Add_output_0_max:0"
output: "/encoder/layer.7/attention/self/Add_output_0:0"
name: "/encoder/layer.7/attention/self/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/Add_output_0:0"
input: "/encoder/layer.7/attention/self/Add_output_0:1"
input: "/encoder/layer.7/attention/self/Add_output_0:2"
output: "/encoder/layer.7/attention/self/Softmax_output_0:0"
name: "/encoder/layer.7/attention/self/Softmax"
type: "QuantizedSoftmax_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1507"
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1507_min:0"
input: "onnx::MatMul_1507_max:0"
output: "/encoder/layer.7/attention/self/value/MatMul_output_0_matmul:0"
name: "/encoder/layer.7/attention/self/value/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01867643930017948
  zero_point: 141
  minval: -2.63337779045105
  maxval: 2.1291139125823975
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.7/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.7/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.7/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.7/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.7/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.7/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01867643930017948
  zero_point: 141
  minval: -2.63337779045105
  maxval: 2.1291139125823975
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.7.attention.self.value.bias:0"
input: "/encoder/layer.7/attention/self/value/MatMul_output_0:0"
input: "encoder.layer.7.attention.self.value.bias_min:0"
input: "encoder.layer.7.attention.self.value.bias_max:0"
input: "/encoder/layer.7/attention/self/value/MatMul_output_0:1"
input: "/encoder/layer.7/attention/self/value/MatMul_output_0:2"
input: "/encoder/layer.7/attention/self/value/Add_output_0_min:0"
input: "/encoder/layer.7/attention/self/value/Add_output_0_max:0"
output: "/encoder/layer.7/attention/self/value/Add_output_0:0"
name: "/encoder/layer.7/attention/self/value/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018876798450946808
  zero_point: 141
  minval: -2.661628484725952
  maxval: 2.1519548892974854
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/value/Add_output_0:0"
input: "/encoder/layer.7/attention/self/Reshape_1/shape:0"
input: "/encoder/layer.7/attention/self/value/Add_output_0:1"
input: "/encoder/layer.7/attention/self/value/Add_output_0:2"
output: "/encoder/layer.7/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.7/attention/self/Reshape_1"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018876798450946808
  zero_point: 141
  minval: -2.661628484725952
  maxval: 2.1519548892974854
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/Reshape_1_output_0:0"
input: "/encoder/layer.7/attention/self/Transpose/shape:0"
input: "/encoder/layer.7/attention/self/Reshape_1_output_0_min:0"
input: "/encoder/layer.7/attention/self/Reshape_1_output_0_max:0"
output: "/encoder/layer.7/attention/self/Transpose_output_0:0"
name: "/encoder/layer.7/attention/self/Transpose"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018876798450946808
  zero_point: 141
  minval: -2.661628484725952
  maxval: 2.1519548892974854
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/Softmax_output_0:0"
input: "/encoder/layer.7/attention/self/Transpose_output_0:0"
input: "/encoder/layer.7/attention/self/Softmax_output_0:1"
input: "/encoder/layer.7/attention/self/Softmax_output_0:2"
input: "/encoder/layer.7/attention/self/Transpose_output_0:1"
input: "/encoder/layer.7/attention/self/Transpose_output_0:2"
output: "/encoder/layer.7/attention/self/MatMul_1_output_0_batchmatmul:0"
name: "/encoder/layer.7/attention/self/MatMul_1_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007804992608726025
  zero_point: 134
  minval: -1.045868992805481
  maxval: 0.944404125213623
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.7/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.7/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.7/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.7/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.7/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.7/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007804992608726025
  zero_point: 134
  minval: -1.045868992805481
  maxval: 0.944404125213623
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/MatMul_1_output_0:0"
input: "/encoder/layer.7/attention/self/Transpose_3/shape:0"
input: "/encoder/layer.7/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.7/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.7/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.7/attention/self/Transpose_3"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007804992608726025
  zero_point: 134
  minval: -1.045868992805481
  maxval: 0.944404125213623
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/Transpose_3_output_0:0"
input: "/encoder/layer.7/attention/self/Reshape_3/shape:0"
input: "/encoder/layer.7/attention/self/Transpose_3_output_0:1"
input: "/encoder/layer.7/attention/self/Transpose_3_output_0:2"
output: "/encoder/layer.7/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.7/attention/self/Reshape_3"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007804992608726025
  zero_point: 134
  minval: -1.045868992805481
  maxval: 0.944404125213623
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1522"
input: "/encoder/layer.7/attention/self/Reshape_3_output_0:1"
input: "/encoder/layer.7/attention/self/Reshape_3_output_0:2"
input: "onnx::MatMul_1522_min:0"
input: "onnx::MatMul_1522_max:0"
output: "/encoder/layer.7/attention/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.7/attention/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.015512127429246902
  zero_point: 180
  minval: -2.7921829223632812
  maxval: 1.1634095907211304
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.7/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.7/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.7/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.7/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.7/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.7/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.015512127429246902
  zero_point: 180
  minval: -2.7921829223632812
  maxval: 1.1634095907211304
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.7.attention.output.dense.bias:0"
input: "/encoder/layer.7/attention/output/dense/MatMul_output_0:0"
input: "encoder.layer.7.attention.output.dense.bias_min:0"
input: "encoder.layer.7.attention.output.dense.bias_max:0"
input: "/encoder/layer.7/attention/output/dense/MatMul_output_0:1"
input: "/encoder/layer.7/attention/output/dense/MatMul_output_0:2"
input: "/encoder/layer.7/attention/output/dense/Add_output_0_min:0"
input: "/encoder/layer.7/attention/output/dense/Add_output_0_max:0"
output: "/encoder/layer.7/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.7/attention/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.009801630862057209
  zero_point: 144
  minval: -1.4114347696304321
  maxval: 1.0879809856414795
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/output/dense/Add_output_0:0"
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.7/attention/output/dense/Add_output_0:1"
input: "/encoder/layer.7/attention/output/dense/Add_output_0:2"
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.6/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.7/attention/output/Add_output_0_min:0"
input: "/encoder/layer.7/attention/output/Add_output_0_max:0"
output: "/encoder/layer.7/attention/output/Add_output_0:0"
name: "/encoder/layer.7/attention/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06986185163259506
  zero_point: 218
  minval: -15.229883193969727
  maxval: 2.584888458251953
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/output/Add_output_0:0"
input: "/encoder/layer.7/attention/output/Add_output_0:1"
input: "/encoder/layer.7/attention/output/Add_output_0:2"
input: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.00010946666589006782
  zero_point: 255
  minval: -0.027914000675082207
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/output/Add_output_0:0"
input: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.7/attention/output/Add_output_0:1"
input: "/encoder/layer.7/attention/output/Add_output_0:2"
input: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.7/attention/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.7/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.06974241137504578
  zero_point: 218
  minval: -15.203845024108887
  maxval: 2.5804691314697266
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.7/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.7/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.7/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.7/attention/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.7/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.9064976572990417
  zero_point: 0
  minval: 0.0
  maxval: 231.1569061279297
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.7/attention/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003200941253453493
  zero_point: 0
  minval: 0.0
  maxval: 0.8162400126457214
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Add/b:0"
input: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.7/attention/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.7/attention/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.7/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003200941253453493
  zero_point: 0
  minval: 0.0
  maxval: 0.8162400126457214
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.7/attention/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.7/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0035429804120212793
  zero_point: 0
  minval: 0.0
  maxval: 0.9034600257873535
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.7/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.7/attention/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.7/attention/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.7/attention/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.7/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.08873584866523743
  zero_point: 222
  minval: -19.699357986450195
  maxval: 2.9282829761505127
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.7.attention.output.LayerNorm.weight:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.7/attention/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.7.attention.output.LayerNorm.weight_min:0"
input: "encoder.layer.7.attention.output.LayerNorm.weight_max:0"
output: "/encoder/layer.7/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.27034851908683777
  zero_point: 245
  minval: -66.23538970947266
  maxval: 2.7034852504730225
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.7.attention.output.LayerNorm.bias:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.7/attention/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.7.attention.output.LayerNorm.bias_min:0"
input: "encoder.layer.7.attention.output.LayerNorm.bias_max:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.7/attention/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.27870744466781616
  zero_point: 245
  minval: -68.2833251953125
  maxval: 2.787074565887451
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1523"
input: "/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1523_min:0"
input: "onnx::MatMul_1523_max:0"
output: "/encoder/layer.7/intermediate/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.7/intermediate/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0668439120054245
  zero_point: 195
  minval: -13.034563064575195
  maxval: 4.010634899139404
}
padding: 0
out_max_byte_size: 73728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.7/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.7/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.7/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.7/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.7/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.7/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0668439120054245
  zero_point: 195
  minval: -13.034563064575195
  maxval: 4.010634899139404
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/intermediate/dense/MatMul_output_0:0"
input: "/encoder/layer.7/intermediate/dense/MatMul_output_0:1"
input: "/encoder/layer.7/intermediate/dense/MatMul_output_0:2"
output: "/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1"
type: "QuantizedGelu_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.015968652442097664
  zero_point: 11
  minval: -0.17565517127513885
  maxval: 3.8963510990142822
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1524"
input: "/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1_output_0:1"
input: "/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1_output_0:2"
input: "onnx::MatMul_1524_min:0"
input: "onnx::MatMul_1524_max:0"
output: "/encoder/layer.7/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.7/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.019198313355445862
  zero_point: 64
  minval: -1.2286920547485352
  maxval: 3.6668779850006104
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.7/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.7/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.7/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.7/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.7/output/dense/MatMul_output_0:0"
name: "/encoder/layer.7/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.019198313355445862
  zero_point: 64
  minval: -1.2286920547485352
  maxval: 3.6668779850006104
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.7.output.dense.bias:0"
input: "/encoder/layer.7/output/dense/MatMul_output_0:0"
input: "encoder.layer.7.output.dense.bias_min:0"
input: "encoder.layer.7.output.dense.bias_max:0"
input: "/encoder/layer.7/output/dense/MatMul_output_0:1"
input: "/encoder/layer.7/output/dense/MatMul_output_0:2"
input: "/encoder/layer.7/output/dense/Add_output_0_min:0"
input: "/encoder/layer.7/output/dense/Add_output_0_max:0"
output: "/encoder/layer.7/output/dense/Add_output_0:0"
name: "/encoder/layer.7/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.016439272090792656
  zero_point: 77
  minval: -1.2658239603042603
  maxval: 2.9261906147003174
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/output/dense/Add_output_0:0"
input: "/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.7/output/dense/Add_output_0:1"
input: "/encoder/layer.7/output/dense/Add_output_0:2"
input: "/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.7/output/Add_output_0_min:0"
input: "/encoder/layer.7/output/Add_output_0_max:0"
output: "/encoder/layer.7/output/Add_output_0:0"
name: "/encoder/layer.7/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.28545618057250977
  zero_point: 242
  minval: -69.08039855957031
  maxval: 3.710930585861206
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/output/Add_output_0:0"
input: "/encoder/layer.7/output/Add_output_0:1"
input: "/encoder/layer.7/output/Add_output_0:2"
input: "/encoder/layer.7/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.7/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.7/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.7/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.00036383920814841986
  zero_point: 255
  minval: -0.0927790030837059
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/output/Add_output_0:0"
input: "/encoder/layer.7/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.7/output/Add_output_0:1"
input: "/encoder/layer.7/output/Add_output_0:2"
input: "/encoder/layer.7/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.7/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.7/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.7/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.7/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.28507280349731445
  zero_point: 242
  minval: -68.98761749267578
  maxval: 3.705946445465088
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.7/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.7/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.7/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.7/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.7/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.7/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.7/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.7/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 18.663888931274414
  zero_point: 0
  minval: 0.0
  maxval: 4759.29150390625
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.7/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.7/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.7/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.7/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.7/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.7/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.025551553815603256
  zero_point: 0
  minval: 0.0
  maxval: 6.515645980834961
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.7/output/LayerNorm/Add/b:0"
input: "/encoder/layer.7/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.7/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.7/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.7/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.7/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.7/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.7/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.025551553815603256
  zero_point: 0
  minval: 0.0
  maxval: 6.515645980834961
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.7/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.7/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.7/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010010101832449436
  zero_point: 0
  minval: 0.0
  maxval: 2.5525760650634766
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.7/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.7/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.7/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.7/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.7/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.7/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.7/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.7/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.11906018853187561
  zero_point: 227
  minval: -27.026662826538086
  maxval: 3.3336853981018066
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.7.output.LayerNorm.weight:0"
input: "/encoder/layer.7/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.7/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.7.output.LayerNorm.weight_min:0"
input: "encoder.layer.7.output.LayerNorm.weight_max:0"
output: "/encoder/layer.7/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07451529055833817
  zero_point: 220
  minval: -16.39336395263672
  maxval: 2.608035087585449
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.7.output.LayerNorm.bias:0"
input: "/encoder/layer.7/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.7/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.7.output.LayerNorm.bias_min:0"
input: "encoder.layer.7.output.LayerNorm.bias_max:0"
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.7/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07047713547945023
  zero_point: 219
  minval: -15.434492111206055
  maxval: 2.5371768474578857
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1525"
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1525_min:0"
input: "onnx::MatMul_1525_max:0"
output: "/encoder/layer.8/attention/self/query/MatMul_output_0_matmul:0"
name: "/encoder/layer.8/attention/self/query/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03878064453601837
  zero_point: 127
  minval: -4.92514181137085
  maxval: 4.963922500610352
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.8/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.8/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.8/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.8/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.8/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03878064453601837
  zero_point: 127
  minval: -4.92514181137085
  maxval: 4.963922500610352
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.8.attention.self.query.bias:0"
input: "/encoder/layer.8/attention/self/query/MatMul_output_0:0"
input: "encoder.layer.8.attention.self.query.bias_min:0"
input: "encoder.layer.8.attention.self.query.bias_max:0"
input: "/encoder/layer.8/attention/self/query/MatMul_output_0:1"
input: "/encoder/layer.8/attention/self/query/MatMul_output_0:2"
input: "/encoder/layer.8/attention/self/query/Add_output_0_min:0"
input: "/encoder/layer.8/attention/self/query/Add_output_0_max:0"
output: "/encoder/layer.8/attention/self/query/Add_output_0:0"
name: "/encoder/layer.8/attention/self/query/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04355912655591965
  zero_point: 129
  minval: -5.61912727355957
  maxval: 5.488450050354004
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/query/Add_output_0:0"
input: "/encoder/layer.8/attention/self/Reshape_2/shape:0"
input: "/encoder/layer.8/attention/self/query/Add_output_0:1"
input: "/encoder/layer.8/attention/self/query/Add_output_0:2"
output: "/encoder/layer.8/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.8/attention/self/Reshape_2"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04355912655591965
  zero_point: 129
  minval: -5.61912727355957
  maxval: 5.488450050354004
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/Reshape_2_output_0:0"
input: "/encoder/layer.8/attention/self/Transpose_1/shape:0"
input: "/encoder/layer.8/attention/self/Reshape_2_output_0_min:0"
input: "/encoder/layer.8/attention/self/Reshape_2_output_0_max:0"
output: "/encoder/layer.8/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.8/attention/self/Transpose_1"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04355912655591965
  zero_point: 129
  minval: -5.61912727355957
  maxval: 5.488450050354004
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1526"
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1526_min:0"
input: "onnx::MatMul_1526_max:0"
output: "/encoder/layer.8/attention/self/key/MatMul_output_0_matmul:0"
name: "/encoder/layer.8/attention/self/key/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0334072969853878
  zero_point: 127
  minval: -4.242726802825928
  maxval: 4.276134014129639
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.8/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.8/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.8/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.8/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.8/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0334072969853878
  zero_point: 127
  minval: -4.242726802825928
  maxval: 4.276134014129639
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.8.attention.self.key.bias:0"
input: "/encoder/layer.8/attention/self/key/MatMul_output_0:0"
input: "encoder.layer.8.attention.self.key.bias_min:0"
input: "encoder.layer.8.attention.self.key.bias_max:0"
input: "/encoder/layer.8/attention/self/key/MatMul_output_0:1"
input: "/encoder/layer.8/attention/self/key/MatMul_output_0:2"
input: "/encoder/layer.8/attention/self/key/Add_output_0_min:0"
input: "/encoder/layer.8/attention/self/key/Add_output_0_max:0"
output: "/encoder/layer.8/attention/self/key/Add_output_0:0"
name: "/encoder/layer.8/attention/self/key/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03330055624246597
  zero_point: 126
  minval: -4.1958699226379395
  maxval: 4.295771598815918
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/key/Add_output_0:0"
input: "/encoder/layer.8/attention/self/Reshape/shape:0"
input: "/encoder/layer.8/attention/self/key/Add_output_0:1"
input: "/encoder/layer.8/attention/self/key/Add_output_0:2"
output: "/encoder/layer.8/attention/self/Reshape_output_0:0"
name: "/encoder/layer.8/attention/self/Reshape"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03330055624246597
  zero_point: 126
  minval: -4.1958699226379395
  maxval: 4.295771598815918
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/Reshape_output_0:0"
input: "/encoder/layer.8/attention/self/Transpose_2/shape:0"
input: "/encoder/layer.8/attention/self/Reshape_output_0_min:0"
input: "/encoder/layer.8/attention/self/Reshape_output_0_max:0"
output: "/encoder/layer.8/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.8/attention/self/Transpose_2"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03330055624246597
  zero_point: 126
  minval: -4.1958699226379395
  maxval: 4.295771598815918
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.8/attention/self/Transpose_2_output_0:0"
input: "/encoder/layer.8/attention/self/Transpose_1_output_0:1"
input: "/encoder/layer.8/attention/self/Transpose_1_output_0:2"
input: "/encoder/layer.8/attention/self/Transpose_2_output_0:1"
input: "/encoder/layer.8/attention/self/Transpose_2_output_0:2"
output: "/encoder/layer.8/attention/self/MatMul_output_0_batchmatmul:0"
name: "/encoder/layer.8/attention/self/MatMul_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.34134015440940857
  zero_point: 67
  minval: -22.86979103088379
  maxval: 64.17195129394531
}
padding: 0
out_max_byte_size: 1728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.8/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.8/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.8/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.8/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.8/attention/self/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.34134015440940857
  zero_point: 67
  minval: -22.86979103088379
  maxval: 64.17195129394531
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/MatMul_output_0:0"
input: "/encoder/layer.8/attention/self/Div/b:0"
input: "/encoder/layer.8/attention/self/MatMul_output_0:1"
input: "/encoder/layer.8/attention/self/MatMul_output_0:2"
input: "/encoder/layer.8/attention/self/Div/b_min:0"
input: "/encoder/layer.8/attention/self/Div/b_max:0"
input: "/encoder/layer.8/attention/self/Div_output_0_min:0"
input: "/encoder/layer.8/attention/self/Div_output_0_max:0"
output: "/encoder/layer.8/attention/self/Div_output_0:0"
name: "/encoder/layer.8/attention/self/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.04266752302646637
  zero_point: 67
  minval: -2.8587238788604736
  maxval: 8.021493911743164
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/Div_output_0:0"
input: "/Mul_output_0:0"
input: "/encoder/layer.8/attention/self/Div_output_0:1"
input: "/encoder/layer.8/attention/self/Div_output_0:2"
input: "/Mul_output_0:1"
input: "/Mul_output_0:2"
input: "/encoder/layer.8/attention/self/Add_output_0_min:0"
input: "/encoder/layer.8/attention/self/Add_output_0_max:0"
output: "/encoder/layer.8/attention/self/Add_output_0:0"
name: "/encoder/layer.8/attention/self/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/Add_output_0:0"
input: "/encoder/layer.8/attention/self/Add_output_0:1"
input: "/encoder/layer.8/attention/self/Add_output_0:2"
output: "/encoder/layer.8/attention/self/Softmax_output_0:0"
name: "/encoder/layer.8/attention/self/Softmax"
type: "QuantizedSoftmax_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1532"
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1532_min:0"
input: "onnx::MatMul_1532_max:0"
output: "/encoder/layer.8/attention/self/value/MatMul_output_0_matmul:0"
name: "/encoder/layer.8/attention/self/value/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02117350324988365
  zero_point: 125
  minval: -2.6466879844665527
  maxval: 2.7525556087493896
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.8/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.8/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.8/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.8/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.8/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.8/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02117350324988365
  zero_point: 125
  minval: -2.6466879844665527
  maxval: 2.7525556087493896
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.8.attention.self.value.bias:0"
input: "/encoder/layer.8/attention/self/value/MatMul_output_0:0"
input: "encoder.layer.8.attention.self.value.bias_min:0"
input: "encoder.layer.8.attention.self.value.bias_max:0"
input: "/encoder/layer.8/attention/self/value/MatMul_output_0:1"
input: "/encoder/layer.8/attention/self/value/MatMul_output_0:2"
input: "/encoder/layer.8/attention/self/value/Add_output_0_min:0"
input: "/encoder/layer.8/attention/self/value/Add_output_0_max:0"
output: "/encoder/layer.8/attention/self/value/Add_output_0:0"
name: "/encoder/layer.8/attention/self/value/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02119789645075798
  zero_point: 125
  minval: -2.6497368812561035
  maxval: 2.7557265758514404
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/value/Add_output_0:0"
input: "/encoder/layer.8/attention/self/Reshape_1/shape:0"
input: "/encoder/layer.8/attention/self/value/Add_output_0:1"
input: "/encoder/layer.8/attention/self/value/Add_output_0:2"
output: "/encoder/layer.8/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.8/attention/self/Reshape_1"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02119789645075798
  zero_point: 125
  minval: -2.6497368812561035
  maxval: 2.7557265758514404
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/Reshape_1_output_0:0"
input: "/encoder/layer.8/attention/self/Transpose/shape:0"
input: "/encoder/layer.8/attention/self/Reshape_1_output_0_min:0"
input: "/encoder/layer.8/attention/self/Reshape_1_output_0_max:0"
output: "/encoder/layer.8/attention/self/Transpose_output_0:0"
name: "/encoder/layer.8/attention/self/Transpose"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02119789645075798
  zero_point: 125
  minval: -2.6497368812561035
  maxval: 2.7557265758514404
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/Softmax_output_0:0"
input: "/encoder/layer.8/attention/self/Transpose_output_0:0"
input: "/encoder/layer.8/attention/self/Softmax_output_0:1"
input: "/encoder/layer.8/attention/self/Softmax_output_0:2"
input: "/encoder/layer.8/attention/self/Transpose_output_0:1"
input: "/encoder/layer.8/attention/self/Transpose_output_0:2"
output: "/encoder/layer.8/attention/self/MatMul_1_output_0_batchmatmul:0"
name: "/encoder/layer.8/attention/self/MatMul_1_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.011665240861475468
  zero_point: 143
  minval: -1.6681294441223145
  maxval: 1.3065069913864136
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.8/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.8/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.8/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.8/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.8/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.8/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.011665240861475468
  zero_point: 143
  minval: -1.6681294441223145
  maxval: 1.3065069913864136
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/MatMul_1_output_0:0"
input: "/encoder/layer.8/attention/self/Transpose_3/shape:0"
input: "/encoder/layer.8/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.8/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.8/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.8/attention/self/Transpose_3"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.011665240861475468
  zero_point: 143
  minval: -1.6681294441223145
  maxval: 1.3065069913864136
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/Transpose_3_output_0:0"
input: "/encoder/layer.8/attention/self/Reshape_3/shape:0"
input: "/encoder/layer.8/attention/self/Transpose_3_output_0:1"
input: "/encoder/layer.8/attention/self/Transpose_3_output_0:2"
output: "/encoder/layer.8/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.8/attention/self/Reshape_3"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.011665240861475468
  zero_point: 143
  minval: -1.6681294441223145
  maxval: 1.3065069913864136
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1547"
input: "/encoder/layer.8/attention/self/Reshape_3_output_0:1"
input: "/encoder/layer.8/attention/self/Reshape_3_output_0:2"
input: "onnx::MatMul_1547_min:0"
input: "onnx::MatMul_1547_max:0"
output: "/encoder/layer.8/attention/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.8/attention/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01757514476776123
  zero_point: 173
  minval: -3.0404999256134033
  maxval: 1.441161870956421
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.8/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.8/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.8/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.8/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.8/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.8/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01757514476776123
  zero_point: 173
  minval: -3.0404999256134033
  maxval: 1.441161870956421
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.8.attention.output.dense.bias:0"
input: "/encoder/layer.8/attention/output/dense/MatMul_output_0:0"
input: "encoder.layer.8.attention.output.dense.bias_min:0"
input: "encoder.layer.8.attention.output.dense.bias_max:0"
input: "/encoder/layer.8/attention/output/dense/MatMul_output_0:1"
input: "/encoder/layer.8/attention/output/dense/MatMul_output_0:2"
input: "/encoder/layer.8/attention/output/dense/Add_output_0_min:0"
input: "/encoder/layer.8/attention/output/dense/Add_output_0_max:0"
output: "/encoder/layer.8/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.8/attention/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01261430885642767
  zero_point: 145
  minval: -1.8290748596191406
  maxval: 1.3875739574432373
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/output/dense/Add_output_0:0"
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.8/attention/output/dense/Add_output_0:1"
input: "/encoder/layer.8/attention/output/dense/Add_output_0:2"
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.7/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.8/attention/output/Add_output_0_min:0"
input: "/encoder/layer.8/attention/output/Add_output_0_max:0"
output: "/encoder/layer.8/attention/output/Add_output_0:0"
name: "/encoder/layer.8/attention/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0788085088133812
  zero_point: 219
  minval: -17.259063720703125
  maxval: 2.837106466293335
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/output/Add_output_0:0"
input: "/encoder/layer.8/attention/output/Add_output_0:1"
input: "/encoder/layer.8/attention/output/Add_output_0:2"
input: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.00014143137377686799
  zero_point: 255
  minval: -0.0360650010406971
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/output/Add_output_0:0"
input: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.8/attention/output/Add_output_0:1"
input: "/encoder/layer.8/attention/output/Add_output_0:2"
input: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.8/attention/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.8/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07900568097829819
  zero_point: 218
  minval: -17.223237991333008
  maxval: 2.9232101440429688
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.8/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.8/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.8/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.8/attention/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.8/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 1.1632938385009766
  zero_point: 0
  minval: 0.0
  maxval: 296.6399230957031
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.8/attention/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003563070669770241
  zero_point: 0
  minval: 0.0
  maxval: 0.9085829854011536
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Add/b:0"
input: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.8/attention/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.8/attention/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.8/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003563070669770241
  zero_point: 0
  minval: 0.0
  maxval: 0.9085829854011536
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.8/attention/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.8/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0037380235735327005
  zero_point: 0
  minval: 0.0
  maxval: 0.9531959891319275
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.8/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.8/attention/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.8/attention/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.8/attention/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.8/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0832669585943222
  zero_point: 217
  minval: -18.06892967224121
  maxval: 3.164144515991211
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.8.attention.output.LayerNorm.weight:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.8/attention/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.8.attention.output.LayerNorm.weight_min:0"
input: "encoder.layer.8.attention.output.LayerNorm.weight_max:0"
output: "/encoder/layer.8/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2278434932231903
  zero_point: 245
  minval: -55.8216552734375
  maxval: 2.278434991836548
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.8.attention.output.LayerNorm.bias:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.8/attention/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.8.attention.output.LayerNorm.bias_min:0"
input: "encoder.layer.8.attention.output.LayerNorm.bias_max:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.8/attention/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.23593111336231232
  zero_point: 244
  minval: -57.56719207763672
  maxval: 2.5952422618865967
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1548"
input: "/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1548_min:0"
input: "onnx::MatMul_1548_max:0"
output: "/encoder/layer.8/intermediate/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.8/intermediate/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.08149689435958862
  zero_point: 213
  minval: -17.35883903503418
  maxval: 3.4228696823120117
}
padding: 0
out_max_byte_size: 73728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.8/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.8/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.8/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.8/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.8/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.8/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.08149689435958862
  zero_point: 213
  minval: -17.35883903503418
  maxval: 3.4228696823120117
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/intermediate/dense/MatMul_output_0:0"
input: "/encoder/layer.8/intermediate/dense/MatMul_output_0:1"
input: "/encoder/layer.8/intermediate/dense/MatMul_output_0:2"
output: "/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1"
type: "QuantizedGelu_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.013834809884428978
  zero_point: 13
  minval: -0.17985253036022186
  maxval: 3.3480238914489746
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1549"
input: "/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1_output_0:1"
input: "/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1_output_0:2"
input: "onnx::MatMul_1549_min:0"
input: "onnx::MatMul_1549_max:0"
output: "/encoder/layer.8/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.8/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.022208763286471367
  zero_point: 61
  minval: -1.3547345399856567
  maxval: 4.308499813079834
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.8/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.8/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.8/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.8/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.8/output/dense/MatMul_output_0:0"
name: "/encoder/layer.8/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.022208763286471367
  zero_point: 61
  minval: -1.3547345399856567
  maxval: 4.308499813079834
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.8.output.dense.bias:0"
input: "/encoder/layer.8/output/dense/MatMul_output_0:0"
input: "encoder.layer.8.output.dense.bias_min:0"
input: "encoder.layer.8.output.dense.bias_max:0"
input: "/encoder/layer.8/output/dense/MatMul_output_0:1"
input: "/encoder/layer.8/output/dense/MatMul_output_0:2"
input: "/encoder/layer.8/output/dense/Add_output_0_min:0"
input: "/encoder/layer.8/output/dense/Add_output_0_max:0"
output: "/encoder/layer.8/output/dense/Add_output_0:0"
name: "/encoder/layer.8/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.019233081489801407
  zero_point: 69
  minval: -1.3270825147628784
  maxval: 3.577353000640869
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/output/dense/Add_output_0:0"
input: "/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.8/output/dense/Add_output_0:1"
input: "/encoder/layer.8/output/dense/Add_output_0:2"
input: "/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.8/output/Add_output_0_min:0"
input: "/encoder/layer.8/output/Add_output_0_max:0"
output: "/encoder/layer.8/output/Add_output_0:0"
name: "/encoder/layer.8/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.2258034199476242
  zero_point: 243
  minval: -54.87023162841797
  maxval: 2.7096409797668457
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/output/Add_output_0:0"
input: "/encoder/layer.8/output/Add_output_0:1"
input: "/encoder/layer.8/output/Add_output_0:2"
input: "/encoder/layer.8/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.8/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.8/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.8/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0003142000059597194
  zero_point: 255
  minval: -0.0801210030913353
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/output/Add_output_0:0"
input: "/encoder/layer.8/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.8/output/Add_output_0:1"
input: "/encoder/layer.8/output/Add_output_0:2"
input: "/encoder/layer.8/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.8/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.8/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.8/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.8/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.22476567327976227
  zero_point: 243
  minval: -54.61805725097656
  maxval: 2.697187900543213
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.8/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.8/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.8/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.8/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.8/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.8/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.8/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.8/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 11.698556900024414
  zero_point: 0
  minval: 0.0
  maxval: 2983.132080078125
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.8/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.8/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.8/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.8/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.8/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.8/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01716194860637188
  zero_point: 0
  minval: 0.0
  maxval: 4.3762969970703125
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.8/output/LayerNorm/Add/b:0"
input: "/encoder/layer.8/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.8/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.8/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.8/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.8/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.8/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.8/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01716194860637188
  zero_point: 0
  minval: 0.0
  maxval: 4.3762969970703125
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.8/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.8/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.8/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.008203764446079731
  zero_point: 0
  minval: 0.0
  maxval: 2.0919599533081055
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.8/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.8/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.8/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.8/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.8/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.8/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.8/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.8/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.1135154590010643
  zero_point: 230
  minval: -26.10855484008789
  maxval: 2.837886333465576
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.8.output.LayerNorm.weight:0"
input: "/encoder/layer.8/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.8/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.8.output.LayerNorm.weight_min:0"
input: "encoder.layer.8.output.LayerNorm.weight_max:0"
output: "/encoder/layer.8/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07404923439025879
  zero_point: 223
  minval: -16.51297950744629
  maxval: 2.3695755004882812
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.8.output.LayerNorm.bias:0"
input: "/encoder/layer.8/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.8/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.8.output.LayerNorm.bias_min:0"
input: "encoder.layer.8.output.LayerNorm.bias_max:0"
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.8/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0734701156616211
  zero_point: 223
  minval: -16.383834838867188
  maxval: 2.351043701171875
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1550"
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1550_min:0"
input: "onnx::MatMul_1550_max:0"
output: "/encoder/layer.9/attention/self/query/MatMul_output_0_matmul:0"
name: "/encoder/layer.9/attention/self/query/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.040860384702682495
  zero_point: 135
  minval: -5.5161519050598145
  maxval: 4.90324592590332
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.9/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.9/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.9/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.9/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.9/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.040860384702682495
  zero_point: 135
  minval: -5.5161519050598145
  maxval: 4.90324592590332
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.9.attention.self.query.bias:0"
input: "/encoder/layer.9/attention/self/query/MatMul_output_0:0"
input: "encoder.layer.9.attention.self.query.bias_min:0"
input: "encoder.layer.9.attention.self.query.bias_max:0"
input: "/encoder/layer.9/attention/self/query/MatMul_output_0:1"
input: "/encoder/layer.9/attention/self/query/MatMul_output_0:2"
input: "/encoder/layer.9/attention/self/query/Add_output_0_min:0"
input: "/encoder/layer.9/attention/self/query/Add_output_0_max:0"
output: "/encoder/layer.9/attention/self/query/Add_output_0:0"
name: "/encoder/layer.9/attention/self/query/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.045451246201992035
  zero_point: 138
  minval: -6.272272109985352
  maxval: 5.317796230316162
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/query/Add_output_0:0"
input: "/encoder/layer.9/attention/self/Reshape_2/shape:0"
input: "/encoder/layer.9/attention/self/query/Add_output_0:1"
input: "/encoder/layer.9/attention/self/query/Add_output_0:2"
output: "/encoder/layer.9/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.9/attention/self/Reshape_2"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.045451246201992035
  zero_point: 138
  minval: -6.272272109985352
  maxval: 5.317796230316162
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/Reshape_2_output_0:0"
input: "/encoder/layer.9/attention/self/Transpose_1/shape:0"
input: "/encoder/layer.9/attention/self/Reshape_2_output_0_min:0"
input: "/encoder/layer.9/attention/self/Reshape_2_output_0_max:0"
output: "/encoder/layer.9/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.9/attention/self/Transpose_1"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.045451246201992035
  zero_point: 138
  minval: -6.272272109985352
  maxval: 5.317796230316162
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1551"
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1551_min:0"
input: "onnx::MatMul_1551_max:0"
output: "/encoder/layer.9/attention/self/key/MatMul_output_0_matmul:0"
name: "/encoder/layer.9/attention/self/key/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03000347502529621
  zero_point: 131
  minval: -3.930455446243286
  maxval: 3.720431089401245
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.9/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.9/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.9/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.9/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.9/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03000347502529621
  zero_point: 131
  minval: -3.930455446243286
  maxval: 3.720431089401245
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.9.attention.self.key.bias:0"
input: "/encoder/layer.9/attention/self/key/MatMul_output_0:0"
input: "encoder.layer.9.attention.self.key.bias_min:0"
input: "encoder.layer.9.attention.self.key.bias_max:0"
input: "/encoder/layer.9/attention/self/key/MatMul_output_0:1"
input: "/encoder/layer.9/attention/self/key/MatMul_output_0:2"
input: "/encoder/layer.9/attention/self/key/Add_output_0_min:0"
input: "/encoder/layer.9/attention/self/key/Add_output_0_max:0"
output: "/encoder/layer.9/attention/self/key/Add_output_0:0"
name: "/encoder/layer.9/attention/self/key/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.029980653896927834
  zero_point: 130
  minval: -3.8974850177764893
  maxval: 3.747581720352173
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/key/Add_output_0:0"
input: "/encoder/layer.9/attention/self/Reshape/shape:0"
input: "/encoder/layer.9/attention/self/key/Add_output_0:1"
input: "/encoder/layer.9/attention/self/key/Add_output_0:2"
output: "/encoder/layer.9/attention/self/Reshape_output_0:0"
name: "/encoder/layer.9/attention/self/Reshape"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.029980653896927834
  zero_point: 130
  minval: -3.8974850177764893
  maxval: 3.747581720352173
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/Reshape_output_0:0"
input: "/encoder/layer.9/attention/self/Transpose_2/shape:0"
input: "/encoder/layer.9/attention/self/Reshape_output_0_min:0"
input: "/encoder/layer.9/attention/self/Reshape_output_0_max:0"
output: "/encoder/layer.9/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.9/attention/self/Transpose_2"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.029980653896927834
  zero_point: 130
  minval: -3.8974850177764893
  maxval: 3.747581720352173
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.9/attention/self/Transpose_2_output_0:0"
input: "/encoder/layer.9/attention/self/Transpose_1_output_0:1"
input: "/encoder/layer.9/attention/self/Transpose_1_output_0:2"
input: "/encoder/layer.9/attention/self/Transpose_2_output_0:1"
input: "/encoder/layer.9/attention/self/Transpose_2_output_0:2"
output: "/encoder/layer.9/attention/self/MatMul_output_0_batchmatmul:0"
name: "/encoder/layer.9/attention/self/MatMul_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.34506726264953613
  zero_point: 100
  minval: -34.5067253112793
  maxval: 53.48542404174805
}
padding: 0
out_max_byte_size: 1728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.9/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.9/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.9/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.9/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.9/attention/self/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.34506726264953613
  zero_point: 100
  minval: -34.5067253112793
  maxval: 53.48542404174805
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/MatMul_output_0:0"
input: "/encoder/layer.9/attention/self/Div/b:0"
input: "/encoder/layer.9/attention/self/MatMul_output_0:1"
input: "/encoder/layer.9/attention/self/MatMul_output_0:2"
input: "/encoder/layer.9/attention/self/Div/b_min:0"
input: "/encoder/layer.9/attention/self/Div/b_max:0"
input: "/encoder/layer.9/attention/self/Div_output_0_min:0"
input: "/encoder/layer.9/attention/self/Div_output_0_max:0"
output: "/encoder/layer.9/attention/self/Div_output_0:0"
name: "/encoder/layer.9/attention/self/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.043133411556482315
  zero_point: 100
  minval: -4.31334114074707
  maxval: 6.685678482055664
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/Div_output_0:0"
input: "/Mul_output_0:0"
input: "/encoder/layer.9/attention/self/Div_output_0:1"
input: "/encoder/layer.9/attention/self/Div_output_0:2"
input: "/Mul_output_0:1"
input: "/Mul_output_0:2"
input: "/encoder/layer.9/attention/self/Add_output_0_min:0"
input: "/encoder/layer.9/attention/self/Add_output_0_max:0"
output: "/encoder/layer.9/attention/self/Add_output_0:0"
name: "/encoder/layer.9/attention/self/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/Add_output_0:0"
input: "/encoder/layer.9/attention/self/Add_output_0:1"
input: "/encoder/layer.9/attention/self/Add_output_0:2"
output: "/encoder/layer.9/attention/self/Softmax_output_0:0"
name: "/encoder/layer.9/attention/self/Softmax"
type: "QuantizedSoftmax_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1557"
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1557_min:0"
input: "onnx::MatMul_1557_max:0"
output: "/encoder/layer.9/attention/self/value/MatMul_output_0_matmul:0"
name: "/encoder/layer.9/attention/self/value/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.022493071854114532
  zero_point: 110
  minval: -2.4742379188537598
  maxval: 3.261495590209961
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.9/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.9/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.9/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.9/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.9/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.9/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.022493071854114532
  zero_point: 110
  minval: -2.4742379188537598
  maxval: 3.261495590209961
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.9.attention.self.value.bias:0"
input: "/encoder/layer.9/attention/self/value/MatMul_output_0:0"
input: "encoder.layer.9.attention.self.value.bias_min:0"
input: "encoder.layer.9.attention.self.value.bias_max:0"
input: "/encoder/layer.9/attention/self/value/MatMul_output_0:1"
input: "/encoder/layer.9/attention/self/value/MatMul_output_0:2"
input: "/encoder/layer.9/attention/self/value/Add_output_0_min:0"
input: "/encoder/layer.9/attention/self/value/Add_output_0_max:0"
output: "/encoder/layer.9/attention/self/value/Add_output_0:0"
name: "/encoder/layer.9/attention/self/value/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.023025354370474815
  zero_point: 108
  minval: -2.4867382049560547
  maxval: 3.3847270011901855
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/value/Add_output_0:0"
input: "/encoder/layer.9/attention/self/Reshape_1/shape:0"
input: "/encoder/layer.9/attention/self/value/Add_output_0:1"
input: "/encoder/layer.9/attention/self/value/Add_output_0:2"
output: "/encoder/layer.9/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.9/attention/self/Reshape_1"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.023025354370474815
  zero_point: 108
  minval: -2.4867382049560547
  maxval: 3.3847270011901855
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/Reshape_1_output_0:0"
input: "/encoder/layer.9/attention/self/Transpose/shape:0"
input: "/encoder/layer.9/attention/self/Reshape_1_output_0_min:0"
input: "/encoder/layer.9/attention/self/Reshape_1_output_0_max:0"
output: "/encoder/layer.9/attention/self/Transpose_output_0:0"
name: "/encoder/layer.9/attention/self/Transpose"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.023025354370474815
  zero_point: 108
  minval: -2.4867382049560547
  maxval: 3.3847270011901855
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/Softmax_output_0:0"
input: "/encoder/layer.9/attention/self/Transpose_output_0:0"
input: "/encoder/layer.9/attention/self/Softmax_output_0:1"
input: "/encoder/layer.9/attention/self/Softmax_output_0:2"
input: "/encoder/layer.9/attention/self/Transpose_output_0:1"
input: "/encoder/layer.9/attention/self/Transpose_output_0:2"
output: "/encoder/layer.9/attention/self/MatMul_1_output_0_batchmatmul:0"
name: "/encoder/layer.9/attention/self/MatMul_1_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01358900684863329
  zero_point: 106
  minval: -1.4404346942901611
  maxval: 2.024761915206909
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.9/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.9/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.9/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.9/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.9/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.9/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01358900684863329
  zero_point: 106
  minval: -1.4404346942901611
  maxval: 2.024761915206909
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/MatMul_1_output_0:0"
input: "/encoder/layer.9/attention/self/Transpose_3/shape:0"
input: "/encoder/layer.9/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.9/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.9/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.9/attention/self/Transpose_3"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01358900684863329
  zero_point: 106
  minval: -1.4404346942901611
  maxval: 2.024761915206909
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/Transpose_3_output_0:0"
input: "/encoder/layer.9/attention/self/Reshape_3/shape:0"
input: "/encoder/layer.9/attention/self/Transpose_3_output_0:1"
input: "/encoder/layer.9/attention/self/Transpose_3_output_0:2"
output: "/encoder/layer.9/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.9/attention/self/Reshape_3"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01358900684863329
  zero_point: 106
  minval: -1.4404346942901611
  maxval: 2.024761915206909
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1572"
input: "/encoder/layer.9/attention/self/Reshape_3_output_0:1"
input: "/encoder/layer.9/attention/self/Reshape_3_output_0:2"
input: "onnx::MatMul_1572_min:0"
input: "onnx::MatMul_1572_max:0"
output: "/encoder/layer.9/attention/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.9/attention/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010727767832577229
  zero_point: 125
  minval: -1.3409709930419922
  maxval: 1.394609808921814
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.9/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.9/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.9/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.9/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.9/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.9/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010727767832577229
  zero_point: 125
  minval: -1.3409709930419922
  maxval: 1.394609808921814
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.9.attention.output.dense.bias:0"
input: "/encoder/layer.9/attention/output/dense/MatMul_output_0:0"
input: "encoder.layer.9.attention.output.dense.bias_min:0"
input: "encoder.layer.9.attention.output.dense.bias_max:0"
input: "/encoder/layer.9/attention/output/dense/MatMul_output_0:1"
input: "/encoder/layer.9/attention/output/dense/MatMul_output_0:2"
input: "/encoder/layer.9/attention/output/dense/Add_output_0_min:0"
input: "/encoder/layer.9/attention/output/dense/Add_output_0_max:0"
output: "/encoder/layer.9/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.9/attention/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010656259953975677
  zero_point: 128
  minval: -1.3640012741088867
  maxval: 1.3533450365066528
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/output/dense/Add_output_0:0"
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.9/attention/output/dense/Add_output_0:1"
input: "/encoder/layer.9/attention/output/dense/Add_output_0:2"
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.8/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.9/attention/output/Add_output_0_min:0"
input: "/encoder/layer.9/attention/output/Add_output_0_max:0"
output: "/encoder/layer.9/attention/output/Add_output_0:0"
name: "/encoder/layer.9/attention/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07457316666841507
  zero_point: 214
  minval: -15.958657264709473
  maxval: 3.057499647140503
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/output/Add_output_0:0"
input: "/encoder/layer.9/attention/output/Add_output_0:1"
input: "/encoder/layer.9/attention/output/Add_output_0:2"
input: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0001346705830655992
  zero_point: 255
  minval: -0.034341000020504
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/output/Add_output_0:0"
input: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.9/attention/output/Add_output_0:1"
input: "/encoder/layer.9/attention/output/Add_output_0:2"
input: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.9/attention/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.9/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07447197288274765
  zero_point: 214
  minval: -15.937003135681152
  maxval: 3.0533509254455566
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.9/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.9/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.9/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.9/attention/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.9/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.9944464564323425
  zero_point: 0
  minval: 0.0
  maxval: 253.58384704589844
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.9/attention/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003626580350100994
  zero_point: 0
  minval: 0.0
  maxval: 0.9247779846191406
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Add/b:0"
input: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.9/attention/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.9/attention/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.9/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003626580350100994
  zero_point: 0
  minval: 0.0
  maxval: 0.9247779846191406
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.9/attention/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.9/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0037711921613663435
  zero_point: 0
  minval: 0.0
  maxval: 0.961654007434845
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.9/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.9/attention/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.9/attention/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.9/attention/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.9/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07781985402107239
  zero_point: 213
  minval: -16.57563018798828
  maxval: 3.2684340476989746
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.9.attention.output.LayerNorm.weight:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.9/attention/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.9.attention.output.LayerNorm.weight_min:0"
input: "encoder.layer.9.attention.output.LayerNorm.weight_max:0"
output: "/encoder/layer.9/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.12420880794525146
  zero_point: 234
  minval: -29.064861297607422
  maxval: 2.608384847640991
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.9.attention.output.LayerNorm.bias:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.9/attention/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.9.attention.output.LayerNorm.bias_min:0"
input: "encoder.layer.9.attention.output.LayerNorm.bias_max:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.9/attention/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.1305486261844635
  zero_point: 234
  minval: -30.54837989807129
  maxval: 2.7415213584899902
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1573"
input: "/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1573_min:0"
input: "onnx::MatMul_1573_max:0"
output: "/encoder/layer.9/intermediate/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.9/intermediate/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07669970393180847
  zero_point: 218
  minval: -16.720535278320312
  maxval: 2.8378889560699463
}
padding: 0
out_max_byte_size: 73728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.9/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.9/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.9/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.9/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.9/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.9/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07669970393180847
  zero_point: 218
  minval: -16.720535278320312
  maxval: 2.8378889560699463
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/intermediate/dense/MatMul_output_0:0"
input: "/encoder/layer.9/intermediate/dense/MatMul_output_0:1"
input: "/encoder/layer.9/intermediate/dense/MatMul_output_0:2"
output: "/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1"
type: "QuantizedGelu_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010867472738027573
  zero_point: 16
  minval: -0.17387956380844116
  maxval: 2.5973260402679443
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1574"
input: "/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1_output_0:1"
input: "/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1_output_0:2"
input: "onnx::MatMul_1574_min:0"
input: "onnx::MatMul_1574_max:0"
output: "/encoder/layer.9/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.9/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.10220877826213837
  zero_point: 155
  minval: -15.842361450195312
  maxval: 10.220877647399902
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.9/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.9/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.9/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.9/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.9/output/dense/MatMul_output_0:0"
name: "/encoder/layer.9/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.10220877826213837
  zero_point: 155
  minval: -15.842361450195312
  maxval: 10.220877647399902
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.9.output.dense.bias:0"
input: "/encoder/layer.9/output/dense/MatMul_output_0:0"
input: "encoder.layer.9.output.dense.bias_min:0"
input: "encoder.layer.9.output.dense.bias_max:0"
input: "/encoder/layer.9/output/dense/MatMul_output_0:1"
input: "/encoder/layer.9/output/dense/MatMul_output_0:2"
input: "/encoder/layer.9/output/dense/Add_output_0_min:0"
input: "/encoder/layer.9/output/dense/Add_output_0_max:0"
output: "/encoder/layer.9/output/dense/Add_output_0:0"
name: "/encoder/layer.9/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.1061997264623642
  zero_point: 156
  minval: -16.567157745361328
  maxval: 10.513772964477539
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/output/dense/Add_output_0:0"
input: "/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.9/output/dense/Add_output_0:1"
input: "/encoder/layer.9/output/dense/Add_output_0:2"
input: "/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.9/output/Add_output_0_min:0"
input: "/encoder/layer.9/output/Add_output_0_max:0"
output: "/encoder/layer.9/output/Add_output_0:0"
name: "/encoder/layer.9/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.1955433040857315
  zero_point: 191
  minval: -37.34877014160156
  maxval: 12.514771461486816
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/output/Add_output_0:0"
input: "/encoder/layer.9/output/Add_output_0:1"
input: "/encoder/layer.9/output/Add_output_0:2"
input: "/encoder/layer.9/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.9/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.9/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.9/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0003437490086071193
  zero_point: 255
  minval: -0.08765599876642227
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/output/Add_output_0:0"
input: "/encoder/layer.9/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.9/output/Add_output_0:1"
input: "/encoder/layer.9/output/Add_output_0:2"
input: "/encoder/layer.9/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.9/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.9/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.9/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.9/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.1950843632221222
  zero_point: 191
  minval: -37.261112213134766
  maxval: 12.48539924621582
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.9/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.9/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.9/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.9/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.9/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.9/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.9/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.9/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 5.444668769836426
  zero_point: 0
  minval: 0.0
  maxval: 1388.3905029296875
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.9/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.9/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.9/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.9/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.9/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.9/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.012891761027276516
  zero_point: 0
  minval: 0.0
  maxval: 3.2873990535736084
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.9/output/LayerNorm/Add/b:0"
input: "/encoder/layer.9/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.9/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.9/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.9/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.9/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.9/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.9/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.012891761027276516
  zero_point: 0
  minval: 0.0
  maxval: 3.2873990535736084
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.9/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.9/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.9/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007110270671546459
  zero_point: 0
  minval: 0.0
  maxval: 1.8131190538406372
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.9/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.9/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.9/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.9/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.9/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.9/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.9/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.9/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.1075960323214531
  zero_point: 191
  minval: -20.55084228515625
  maxval: 6.886146068572998
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.9.output.LayerNorm.weight:0"
input: "/encoder/layer.9/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.9/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.9.output.LayerNorm.weight_min:0"
input: "encoder.layer.9.output.LayerNorm.weight_max:0"
output: "/encoder/layer.9/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07400540262460709
  zero_point: 220
  minval: -16.28118896484375
  maxval: 2.590189218521118
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.9.output.LayerNorm.bias:0"
input: "/encoder/layer.9/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.9/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.9.output.LayerNorm.bias_min:0"
input: "encoder.layer.9.output.LayerNorm.bias_max:0"
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.9/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07520761340856552
  zero_point: 222
  minval: -16.696090698242188
  maxval: 2.48185133934021
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1575"
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1575_min:0"
input: "onnx::MatMul_1575_max:0"
output: "/encoder/layer.10/attention/self/query/MatMul_output_0_matmul:0"
name: "/encoder/layer.10/attention/self/query/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.035721272230148315
  zero_point: 147
  minval: -5.2510271072387695
  maxval: 3.8578972816467285
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.10/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.10/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.10/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.10/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.10/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.035721272230148315
  zero_point: 147
  minval: -5.2510271072387695
  maxval: 3.8578972816467285
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.10.attention.self.query.bias:0"
input: "/encoder/layer.10/attention/self/query/MatMul_output_0:0"
input: "encoder.layer.10.attention.self.query.bias_min:0"
input: "encoder.layer.10.attention.self.query.bias_max:0"
input: "/encoder/layer.10/attention/self/query/MatMul_output_0:1"
input: "/encoder/layer.10/attention/self/query/MatMul_output_0:2"
input: "/encoder/layer.10/attention/self/query/Add_output_0_min:0"
input: "/encoder/layer.10/attention/self/query/Add_output_0_max:0"
output: "/encoder/layer.10/attention/self/query/Add_output_0:0"
name: "/encoder/layer.10/attention/self/query/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03757181391119957
  zero_point: 147
  minval: -5.523056983947754
  maxval: 4.057755947113037
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/query/Add_output_0:0"
input: "/encoder/layer.10/attention/self/Reshape_2/shape:0"
input: "/encoder/layer.10/attention/self/query/Add_output_0:1"
input: "/encoder/layer.10/attention/self/query/Add_output_0:2"
output: "/encoder/layer.10/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.10/attention/self/Reshape_2"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03757181391119957
  zero_point: 147
  minval: -5.523056983947754
  maxval: 4.057755947113037
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/Reshape_2_output_0:0"
input: "/encoder/layer.10/attention/self/Transpose_1/shape:0"
input: "/encoder/layer.10/attention/self/Reshape_2_output_0_min:0"
input: "/encoder/layer.10/attention/self/Reshape_2_output_0_max:0"
output: "/encoder/layer.10/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.10/attention/self/Transpose_1"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03757181391119957
  zero_point: 147
  minval: -5.523056983947754
  maxval: 4.057755947113037
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1576"
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1576_min:0"
input: "onnx::MatMul_1576_max:0"
output: "/encoder/layer.10/attention/self/key/MatMul_output_0_matmul:0"
name: "/encoder/layer.10/attention/self/key/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03174690157175064
  zero_point: 120
  minval: -3.8096280097961426
  maxval: 4.285831451416016
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.10/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.10/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.10/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.10/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.10/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03174690157175064
  zero_point: 120
  minval: -3.8096280097961426
  maxval: 4.285831451416016
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.10.attention.self.key.bias:0"
input: "/encoder/layer.10/attention/self/key/MatMul_output_0:0"
input: "encoder.layer.10.attention.self.key.bias_min:0"
input: "encoder.layer.10.attention.self.key.bias_max:0"
input: "/encoder/layer.10/attention/self/key/MatMul_output_0:1"
input: "/encoder/layer.10/attention/self/key/MatMul_output_0:2"
input: "/encoder/layer.10/attention/self/key/Add_output_0_min:0"
input: "/encoder/layer.10/attention/self/key/Add_output_0_max:0"
output: "/encoder/layer.10/attention/self/key/Add_output_0:0"
name: "/encoder/layer.10/attention/self/key/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.031860560178756714
  zero_point: 120
  minval: -3.8232669830322266
  maxval: 4.301175594329834
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/key/Add_output_0:0"
input: "/encoder/layer.10/attention/self/Reshape/shape:0"
input: "/encoder/layer.10/attention/self/key/Add_output_0:1"
input: "/encoder/layer.10/attention/self/key/Add_output_0:2"
output: "/encoder/layer.10/attention/self/Reshape_output_0:0"
name: "/encoder/layer.10/attention/self/Reshape"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.031860560178756714
  zero_point: 120
  minval: -3.8232669830322266
  maxval: 4.301175594329834
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/Reshape_output_0:0"
input: "/encoder/layer.10/attention/self/Transpose_2/shape:0"
input: "/encoder/layer.10/attention/self/Reshape_output_0_min:0"
input: "/encoder/layer.10/attention/self/Reshape_output_0_max:0"
output: "/encoder/layer.10/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.10/attention/self/Transpose_2"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.031860560178756714
  zero_point: 120
  minval: -3.8232669830322266
  maxval: 4.301175594329834
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.10/attention/self/Transpose_2_output_0:0"
input: "/encoder/layer.10/attention/self/Transpose_1_output_0:1"
input: "/encoder/layer.10/attention/self/Transpose_1_output_0:2"
input: "/encoder/layer.10/attention/self/Transpose_2_output_0:1"
input: "/encoder/layer.10/attention/self/Transpose_2_output_0:2"
output: "/encoder/layer.10/attention/self/MatMul_output_0_batchmatmul:0"
name: "/encoder/layer.10/attention/self/MatMul_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.37985730171203613
  zero_point: 164
  minval: -62.29659652709961
  maxval: 34.567012786865234
}
padding: 0
out_max_byte_size: 1728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.10/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.10/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.10/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.10/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.10/attention/self/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.37985730171203613
  zero_point: 164
  minval: -62.29659652709961
  maxval: 34.567012786865234
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/MatMul_output_0:0"
input: "/encoder/layer.10/attention/self/Div/b:0"
input: "/encoder/layer.10/attention/self/MatMul_output_0:1"
input: "/encoder/layer.10/attention/self/MatMul_output_0:2"
input: "/encoder/layer.10/attention/self/Div/b_min:0"
input: "/encoder/layer.10/attention/self/Div/b_max:0"
input: "/encoder/layer.10/attention/self/Div_output_0_min:0"
input: "/encoder/layer.10/attention/self/Div_output_0_max:0"
output: "/encoder/layer.10/attention/self/Div_output_0:0"
name: "/encoder/layer.10/attention/self/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.047482166439294815
  zero_point: 164
  minval: -7.787075042724609
  maxval: 4.3208770751953125
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/Div_output_0:0"
input: "/Mul_output_0:0"
input: "/encoder/layer.10/attention/self/Div_output_0:1"
input: "/encoder/layer.10/attention/self/Div_output_0:2"
input: "/Mul_output_0:1"
input: "/Mul_output_0:2"
input: "/encoder/layer.10/attention/self/Add_output_0_min:0"
input: "/encoder/layer.10/attention/self/Add_output_0_max:0"
output: "/encoder/layer.10/attention/self/Add_output_0:0"
name: "/encoder/layer.10/attention/self/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/Add_output_0:0"
input: "/encoder/layer.10/attention/self/Add_output_0:1"
input: "/encoder/layer.10/attention/self/Add_output_0:2"
output: "/encoder/layer.10/attention/self/Softmax_output_0:0"
name: "/encoder/layer.10/attention/self/Softmax"
type: "QuantizedSoftmax_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1582"
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1582_min:0"
input: "onnx::MatMul_1582_max:0"
output: "/encoder/layer.10/attention/self/value/MatMul_output_0_matmul:0"
name: "/encoder/layer.10/attention/self/value/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018686113879084587
  zero_point: 140
  minval: -2.616055965423584
  maxval: 2.1489031314849854
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.10/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.10/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.10/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.10/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.10/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.10/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.018686113879084587
  zero_point: 140
  minval: -2.616055965423584
  maxval: 2.1489031314849854
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.10.attention.self.value.bias:0"
input: "/encoder/layer.10/attention/self/value/MatMul_output_0:0"
input: "encoder.layer.10.attention.self.value.bias_min:0"
input: "encoder.layer.10.attention.self.value.bias_max:0"
input: "/encoder/layer.10/attention/self/value/MatMul_output_0:1"
input: "/encoder/layer.10/attention/self/value/MatMul_output_0:2"
input: "/encoder/layer.10/attention/self/value/Add_output_0_min:0"
input: "/encoder/layer.10/attention/self/value/Add_output_0_max:0"
output: "/encoder/layer.10/attention/self/value/Add_output_0:0"
name: "/encoder/layer.10/attention/self/value/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01952427253127098
  zero_point: 136
  minval: -2.655301094055176
  maxval: 2.3233883380889893
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/value/Add_output_0:0"
input: "/encoder/layer.10/attention/self/Reshape_1/shape:0"
input: "/encoder/layer.10/attention/self/value/Add_output_0:1"
input: "/encoder/layer.10/attention/self/value/Add_output_0:2"
output: "/encoder/layer.10/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.10/attention/self/Reshape_1"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01952427253127098
  zero_point: 136
  minval: -2.655301094055176
  maxval: 2.3233883380889893
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/Reshape_1_output_0:0"
input: "/encoder/layer.10/attention/self/Transpose/shape:0"
input: "/encoder/layer.10/attention/self/Reshape_1_output_0_min:0"
input: "/encoder/layer.10/attention/self/Reshape_1_output_0_max:0"
output: "/encoder/layer.10/attention/self/Transpose_output_0:0"
name: "/encoder/layer.10/attention/self/Transpose"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01952427253127098
  zero_point: 136
  minval: -2.655301094055176
  maxval: 2.3233883380889893
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/Softmax_output_0:0"
input: "/encoder/layer.10/attention/self/Transpose_output_0:0"
input: "/encoder/layer.10/attention/self/Softmax_output_0:1"
input: "/encoder/layer.10/attention/self/Softmax_output_0:2"
input: "/encoder/layer.10/attention/self/Transpose_output_0:1"
input: "/encoder/layer.10/attention/self/Transpose_output_0:2"
output: "/encoder/layer.10/attention/self/MatMul_1_output_0_batchmatmul:0"
name: "/encoder/layer.10/attention/self/MatMul_1_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.013253866694867611
  zero_point: 120
  minval: -1.5904639959335327
  maxval: 1.7892719507217407
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.10/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.10/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.10/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.10/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.10/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.10/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.013253866694867611
  zero_point: 120
  minval: -1.5904639959335327
  maxval: 1.7892719507217407
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/MatMul_1_output_0:0"
input: "/encoder/layer.10/attention/self/Transpose_3/shape:0"
input: "/encoder/layer.10/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.10/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.10/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.10/attention/self/Transpose_3"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.013253866694867611
  zero_point: 120
  minval: -1.5904639959335327
  maxval: 1.7892719507217407
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/Transpose_3_output_0:0"
input: "/encoder/layer.10/attention/self/Reshape_3/shape:0"
input: "/encoder/layer.10/attention/self/Transpose_3_output_0:1"
input: "/encoder/layer.10/attention/self/Transpose_3_output_0:2"
output: "/encoder/layer.10/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.10/attention/self/Reshape_3"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.013253866694867611
  zero_point: 120
  minval: -1.5904639959335327
  maxval: 1.7892719507217407
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1597"
input: "/encoder/layer.10/attention/self/Reshape_3_output_0:1"
input: "/encoder/layer.10/attention/self/Reshape_3_output_0:2"
input: "onnx::MatMul_1597_min:0"
input: "onnx::MatMul_1597_max:0"
output: "/encoder/layer.10/attention/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.10/attention/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.011150236241519451
  zero_point: 127
  minval: -1.4160799980163574
  maxval: 1.4272302389144897
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.10/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.10/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.10/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.10/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.10/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.10/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.011150236241519451
  zero_point: 127
  minval: -1.4160799980163574
  maxval: 1.4272302389144897
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.10.attention.output.dense.bias:0"
input: "/encoder/layer.10/attention/output/dense/MatMul_output_0:0"
input: "encoder.layer.10.attention.output.dense.bias_min:0"
input: "encoder.layer.10.attention.output.dense.bias_max:0"
input: "/encoder/layer.10/attention/output/dense/MatMul_output_0:1"
input: "/encoder/layer.10/attention/output/dense/MatMul_output_0:2"
input: "/encoder/layer.10/attention/output/dense/Add_output_0_min:0"
input: "/encoder/layer.10/attention/output/dense/Add_output_0_max:0"
output: "/encoder/layer.10/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.10/attention/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.010908850468695164
  zero_point: 127
  minval: -1.385424017906189
  maxval: 1.396332859992981
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/output/dense/Add_output_0:0"
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.10/attention/output/dense/Add_output_0:1"
input: "/encoder/layer.10/attention/output/dense/Add_output_0:2"
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.9/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.10/attention/output/Add_output_0_min:0"
input: "/encoder/layer.10/attention/output/Add_output_0_max:0"
output: "/encoder/layer.10/attention/output/Add_output_0:0"
name: "/encoder/layer.10/attention/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07651827484369278
  zero_point: 215
  minval: -16.45142936706543
  maxval: 3.0607309341430664
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/output/Add_output_0:0"
input: "/encoder/layer.10/attention/output/Add_output_0:1"
input: "/encoder/layer.10/attention/output/Add_output_0:2"
input: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.00012767451698891819
  zero_point: 255
  minval: -0.03255699947476387
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/output/Add_output_0:0"
input: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.10/attention/output/Add_output_0:1"
input: "/encoder/layer.10/attention/output/Add_output_0:2"
input: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.10/attention/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.10/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07627394050359726
  zero_point: 215
  minval: -16.398897171020508
  maxval: 3.050957679748535
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.10/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.10/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.10/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.10/attention/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.10/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 1.0546032190322876
  zero_point: 0
  minval: 0.0
  maxval: 268.923828125
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.10/attention/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.004220109898597002
  zero_point: 0
  minval: 0.0
  maxval: 1.0761280059814453
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Add/b:0"
input: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.10/attention/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.10/attention/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.10/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.004220109898597002
  zero_point: 0
  minval: 0.0
  maxval: 1.0761280059814453
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.10/attention/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.10/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0040681017562747
  zero_point: 0
  minval: 0.0
  maxval: 1.0373660326004028
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.10/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.10/attention/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.10/attention/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.10/attention/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.10/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07421695441007614
  zero_point: 213
  minval: -15.808212280273438
  maxval: 3.117112159729004
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.10.attention.output.LayerNorm.weight:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.10/attention/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.10.attention.output.LayerNorm.weight_min:0"
input: "encoder.layer.10.attention.output.LayerNorm.weight_max:0"
output: "/encoder/layer.10/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.12244266271591187
  zero_point: 224
  minval: -27.427156448364258
  maxval: 3.795722484588623
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.10.attention.output.LayerNorm.bias:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.10/attention/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.10.attention.output.LayerNorm.bias_min:0"
input: "encoder.layer.10.attention.output.LayerNorm.bias_max:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.10/attention/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.13265176117420197
  zero_point: 221
  minval: -29.3160400390625
  maxval: 4.510159969329834
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1598"
input: "/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1598_min:0"
input: "onnx::MatMul_1598_max:0"
output: "/encoder/layer.10/intermediate/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.10/intermediate/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.14899571239948273
  zero_point: 63
  minval: -9.38672924041748
  maxval: 28.607175827026367
}
padding: 0
out_max_byte_size: 73728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.10/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.10/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.10/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.10/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.10/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.10/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.14899571239948273
  zero_point: 63
  minval: -9.38672924041748
  maxval: 28.607175827026367
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/intermediate/dense/MatMul_output_0:0"
input: "/encoder/layer.10/intermediate/dense/MatMul_output_0:1"
input: "/encoder/layer.10/intermediate/dense/MatMul_output_0:2"
output: "/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1"
type: "QuantizedGelu_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.11296462267637253
  zero_point: 2
  minval: -0.22592924535274506
  maxval: 28.580049514770508
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1599"
input: "/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1_output_0:1"
input: "/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1_output_0:2"
input: "onnx::MatMul_1599_min:0"
input: "onnx::MatMul_1599_max:0"
output: "/encoder/layer.10/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.10/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.8073998093605042
  zero_point: 248
  minval: -200.2351531982422
  maxval: 5.651798725128174
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.10/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.10/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.10/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.10/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.10/output/dense/MatMul_output_0:0"
name: "/encoder/layer.10/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.8073998093605042
  zero_point: 248
  minval: -200.2351531982422
  maxval: 5.651798725128174
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.10.output.dense.bias:0"
input: "/encoder/layer.10/output/dense/MatMul_output_0:0"
input: "encoder.layer.10.output.dense.bias_min:0"
input: "encoder.layer.10.output.dense.bias_max:0"
input: "/encoder/layer.10/output/dense/MatMul_output_0:1"
input: "/encoder/layer.10/output/dense/MatMul_output_0:2"
input: "/encoder/layer.10/output/dense/Add_output_0_min:0"
input: "/encoder/layer.10/output/dense/Add_output_0_max:0"
output: "/encoder/layer.10/output/dense/Add_output_0:0"
name: "/encoder/layer.10/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.8121053576469421
  zero_point: 248
  minval: -201.40213012695312
  maxval: 5.684737682342529
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/output/dense/Add_output_0:0"
input: "/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.10/output/dense/Add_output_0:1"
input: "/encoder/layer.10/output/dense/Add_output_0:2"
input: "/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.10/output/Add_output_0_min:0"
input: "/encoder/layer.10/output/Add_output_0_max:0"
output: "/encoder/layer.10/output/Add_output_0:0"
name: "/encoder/layer.10/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.8471226096153259
  zero_point: 243
  minval: -205.85079956054688
  maxval: 10.165472030639648
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/output/Add_output_0:0"
input: "/encoder/layer.10/output/Add_output_0:1"
input: "/encoder/layer.10/output/Add_output_0:2"
input: "/encoder/layer.10/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.10/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.10/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.10/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0014954509679228067
  zero_point: 255
  minval: -0.38133999705314636
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/output/Add_output_0:0"
input: "/encoder/layer.10/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.10/output/Add_output_0:1"
input: "/encoder/layer.10/output/Add_output_0:2"
input: "/encoder/layer.10/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.10/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.10/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.10/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.10/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.8455533385276794
  zero_point: 243
  minval: -205.46946716308594
  maxval: 10.14664077758789
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.10/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.10/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.10/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.10/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.10/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.10/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.10/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.10/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 165.5596160888672
  zero_point: 0
  minval: 0.0
  maxval: 42217.703125
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.10/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.10/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.10/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.10/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.10/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.10/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.24165654182434082
  zero_point: 0
  minval: 0.0
  maxval: 61.62241744995117
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.10/output/LayerNorm/Add/b:0"
input: "/encoder/layer.10/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.10/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.10/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.10/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.10/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.10/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.10/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.24165654182434082
  zero_point: 0
  minval: 0.0
  maxval: 61.62241744995117
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.10/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.10/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.10/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.03078429400920868
  zero_point: 0
  minval: 0.0
  maxval: 7.849995136260986
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.10/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.10/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.10/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.10/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.10/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.10/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.10/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.10/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.11429900676012039
  zero_point: 229
  minval: -26.17447280883789
  maxval: 2.9717743396759033
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.10.output.LayerNorm.weight:0"
input: "/encoder/layer.10/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.10/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.10.output.LayerNorm.weight_min:0"
input: "encoder.layer.10.output.LayerNorm.weight_max:0"
output: "/encoder/layer.10/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07190462201833725
  zero_point: 222
  minval: -15.962825775146484
  maxval: 2.3728525638580322
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.10.output.LayerNorm.bias:0"
input: "/encoder/layer.10/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.10/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.10.output.LayerNorm.bias_min:0"
input: "encoder.layer.10.output.LayerNorm.bias_max:0"
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.10/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07423636317253113
  zero_point: 224
  minval: -16.62894630432129
  maxval: 2.3013274669647217
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1600"
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1600_min:0"
input: "onnx::MatMul_1600_max:0"
output: "/encoder/layer.11/attention/self/query/MatMul_output_0_matmul:0"
name: "/encoder/layer.11/attention/self/query/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.027746092528104782
  zero_point: 131
  minval: -3.634737968444824
  maxval: 3.4405152797698975
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/query/MatMul_output_0_matmul:0"
input: "/encoder/layer.11/attention/self/query/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.11/attention/self/query/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.11/attention/self/query/MatMul_output_0_min:0"
input: "/encoder/layer.11/attention/self/query/MatMul_output_0_max:0"
output: "/encoder/layer.11/attention/self/query/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/query/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.027746092528104782
  zero_point: 131
  minval: -3.634737968444824
  maxval: 3.4405152797698975
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.11.attention.self.query.bias:0"
input: "/encoder/layer.11/attention/self/query/MatMul_output_0:0"
input: "encoder.layer.11.attention.self.query.bias_min:0"
input: "encoder.layer.11.attention.self.query.bias_max:0"
input: "/encoder/layer.11/attention/self/query/MatMul_output_0:1"
input: "/encoder/layer.11/attention/self/query/MatMul_output_0:2"
input: "/encoder/layer.11/attention/self/query/Add_output_0_min:0"
input: "/encoder/layer.11/attention/self/query/Add_output_0_max:0"
output: "/encoder/layer.11/attention/self/query/Add_output_0:0"
name: "/encoder/layer.11/attention/self/query/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.028647832572460175
  zero_point: 126
  minval: -3.6096270084381104
  maxval: 3.695570468902588
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/query/Add_output_0:0"
input: "/encoder/layer.11/attention/self/Reshape_2/shape:0"
input: "/encoder/layer.11/attention/self/query/Add_output_0:1"
input: "/encoder/layer.11/attention/self/query/Add_output_0:2"
output: "/encoder/layer.11/attention/self/Reshape_2_output_0:0"
name: "/encoder/layer.11/attention/self/Reshape_2"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.028647832572460175
  zero_point: 126
  minval: -3.6096270084381104
  maxval: 3.695570468902588
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/Reshape_2_output_0:0"
input: "/encoder/layer.11/attention/self/Transpose_1/shape:0"
input: "/encoder/layer.11/attention/self/Reshape_2_output_0_min:0"
input: "/encoder/layer.11/attention/self/Reshape_2_output_0_max:0"
output: "/encoder/layer.11/attention/self/Transpose_1_output_0:0"
name: "/encoder/layer.11/attention/self/Transpose_1"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.028647832572460175
  zero_point: 126
  minval: -3.6096270084381104
  maxval: 3.695570468902588
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1601"
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1601_min:0"
input: "onnx::MatMul_1601_max:0"
output: "/encoder/layer.11/attention/self/key/MatMul_output_0_matmul:0"
name: "/encoder/layer.11/attention/self/key/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.027924062684178352
  zero_point: 129
  minval: -3.6022040843963623
  maxval: 3.5184319019317627
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/key/MatMul_output_0_matmul:0"
input: "/encoder/layer.11/attention/self/key/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.11/attention/self/key/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.11/attention/self/key/MatMul_output_0_min:0"
input: "/encoder/layer.11/attention/self/key/MatMul_output_0_max:0"
output: "/encoder/layer.11/attention/self/key/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/key/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.027924062684178352
  zero_point: 129
  minval: -3.6022040843963623
  maxval: 3.5184319019317627
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.11.attention.self.key.bias:0"
input: "/encoder/layer.11/attention/self/key/MatMul_output_0:0"
input: "encoder.layer.11.attention.self.key.bias_min:0"
input: "encoder.layer.11.attention.self.key.bias_max:0"
input: "/encoder/layer.11/attention/self/key/MatMul_output_0:1"
input: "/encoder/layer.11/attention/self/key/MatMul_output_0:2"
input: "/encoder/layer.11/attention/self/key/Add_output_0_min:0"
input: "/encoder/layer.11/attention/self/key/Add_output_0_max:0"
output: "/encoder/layer.11/attention/self/key/Add_output_0:0"
name: "/encoder/layer.11/attention/self/key/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.027895448729395866
  zero_point: 129
  minval: -3.598512887954712
  maxval: 3.514826536178589
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/key/Add_output_0:0"
input: "/encoder/layer.11/attention/self/Reshape/shape:0"
input: "/encoder/layer.11/attention/self/key/Add_output_0:1"
input: "/encoder/layer.11/attention/self/key/Add_output_0:2"
output: "/encoder/layer.11/attention/self/Reshape_output_0:0"
name: "/encoder/layer.11/attention/self/Reshape"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.027895448729395866
  zero_point: 129
  minval: -3.598512887954712
  maxval: 3.514826536178589
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/Reshape_output_0:0"
input: "/encoder/layer.11/attention/self/Transpose_2/shape:0"
input: "/encoder/layer.11/attention/self/Reshape_output_0_min:0"
input: "/encoder/layer.11/attention/self/Reshape_output_0_max:0"
output: "/encoder/layer.11/attention/self/Transpose_2_output_0:0"
name: "/encoder/layer.11/attention/self/Transpose_2"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 3
  ints: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 64
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.027895448729395866
  zero_point: 129
  minval: -3.598512887954712
  maxval: 3.514826536178589
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/Transpose_1_output_0:0"
input: "/encoder/layer.11/attention/self/Transpose_2_output_0:0"
input: "/encoder/layer.11/attention/self/Transpose_1_output_0:1"
input: "/encoder/layer.11/attention/self/Transpose_1_output_0:2"
input: "/encoder/layer.11/attention/self/Transpose_2_output_0:1"
input: "/encoder/layer.11/attention/self/Transpose_2_output_0:2"
output: "/encoder/layer.11/attention/self/MatMul_output_0_batchmatmul:0"
name: "/encoder/layer.11/attention/self/MatMul_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.23882785439491272
  zero_point: 129
  minval: -30.808794021606445
  maxval: 30.092309951782227
}
padding: 0
out_max_byte_size: 1728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/MatMul_output_0_batchmatmul:0"
input: "/encoder/layer.11/attention/self/MatMul_output_0_batchmatmul_min:0"
input: "/encoder/layer.11/attention/self/MatMul_output_0_batchmatmul_max:0"
input: "/encoder/layer.11/attention/self/MatMul_output_0_min:0"
input: "/encoder/layer.11/attention/self/MatMul_output_0_max:0"
output: "/encoder/layer.11/attention/self/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.23882785439491272
  zero_point: 129
  minval: -30.808794021606445
  maxval: 30.092309951782227
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/MatMul_output_0:0"
input: "/encoder/layer.11/attention/self/Div/b:0"
input: "/encoder/layer.11/attention/self/MatMul_output_0:1"
input: "/encoder/layer.11/attention/self/MatMul_output_0:2"
input: "/encoder/layer.11/attention/self/Div/b_min:0"
input: "/encoder/layer.11/attention/self/Div/b_max:0"
input: "/encoder/layer.11/attention/self/Div_output_0_min:0"
input: "/encoder/layer.11/attention/self/Div_output_0_max:0"
output: "/encoder/layer.11/attention/self/Div_output_0:0"
name: "/encoder/layer.11/attention/self/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
arg {
  name: "scalar_input"
  f: 8.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02985348366200924
  zero_point: 129
  minval: -3.8510994911193848
  maxval: 3.7615389823913574
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/Div_output_0:0"
input: "/Mul_output_0:0"
input: "/encoder/layer.11/attention/self/Div_output_0:1"
input: "/encoder/layer.11/attention/self/Div_output_0:2"
input: "/Mul_output_0:1"
input: "/Mul_output_0:2"
input: "/encoder/layer.11/attention/self/Add_output_0_min:0"
input: "/encoder/layer.11/attention/self/Add_output_0_max:0"
output: "/encoder/layer.11/attention/self/Add_output_0:0"
name: "/encoder/layer.11/attention/self/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 1.3344405750530544e+36
  zero_point: 255
  minval: -3.4028234663852886e+38
  maxval: 0.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/Add_output_0:0"
input: "/encoder/layer.11/attention/self/Add_output_0:1"
input: "/encoder/layer.11/attention/self/Add_output_0:2"
output: "/encoder/layer.11/attention/self/Softmax_output_0:0"
name: "/encoder/layer.11/attention/self/Softmax"
type: "QuantizedSoftmax_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 6
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.003921568859368563
  zero_point: 0
  minval: 0.0
  maxval: 1.0
}
padding: 0
out_max_byte_size: 432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1607"
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1607_min:0"
input: "onnx::MatMul_1607_max:0"
output: "/encoder/layer.11/attention/self/value/MatMul_output_0_matmul:0"
name: "/encoder/layer.11/attention/self/value/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.020123830065131187
  zero_point: 124
  minval: -2.4953548908233643
  maxval: 2.6362218856811523
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/value/MatMul_output_0_matmul:0"
input: "/encoder/layer.11/attention/self/value/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.11/attention/self/value/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.11/attention/self/value/MatMul_output_0_min:0"
input: "/encoder/layer.11/attention/self/value/MatMul_output_0_max:0"
output: "/encoder/layer.11/attention/self/value/MatMul_output_0:0"
name: "/encoder/layer.11/attention/self/value/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.020123830065131187
  zero_point: 124
  minval: -2.4953548908233643
  maxval: 2.6362218856811523
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.11.attention.self.value.bias:0"
input: "/encoder/layer.11/attention/self/value/MatMul_output_0:0"
input: "encoder.layer.11.attention.self.value.bias_min:0"
input: "encoder.layer.11.attention.self.value.bias_max:0"
input: "/encoder/layer.11/attention/self/value/MatMul_output_0:1"
input: "/encoder/layer.11/attention/self/value/MatMul_output_0:2"
input: "/encoder/layer.11/attention/self/value/Add_output_0_min:0"
input: "/encoder/layer.11/attention/self/value/Add_output_0_max:0"
output: "/encoder/layer.11/attention/self/value/Add_output_0:0"
name: "/encoder/layer.11/attention/self/value/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01989193633198738
  zero_point: 124
  minval: -2.466599941253662
  maxval: 2.6058435440063477
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/value/Add_output_0:0"
input: "/encoder/layer.11/attention/self/Reshape_1/shape:0"
input: "/encoder/layer.11/attention/self/value/Add_output_0:1"
input: "/encoder/layer.11/attention/self/value/Add_output_0:2"
output: "/encoder/layer.11/attention/self/Reshape_1_output_0:0"
name: "/encoder/layer.11/attention/self/Reshape_1"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 12
  ints: 64
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01989193633198738
  zero_point: 124
  minval: -2.466599941253662
  maxval: 2.6058435440063477
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/Reshape_1_output_0:0"
input: "/encoder/layer.11/attention/self/Transpose/shape:0"
input: "/encoder/layer.11/attention/self/Reshape_1_output_0_min:0"
input: "/encoder/layer.11/attention/self/Reshape_1_output_0_max:0"
output: "/encoder/layer.11/attention/self/Transpose_output_0:0"
name: "/encoder/layer.11/attention/self/Transpose"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01989193633198738
  zero_point: 124
  minval: -2.466599941253662
  maxval: 2.6058435440063477
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/Softmax_output_0:0"
input: "/encoder/layer.11/attention/self/Transpose_output_0:0"
input: "/encoder/layer.11/attention/self/Softmax_output_0:1"
input: "/encoder/layer.11/attention/self/Softmax_output_0:2"
input: "/encoder/layer.11/attention/self/Transpose_output_0:1"
input: "/encoder/layer.11/attention/self/Transpose_output_0:2"
output: "/encoder/layer.11/attention/self/MatMul_1_output_0_batchmatmul:0"
name: "/encoder/layer.11/attention/self/MatMul_1_matmul"
type: "QuantizedBatchMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.013856226578354836
  zero_point: 128
  minval: -1.773597002029419
  maxval: 1.7597408294677734
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/MatMul_1_output_0_batchmatmul:0"
input: "/encoder/layer.11/attention/self/MatMul_1_output_0_batchmatmul_min:0"
input: "/encoder/layer.11/attention/self/MatMul_1_output_0_batchmatmul_max:0"
input: "/encoder/layer.11/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.11/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.11/attention/self/MatMul_1_output_0:0"
name: "/encoder/layer.11/attention/self/MatMul_1_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 12
  dims: 6
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.013856226578354836
  zero_point: 128
  minval: -1.773597002029419
  maxval: 1.7597408294677734
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/MatMul_1_output_0:0"
input: "/encoder/layer.11/attention/self/Transpose_3/shape:0"
input: "/encoder/layer.11/attention/self/MatMul_1_output_0_min:0"
input: "/encoder/layer.11/attention/self/MatMul_1_output_0_max:0"
output: "/encoder/layer.11/attention/self/Transpose_3_output_0:0"
name: "/encoder/layer.11/attention/self/Transpose_3"
type: "Transpose_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dims"
  ints: 0
  ints: 2
  ints: 1
  ints: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 12
  dims: 64
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.013856226578354836
  zero_point: 128
  minval: -1.773597002029419
  maxval: 1.7597408294677734
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/Transpose_3_output_0:0"
input: "/encoder/layer.11/attention/self/Reshape_3/shape:0"
input: "/encoder/layer.11/attention/self/Transpose_3_output_0:1"
input: "/encoder/layer.11/attention/self/Transpose_3_output_0:2"
output: "/encoder/layer.11/attention/self/Reshape_3_output_0:0"
name: "/encoder/layer.11/attention/self/Reshape_3"
type: "QuantizedReshape"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "dim"
  ints: 1
  ints: 6
  ints: 768
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.013856226578354836
  zero_point: 128
  minval: -1.773597002029419
  maxval: 1.7597408294677734
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/self/Reshape_3_output_0:0"
input: "onnx::MatMul_1622"
input: "/encoder/layer.11/attention/self/Reshape_3_output_0:1"
input: "/encoder/layer.11/attention/self/Reshape_3_output_0:2"
input: "onnx::MatMul_1622_min:0"
input: "onnx::MatMul_1622_max:0"
output: "/encoder/layer.11/attention/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.11/attention/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.013555709272623062
  zero_point: 124
  minval: -1.680907964706421
  maxval: 1.775797963142395
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.11/attention/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.11/attention/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.11/attention/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.11/attention/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.11/attention/output/dense/MatMul_output_0:0"
name: "/encoder/layer.11/attention/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.013555709272623062
  zero_point: 124
  minval: -1.680907964706421
  maxval: 1.775797963142395
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.11.attention.output.dense.bias:0"
input: "/encoder/layer.11/attention/output/dense/MatMul_output_0:0"
input: "encoder.layer.11.attention.output.dense.bias_min:0"
input: "encoder.layer.11.attention.output.dense.bias_max:0"
input: "/encoder/layer.11/attention/output/dense/MatMul_output_0:1"
input: "/encoder/layer.11/attention/output/dense/MatMul_output_0:2"
input: "/encoder/layer.11/attention/output/dense/Add_output_0_min:0"
input: "/encoder/layer.11/attention/output/dense/Add_output_0_max:0"
output: "/encoder/layer.11/attention/output/dense/Add_output_0:0"
name: "/encoder/layer.11/attention/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01359746977686882
  zero_point: 121
  minval: -1.6452938318252563
  maxval: 1.8220609426498413
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/output/dense/Add_output_0:0"
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.11/attention/output/dense/Add_output_0:1"
input: "/encoder/layer.11/attention/output/dense/Add_output_0:2"
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.10/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.11/attention/output/Add_output_0_min:0"
input: "/encoder/layer.11/attention/output/Add_output_0_max:0"
output: "/encoder/layer.11/attention/output/Add_output_0:0"
name: "/encoder/layer.11/attention/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.08329323679208755
  zero_point: 218
  minval: -18.15792465209961
  maxval: 3.0818495750427246
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/output/Add_output_0:0"
input: "/encoder/layer.11/attention/output/Add_output_0:1"
input: "/encoder/layer.11/attention/output/Add_output_0:2"
input: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.00014256470603868365
  zero_point: 255
  minval: -0.036354001611471176
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/output/Add_output_0:0"
input: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.11/attention/output/Add_output_0:1"
input: "/encoder/layer.11/attention/output/Add_output_0:2"
input: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.11/attention/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.11/attention/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.08313101530075073
  zero_point: 218
  minval: -18.122560501098633
  maxval: 3.075847625732422
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.11/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.11/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.11/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.11/attention/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.11/attention/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 1.287949800491333
  zero_point: 0
  minval: 0.0
  maxval: 328.42718505859375
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.11/attention/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.00558821577578783
  zero_point: 0
  minval: 0.0
  maxval: 1.424994945526123
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Add/b:0"
input: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.11/attention/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.11/attention/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.11/attention/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.00558821577578783
  zero_point: 0
  minval: 0.0
  maxval: 1.424994945526123
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.11/attention/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.11/attention/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.004681298043578863
  zero_point: 0
  minval: 0.0
  maxval: 1.1937309503555298
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.11/attention/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.11/attention/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.11/attention/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.11/attention/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.11/attention/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.07127435505390167
  zero_point: 213
  minval: -15.181438446044922
  maxval: 2.993522882461548
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.11.attention.output.LayerNorm.weight:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.11/attention/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.11.attention.output.LayerNorm.weight_min:0"
input: "encoder.layer.11.attention.output.LayerNorm.weight_max:0"
output: "/encoder/layer.11/attention/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.10579519718885422
  zero_point: 231
  minval: -24.438690185546875
  maxval: 2.5390846729278564
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.11.attention.output.LayerNorm.bias:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.11/attention/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.11.attention.output.LayerNorm.bias_min:0"
input: "encoder.layer.11.attention.output.LayerNorm.bias_max:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0_min:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0_max:0"
output: "/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0:0"
name: "/encoder/layer.11/attention/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.11408033967018127
  zero_point: 234
  minval: -26.694799423217773
  maxval: 2.3956871032714844
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0:0"
input: "onnx::MatMul_1623"
input: "/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0:2"
input: "onnx::MatMul_1623_min:0"
input: "onnx::MatMul_1623_max:0"
output: "/encoder/layer.11/intermediate/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.11/intermediate/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.031074268743395805
  zero_point: 125
  minval: -3.8842835426330566
  maxval: 4.0396552085876465
}
padding: 0
out_max_byte_size: 73728
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/intermediate/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.11/intermediate/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.11/intermediate/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.11/intermediate/dense/MatMul_output_0_min:0"
input: "/encoder/layer.11/intermediate/dense/MatMul_output_0_max:0"
output: "/encoder/layer.11/intermediate/dense/MatMul_output_0:0"
name: "/encoder/layer.11/intermediate/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.031074268743395805
  zero_point: 125
  minval: -3.8842835426330566
  maxval: 4.0396552085876465
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/intermediate/dense/MatMul_output_0:0"
input: "/encoder/layer.11/intermediate/dense/MatMul_output_0:1"
input: "/encoder/layer.11/intermediate/dense/MatMul_output_0:2"
output: "/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1_output_0:0"
name: "Gelu_/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1"
type: "QuantizedGelu_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
arg {
  name: "scalar_input"
  f: 0.5
}
arg {
  name: "scalar_input_index"
  i: 1
}
arg {
  name: "activation"
  s: "GELU"
}
output_shape {
  dims: 1
  dims: 6
  dims: 3072
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.01545190904289484
  zero_point: 11
  minval: -0.16997100412845612
  maxval: 3.770265817642212
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1_output_0:0"
input: "onnx::MatMul_1624"
input: "/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1_output_0:1"
input: "/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1_output_0:2"
input: "onnx::MatMul_1624_min:0"
input: "onnx::MatMul_1624_max:0"
output: "/encoder/layer.11/output/dense/MatMul_output_0_matmul:0"
name: "/encoder/layer.11/output/dense/MatMul_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.044259894639253616
  zero_point: 172
  minval: -7.612701892852783
  maxval: 3.6735713481903076
}
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/output/dense/MatMul_output_0_matmul:0"
input: "/encoder/layer.11/output/dense/MatMul_output_0_matmul_min:0"
input: "/encoder/layer.11/output/dense/MatMul_output_0_matmul_max:0"
input: "/encoder/layer.11/output/dense/MatMul_output_0_min:0"
input: "/encoder/layer.11/output/dense/MatMul_output_0_max:0"
output: "/encoder/layer.11/output/dense/MatMul_output_0:0"
name: "/encoder/layer.11/output/dense/MatMul_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.044259894639253616
  zero_point: 172
  minval: -7.612701892852783
  maxval: 3.6735713481903076
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "encoder.layer.11.output.dense.bias:0"
input: "/encoder/layer.11/output/dense/MatMul_output_0:0"
input: "encoder.layer.11.output.dense.bias_min:0"
input: "encoder.layer.11.output.dense.bias_max:0"
input: "/encoder/layer.11/output/dense/MatMul_output_0:1"
input: "/encoder/layer.11/output/dense/MatMul_output_0:2"
input: "/encoder/layer.11/output/dense/Add_output_0_min:0"
input: "/encoder/layer.11/output/dense/Add_output_0_max:0"
output: "/encoder/layer.11/output/dense/Add_output_0:0"
name: "/encoder/layer.11/output/dense/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.044334687292575836
  zero_point: 176
  minval: -7.802905082702637
  maxval: 3.5024402141571045
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/output/dense/Add_output_0:0"
input: "/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0:0"
input: "/encoder/layer.11/output/dense/Add_output_0:1"
input: "/encoder/layer.11/output/dense/Add_output_0:2"
input: "/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0:1"
input: "/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0:2"
input: "/encoder/layer.11/output/Add_output_0_min:0"
input: "/encoder/layer.11/output/Add_output_0_max:0"
output: "/encoder/layer.11/output/Add_output_0:0"
name: "/encoder/layer.11/output/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.1198514774441719
  zero_point: 225
  minval: -26.966583251953125
  maxval: 3.5955443382263184
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/output/Add_output_0:0"
input: "/encoder/layer.11/output/Add_output_0:1"
input: "/encoder/layer.11/output/Add_output_0:2"
input: "/encoder/layer.11/output/LayerNorm/ReduceMean/axes:0"
input: "/encoder/layer.11/output/LayerNorm/ReduceMean_output_0_min:0"
input: "/encoder/layer.11/output/LayerNorm/ReduceMean_output_0_max:0"
output: "/encoder/layer.11/output/LayerNorm/ReduceMean_output_0:0"
name: "/encoder/layer.11/output/LayerNorm/ReduceMean"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0002673058770596981
  zero_point: 255
  minval: -0.06816300004720688
  maxval: 0.0
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/output/Add_output_0:0"
input: "/encoder/layer.11/output/LayerNorm/ReduceMean_output_0:0"
input: "/encoder/layer.11/output/Add_output_0:1"
input: "/encoder/layer.11/output/Add_output_0:2"
input: "/encoder/layer.11/output/LayerNorm/ReduceMean_output_0:1"
input: "/encoder/layer.11/output/LayerNorm/ReduceMean_output_0:2"
input: "/encoder/layer.11/output/LayerNorm/Sub_output_0_min:0"
input: "/encoder/layer.11/output/LayerNorm/Sub_output_0_max:0"
output: "/encoder/layer.11/output/LayerNorm/Sub_output_0:0"
name: "/encoder/layer.11/output/LayerNorm/Sub"
type: "QuantizedSub_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.11954853683710098
  zero_point: 225
  minval: -26.898420333862305
  maxval: 3.586456060409546
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.11/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.11/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.11/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.11/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.11/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.11/output/LayerNorm/Pow_output_0_min:0"
input: "/encoder/layer.11/output/LayerNorm/Pow_output_0_max:0"
output: "/encoder/layer.11/output/LayerNorm/Pow_output_0:0"
name: "/encoder/layer.11/output/LayerNorm/Pow"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 2.0
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 2.837352991104126
  zero_point: 0
  minval: 0.0
  maxval: 723.5250244140625
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/output/LayerNorm/Pow_output_0:0"
input: "/encoder/layer.11/output/LayerNorm/Pow_output_0:1"
input: "/encoder/layer.11/output/LayerNorm/Pow_output_0:2"
input: "/encoder/layer.11/output/LayerNorm/ReduceMean_1/axes:0"
input: "/encoder/layer.11/output/LayerNorm/ReduceMean_1_output_0_min:0"
input: "/encoder/layer.11/output/LayerNorm/ReduceMean_1_output_0_max:0"
output: "/encoder/layer.11/output/LayerNorm/ReduceMean_1_output_0:0"
name: "/encoder/layer.11/output/LayerNorm/ReduceMean_1"
type: "QuantizedMean_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "reduce_type"
  i: 0
}
arg {
  name: "axis"
  ints: -1
}
arg {
  name: "keepdims"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007044729311019182
  zero_point: 0
  minval: 0.0
  maxval: 1.7964060306549072
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/output/LayerNorm/ReduceMean_1_output_0:0"
input: "/encoder/layer.11/output/LayerNorm/Add/b:0"
input: "/encoder/layer.11/output/LayerNorm/ReduceMean_1_output_0:1"
input: "/encoder/layer.11/output/LayerNorm/ReduceMean_1_output_0:2"
input: "/encoder/layer.11/output/LayerNorm/Add/b_min:0"
input: "/encoder/layer.11/output/LayerNorm/Add/b_max:0"
input: "/encoder/layer.11/output/LayerNorm/Add_output_0_min:0"
input: "/encoder/layer.11/output/LayerNorm/Add_output_0_max:0"
output: "/encoder/layer.11/output/LayerNorm/Add_output_0:0"
name: "/encoder/layer.11/output/LayerNorm/Add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
arg {
  name: "scalar_input"
  f: 9.999999960041972e-13
}
arg {
  name: "scalar_input_index"
  i: 1
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.007044729311019182
  zero_point: 0
  minval: 0.0
  maxval: 1.7964060306549072
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/output/LayerNorm/Add_output_0:0"
input: "/encoder/layer.11/output/LayerNorm/Add_output_0:1"
input: "/encoder/layer.11/output/LayerNorm/Add_output_0:2"
output: "/encoder/layer.11/output/LayerNorm/Sqrt_output_0:0"
name: "/encoder/layer.11/output/LayerNorm/Sqrt"
type: "QuantizedSqrt_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 9
}
arg {
  name: "scalar_input"
  f: 0.5
}
output_shape {
  dims: 1
  dims: 6
  dims: 1
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.005256082396954298
  zero_point: 0
  minval: 0.0
  maxval: 1.3403010368347168
}
padding: 0
out_max_byte_size: 6
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/output/LayerNorm/Sub_output_0:0"
input: "/encoder/layer.11/output/LayerNorm/Sqrt_output_0:0"
input: "/encoder/layer.11/output/LayerNorm/Sub_output_0:1"
input: "/encoder/layer.11/output/LayerNorm/Sub_output_0:2"
input: "/encoder/layer.11/output/LayerNorm/Sqrt_output_0:1"
input: "/encoder/layer.11/output/LayerNorm/Sqrt_output_0:2"
input: "/encoder/layer.11/output/LayerNorm/Div_output_0_min:0"
input: "/encoder/layer.11/output/LayerNorm/Div_output_0_max:0"
output: "/encoder/layer.11/output/LayerNorm/Div_output_0:0"
name: "/encoder/layer.11/output/LayerNorm/Div"
type: "QuantizedDiv_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 3
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.09080971777439117
  zero_point: 221
  minval: -20.068946838378906
  maxval: 3.0875303745269775
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/output/LayerNorm/Div_output_0:0"
input: "encoder.layer.11.output.LayerNorm.weight:0"
input: "/encoder/layer.11/output/LayerNorm/Div_output_0:1"
input: "/encoder/layer.11/output/LayerNorm/Div_output_0:2"
input: "encoder.layer.11.output.LayerNorm.weight_min:0"
input: "encoder.layer.11.output.LayerNorm.weight_max:0"
output: "/encoder/layer.11/output/LayerNorm/Mul_output_0:0"
name: "/encoder/layer.11/output/LayerNorm/Mul"
type: "QuantizedMul_8x8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 2
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.028795626014471054
  zero_point: 190
  minval: -5.4711689949035645
  maxval: 1.8717156648635864
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/encoder/layer.11/output/LayerNorm/Mul_output_0:0"
input: "encoder.layer.11.output.LayerNorm.bias:0"
input: "/encoder/layer.11/output/LayerNorm/Mul_output_0:1"
input: "/encoder/layer.11/output/LayerNorm/Mul_output_0:2"
input: "encoder.layer.11.output.LayerNorm.bias_min:0"
input: "encoder.layer.11.output.LayerNorm.bias_max:0"
input: "mace_output_node_last_hidden_state_min:0"
input: "mace_output_node_last_hidden_state_max:0"
output: "mace_output_node_last_hidden_state:0"
name: "mace_output_node_/encoder/layer.11/output/LayerNorm/Add_1"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "type"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.028129352256655693
  zero_point: 187
  minval: -5.260189056396484
  maxval: 1.9127960205078125
}
padding: 0
out_max_byte_size: 4608
out_max_byte_size: 4
out_max_byte_size: 4
, input: "mace_output_node_last_hidden_state:0"
input: "mace_output_node_last_hidden_state:1"
input: "mace_output_node_last_hidden_state:2"
output: "last_hidden_state:0"
name: "last_hidden_state"
type: "DequantizeOUTPUT_8tof"
arg {
  name: "T"
  i: 2
}
arg {
  name: "data_format"
  i: 0
}
output_shape {
  dims: 1
  dims: 6
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_FLOAT
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
padding: 0
out_max_byte_size: 18432
out_max_byte_size: 1
out_max_byte_size: 4
, input: "/Constant_output_0:0"
input: "mace_output_node_last_hidden_state:0"
input: "mace_output_node_last_hidden_state:1"
input: "mace_output_node_last_hidden_state:2"
input: "/pooler/Gather/index_dim"
output: "/pooler/Gather_output_0:0"
name: "/pooler/Gather"
type: "Gather_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "axis"
  i: 1
}
output_shape {
  dims: 1
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.025098640471696854
  zero_point: 209
  minval: -5.2456159591674805
  maxval: 1.1545374393463135
}
padding: 0
out_max_byte_size: 768
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/pooler/Gather_output_0:0"
input: "pooler.dense.weight:0"
input: "/pooler/Gather_output_0:1"
input: "/pooler/Gather_output_0:2"
input: "pooler.dense.weight_min:0"
input: "pooler.dense.weight_max:0"
output: "/pooler/dense/Gemm_output_0_matmul:0"
name: "/pooler/dense/Gemm_matmul"
type: "QuantizedMatMul_8x8to32"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "transpose_a"
  i: 0
}
arg {
  name: "transpose_b"
  i: 1
}
output_shape {
  dims: 1
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_INT32
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02376180700957775
  zero_point: 124
  minval: -2.9464640617370605
  maxval: 3.1127965450286865
}
padding: 0
out_max_byte_size: 3072
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/pooler/dense/Gemm_output_0_matmul:0"
input: "/pooler/dense/Gemm_output_0_matmul_min:0"
input: "/pooler/dense/Gemm_output_0_matmul_max:0"
input: "/pooler/dense/Gemm_output_0_min:0"
input: "/pooler/dense/Gemm_output_0_max:0"
output: "/pooler/dense/Gemm_output_0_requantize_op:0"
name: "/pooler/dense/Gemm_requantize"
type: "Requantize_32to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "transpose_a"
  i: 0
}
arg {
  name: "transpose_b"
  i: 1
}
output_shape {
  dims: 1
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02376180700957775
  zero_point: 124
  minval: -2.9464640617370605
  maxval: 3.1127965450286865
}
padding: 0
out_max_byte_size: 768
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/pooler/dense/Gemm_output_0_requantize_op:0"
input: "pooler.dense.bias:0"
input: "/pooler/dense/Gemm_output_0_requantize_op_min:0"
input: "/pooler/dense/Gemm_output_0_requantize_op_max:0"
input: "pooler.dense.bias_min:0"
input: "pooler.dense.bias_max:0"
output: "/pooler/dense/Gemm_output_0:0"
name: "/pooler/dense/Gemm_add"
type: "QuantizedAdd_8p8to8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "transpose_a"
  i: 0
}
arg {
  name: "transpose_b"
  i: 1
}
output_shape {
  dims: 1
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.02376180700957775
  zero_point: 124
  minval: -2.9464640617370605
  maxval: 3.1127965450286865
}
padding: 0
out_max_byte_size: 768
out_max_byte_size: 4
out_max_byte_size: 4
, input: "/pooler/dense/Gemm_output_0:0"
input: "/pooler/dense/Gemm_output_0:1"
input: "/pooler/dense/Gemm_output_0:2"
output: "mace_output_node_pooler_output:0"
name: "mace_output_node_/pooler/activation/Tanh"
type: "QuantizedTanh_8"
arg {
  name: "T"
  i: 2
}
arg {
  name: "framework_type"
  i: 2
}
arg {
  name: "data_format"
  i: 2
}
arg {
  name: "activation"
  s: "TANH"
}
arg {
  name: "activation_coefficient"
  f: 0.0
}
output_shape {
  dims: 1
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
quantize_info {
  scale: 0.0078125
  zero_point: 128
  minval: -1.0
  maxval: 0.9921875
}
padding: 0
out_max_byte_size: 768
out_max_byte_size: 4
out_max_byte_size: 4
, input: "mace_output_node_pooler_output:0"
input: "mace_output_node_pooler_output:1"
input: "mace_output_node_pooler_output:2"
output: "pooler_output:0"
name: "pooler_output"
type: "DequantizeOUTPUT_8tof"
arg {
  name: "T"
  i: 2
}
arg {
  name: "data_format"
  i: 0
}
output_shape {
  dims: 1
  dims: 768
}
output_shape {
  dims: 1
}
output_shape {
  dims: 1
}
output_type: DT_FLOAT
output_type: DT_UINT8
output_type: DT_FLOAT
output_type: DT_FLOAT
padding: 0
out_max_byte_size: 3072
out_max_byte_size: 1
out_max_byte_size: 4
]
mace_input_node_attention_mask
mace_input_node_token_type_ids
Hexagon op:
Op: mace_input_node (QuantizeINPUT_f_to_8, node_id:1856, index:, shape:[1, 6, 768])
Op: /embeddings/Add (QuantizedAdd_8p8to8, node_id:1857, index:0, shape:[1, 6, 768])
Op: /embeddings/Add_1 (QuantizedAdd_8p8to8, node_id:1858, index:1, shape:[1, 6, 768])
Op: /embeddings/LayerNorm/ReduceMean (QuantizedMean_8, node_id:1859, index:2, shape:[1, 6, 1])
Op: /embeddings/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:1860, index:3, shape:[1, 6, 768])
Op: /embeddings/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:1861, index:4, shape:[1, 6, 768])
Op: /embeddings/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:1862, index:5, shape:[1, 6, 1])
Op: /embeddings/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:1863, index:6, shape:[1, 6, 1])
Op: /embeddings/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:1864, index:7, shape:[1, 6, 1])
Op: /embeddings/LayerNorm/Div (QuantizedDiv_8, node_id:1865, index:8, shape:[1, 6, 768])
Op: /embeddings/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:1866, index:9, shape:[1, 6, 768])
Op: /embeddings/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:1867, index:10, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/self/query/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:1868, index:11, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/self/query/MatMul_requantize (Requantize_32to8, node_id:1869, index:12, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/self/query/Add (QuantizedAdd_8p8to8, node_id:1870, index:13, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/self/Reshape_2 (QuantizedReshape, node_id:1871, index:14, shape:[1, 6, 12, 64])
Op: /encoder/layer.0/attention/self/Transpose_1 (Transpose_8, node_id:1872, index:15, shape:[1, 12, 6, 64])
Op: /encoder/layer.0/attention/self/key/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:1873, index:16, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/self/key/MatMul_requantize (Requantize_32to8, node_id:1874, index:17, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/self/key/Add (QuantizedAdd_8p8to8, node_id:1875, index:18, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/self/Reshape (QuantizedReshape, node_id:1876, index:19, shape:[1, 6, 12, 64])
Op: /encoder/layer.0/attention/self/Transpose_2 (Transpose_8, node_id:1877, index:20, shape:[1, 12, 64, 6])
Op: /encoder/layer.0/attention/self/MatMul_matmul (QuantizedBatchMatMul_8x8to32, node_id:1878, index:21, shape:[1, 12, 6, 6])
Op: /encoder/layer.0/attention/self/MatMul_requantize (Requantize_32to8, node_id:1879, index:22, shape:[1, 12, 6, 6])
Op: /encoder/layer.0/attention/self/Div (QuantizedDiv_8, node_id:1880, index:23, shape:[1, 12, 6, 6])
Op: /Sub (QuantizedSub_8p8to8, node_id:1881, index:24, shape:[1, 1, 1, 6])
Op: /Mul (QuantizedMul_8x8to8, node_id:1882, index:25, shape:[1, 1, 1, 6])
Op: /encoder/layer.0/attention/self/Add (QuantizedAdd_8p8to8, node_id:1883, index:26, shape:[1, 12, 6, 6])
Op: /encoder/layer.0/attention/self/Softmax (QuantizedSoftmax_8, node_id:1884, index:27, shape:[1, 12, 6, 6])
Op: /encoder/layer.0/attention/self/value/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:1885, index:28, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/self/value/MatMul_requantize (Requantize_32to8, node_id:1886, index:29, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/self/value/Add (QuantizedAdd_8p8to8, node_id:1887, index:30, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/self/Reshape_1 (QuantizedReshape, node_id:1888, index:31, shape:[1, 6, 12, 64])
Op: /encoder/layer.0/attention/self/Transpose (Transpose_8, node_id:1889, index:32, shape:[1, 12, 6, 64])
Op: /encoder/layer.0/attention/self/MatMul_1_matmul (QuantizedBatchMatMul_8x8to32, node_id:1890, index:33, shape:[1, 12, 6, 64])
Op: /encoder/layer.0/attention/self/MatMul_1_requantize (Requantize_32to8, node_id:1891, index:34, shape:[1, 12, 6, 64])
Op: /encoder/layer.0/attention/self/Transpose_3 (Transpose_8, node_id:1892, index:35, shape:[1, 6, 12, 64])
Op: /encoder/layer.0/attention/self/Reshape_3 (QuantizedReshape, node_id:1893, index:36, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:1894, index:37, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/output/dense/MatMul_requantize (Requantize_32to8, node_id:1895, index:38, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/output/dense/Add (QuantizedAdd_8p8to8, node_id:1896, index:39, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/output/Add (QuantizedAdd_8p8to8, node_id:1897, index:40, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:1898, index:41, shape:[1, 6, 1])
Op: /encoder/layer.0/attention/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:1899, index:42, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:1900, index:43, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:1901, index:44, shape:[1, 6, 1])
Op: /encoder/layer.0/attention/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:1902, index:45, shape:[1, 6, 1])
Op: /encoder/layer.0/attention/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:1903, index:46, shape:[1, 6, 1])
Op: /encoder/layer.0/attention/output/LayerNorm/Div (QuantizedDiv_8, node_id:1904, index:47, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:1905, index:48, shape:[1, 6, 768])
Op: /encoder/layer.0/attention/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:1906, index:49, shape:[1, 6, 768])
Op: /encoder/layer.0/intermediate/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:1907, index:50, shape:[1, 6, 3072])
Op: /encoder/layer.0/intermediate/dense/MatMul_requantize (Requantize_32to8, node_id:1908, index:51, shape:[1, 6, 3072])
Op: Gelu_/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1 (QuantizedGelu_8, node_id:1909, index:52, shape:[1, 6, 3072])
Op: /encoder/layer.0/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:1910, index:53, shape:[1, 6, 768])
Op: /encoder/layer.0/output/dense/MatMul_requantize (Requantize_32to8, node_id:1911, index:54, shape:[1, 6, 768])
Op: /encoder/layer.0/output/dense/Add (QuantizedAdd_8p8to8, node_id:1912, index:55, shape:[1, 6, 768])
Op: /encoder/layer.0/output/Add (QuantizedAdd_8p8to8, node_id:1913, index:56, shape:[1, 6, 768])
Op: /encoder/layer.0/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:1914, index:57, shape:[1, 6, 1])
Op: /encoder/layer.0/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:1915, index:58, shape:[1, 6, 768])
Op: /encoder/layer.0/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:1916, index:59, shape:[1, 6, 768])
Op: /encoder/layer.0/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:1917, index:60, shape:[1, 6, 1])
Op: /encoder/layer.0/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:1918, index:61, shape:[1, 6, 1])
Op: /encoder/layer.0/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:1919, index:62, shape:[1, 6, 1])
Op: /encoder/layer.0/output/LayerNorm/Div (QuantizedDiv_8, node_id:1920, index:63, shape:[1, 6, 768])
Op: /encoder/layer.0/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:1921, index:64, shape:[1, 6, 768])
Op: /encoder/layer.0/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:1922, index:65, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/self/query/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:1923, index:66, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/self/query/MatMul_requantize (Requantize_32to8, node_id:1924, index:67, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/self/query/Add (QuantizedAdd_8p8to8, node_id:1925, index:68, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/self/Reshape_2 (QuantizedReshape, node_id:1926, index:69, shape:[1, 6, 12, 64])
Op: /encoder/layer.1/attention/self/Transpose_1 (Transpose_8, node_id:1927, index:70, shape:[1, 12, 6, 64])
Op: /encoder/layer.1/attention/self/key/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:1928, index:71, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/self/key/MatMul_requantize (Requantize_32to8, node_id:1929, index:72, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/self/key/Add (QuantizedAdd_8p8to8, node_id:1930, index:73, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/self/Reshape (QuantizedReshape, node_id:1931, index:74, shape:[1, 6, 12, 64])
Op: /encoder/layer.1/attention/self/Transpose_2 (Transpose_8, node_id:1932, index:75, shape:[1, 12, 64, 6])
Op: /encoder/layer.1/attention/self/MatMul_matmul (QuantizedBatchMatMul_8x8to32, node_id:1933, index:76, shape:[1, 12, 6, 6])
Op: /encoder/layer.1/attention/self/MatMul_requantize (Requantize_32to8, node_id:1934, index:77, shape:[1, 12, 6, 6])
Op: /encoder/layer.1/attention/self/Div (QuantizedDiv_8, node_id:1935, index:78, shape:[1, 12, 6, 6])
Op: /encoder/layer.1/attention/self/Add (QuantizedAdd_8p8to8, node_id:1936, index:79, shape:[1, 12, 6, 6])
Op: /encoder/layer.1/attention/self/Softmax (QuantizedSoftmax_8, node_id:1937, index:80, shape:[1, 12, 6, 6])
Op: /encoder/layer.1/attention/self/value/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:1938, index:81, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/self/value/MatMul_requantize (Requantize_32to8, node_id:1939, index:82, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/self/value/Add (QuantizedAdd_8p8to8, node_id:1940, index:83, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/self/Reshape_1 (QuantizedReshape, node_id:1941, index:84, shape:[1, 6, 12, 64])
Op: /encoder/layer.1/attention/self/Transpose (Transpose_8, node_id:1942, index:85, shape:[1, 12, 6, 64])
Op: /encoder/layer.1/attention/self/MatMul_1_matmul (QuantizedBatchMatMul_8x8to32, node_id:1943, index:86, shape:[1, 12, 6, 64])
Op: /encoder/layer.1/attention/self/MatMul_1_requantize (Requantize_32to8, node_id:1944, index:87, shape:[1, 12, 6, 64])
Op: /encoder/layer.1/attention/self/Transpose_3 (Transpose_8, node_id:1945, index:88, shape:[1, 6, 12, 64])
Op: /encoder/layer.1/attention/self/Reshape_3 (QuantizedReshape, node_id:1946, index:89, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:1947, index:90, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/output/dense/MatMul_requantize (Requantize_32to8, node_id:1948, index:91, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/output/dense/Add (QuantizedAdd_8p8to8, node_id:1949, index:92, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/output/Add (QuantizedAdd_8p8to8, node_id:1950, index:93, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:1951, index:94, shape:[1, 6, 1])
Op: /encoder/layer.1/attention/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:1952, index:95, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:1953, index:96, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:1954, index:97, shape:[1, 6, 1])
Op: /encoder/layer.1/attention/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:1955, index:98, shape:[1, 6, 1])
Op: /encoder/layer.1/attention/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:1956, index:99, shape:[1, 6, 1])
Op: /encoder/layer.1/attention/output/LayerNorm/Div (QuantizedDiv_8, node_id:1957, index:100, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:1958, index:101, shape:[1, 6, 768])
Op: /encoder/layer.1/attention/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:1959, index:102, shape:[1, 6, 768])
Op: /encoder/layer.1/intermediate/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:1960, index:103, shape:[1, 6, 3072])
Op: /encoder/layer.1/intermediate/dense/MatMul_requantize (Requantize_32to8, node_id:1961, index:104, shape:[1, 6, 3072])
Op: Gelu_/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1 (QuantizedGelu_8, node_id:1962, index:105, shape:[1, 6, 3072])
Op: /encoder/layer.1/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:1963, index:106, shape:[1, 6, 768])
Op: /encoder/layer.1/output/dense/MatMul_requantize (Requantize_32to8, node_id:1964, index:107, shape:[1, 6, 768])
Op: /encoder/layer.1/output/dense/Add (QuantizedAdd_8p8to8, node_id:1965, index:108, shape:[1, 6, 768])
Op: /encoder/layer.1/output/Add (QuantizedAdd_8p8to8, node_id:1966, index:109, shape:[1, 6, 768])
Op: /encoder/layer.1/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:1967, index:110, shape:[1, 6, 1])
Op: /encoder/layer.1/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:1968, index:111, shape:[1, 6, 768])
Op: /encoder/layer.1/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:1969, index:112, shape:[1, 6, 768])
Op: /encoder/layer.1/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:1970, index:113, shape:[1, 6, 1])
Op: /encoder/layer.1/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:1971, index:114, shape:[1, 6, 1])
Op: /encoder/layer.1/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:1972, index:115, shape:[1, 6, 1])
Op: /encoder/layer.1/output/LayerNorm/Div (QuantizedDiv_8, node_id:1973, index:116, shape:[1, 6, 768])
Op: /encoder/layer.1/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:1974, index:117, shape:[1, 6, 768])
Op: /encoder/layer.1/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:1975, index:118, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/self/query/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:1976, index:119, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/self/query/MatMul_requantize (Requantize_32to8, node_id:1977, index:120, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/self/query/Add (QuantizedAdd_8p8to8, node_id:1978, index:121, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/self/Reshape_2 (QuantizedReshape, node_id:1979, index:122, shape:[1, 6, 12, 64])
Op: /encoder/layer.2/attention/self/Transpose_1 (Transpose_8, node_id:1980, index:123, shape:[1, 12, 6, 64])
Op: /encoder/layer.2/attention/self/key/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:1981, index:124, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/self/key/MatMul_requantize (Requantize_32to8, node_id:1982, index:125, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/self/key/Add (QuantizedAdd_8p8to8, node_id:1983, index:126, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/self/Reshape (QuantizedReshape, node_id:1984, index:127, shape:[1, 6, 12, 64])
Op: /encoder/layer.2/attention/self/Transpose_2 (Transpose_8, node_id:1985, index:128, shape:[1, 12, 64, 6])
Op: /encoder/layer.2/attention/self/MatMul_matmul (QuantizedBatchMatMul_8x8to32, node_id:1986, index:129, shape:[1, 12, 6, 6])
Op: /encoder/layer.2/attention/self/MatMul_requantize (Requantize_32to8, node_id:1987, index:130, shape:[1, 12, 6, 6])
Op: /encoder/layer.2/attention/self/Div (QuantizedDiv_8, node_id:1988, index:131, shape:[1, 12, 6, 6])
Op: /encoder/layer.2/attention/self/Add (QuantizedAdd_8p8to8, node_id:1989, index:132, shape:[1, 12, 6, 6])
Op: /encoder/layer.2/attention/self/Softmax (QuantizedSoftmax_8, node_id:1990, index:133, shape:[1, 12, 6, 6])
Op: /encoder/layer.2/attention/self/value/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:1991, index:134, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/self/value/MatMul_requantize (Requantize_32to8, node_id:1992, index:135, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/self/value/Add (QuantizedAdd_8p8to8, node_id:1993, index:136, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/self/Reshape_1 (QuantizedReshape, node_id:1994, index:137, shape:[1, 6, 12, 64])
Op: /encoder/layer.2/attention/self/Transpose (Transpose_8, node_id:1995, index:138, shape:[1, 12, 6, 64])
Op: /encoder/layer.2/attention/self/MatMul_1_matmul (QuantizedBatchMatMul_8x8to32, node_id:1996, index:139, shape:[1, 12, 6, 64])
Op: /encoder/layer.2/attention/self/MatMul_1_requantize (Requantize_32to8, node_id:1997, index:140, shape:[1, 12, 6, 64])
Op: /encoder/layer.2/attention/self/Transpose_3 (Transpose_8, node_id:1998, index:141, shape:[1, 6, 12, 64])
Op: /encoder/layer.2/attention/self/Reshape_3 (QuantizedReshape, node_id:1999, index:142, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2000, index:143, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/output/dense/MatMul_requantize (Requantize_32to8, node_id:2001, index:144, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/output/dense/Add (QuantizedAdd_8p8to8, node_id:2002, index:145, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/output/Add (QuantizedAdd_8p8to8, node_id:2003, index:146, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2004, index:147, shape:[1, 6, 1])
Op: /encoder/layer.2/attention/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2005, index:148, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2006, index:149, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2007, index:150, shape:[1, 6, 1])
Op: /encoder/layer.2/attention/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2008, index:151, shape:[1, 6, 1])
Op: /encoder/layer.2/attention/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2009, index:152, shape:[1, 6, 1])
Op: /encoder/layer.2/attention/output/LayerNorm/Div (QuantizedDiv_8, node_id:2010, index:153, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2011, index:154, shape:[1, 6, 768])
Op: /encoder/layer.2/attention/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2012, index:155, shape:[1, 6, 768])
Op: /encoder/layer.2/intermediate/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2013, index:156, shape:[1, 6, 3072])
Op: /encoder/layer.2/intermediate/dense/MatMul_requantize (Requantize_32to8, node_id:2014, index:157, shape:[1, 6, 3072])
Op: Gelu_/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1 (QuantizedGelu_8, node_id:2015, index:158, shape:[1, 6, 3072])
Op: /encoder/layer.2/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2016, index:159, shape:[1, 6, 768])
Op: /encoder/layer.2/output/dense/MatMul_requantize (Requantize_32to8, node_id:2017, index:160, shape:[1, 6, 768])
Op: /encoder/layer.2/output/dense/Add (QuantizedAdd_8p8to8, node_id:2018, index:161, shape:[1, 6, 768])
Op: /encoder/layer.2/output/Add (QuantizedAdd_8p8to8, node_id:2019, index:162, shape:[1, 6, 768])
Op: /encoder/layer.2/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2020, index:163, shape:[1, 6, 1])
Op: /encoder/layer.2/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2021, index:164, shape:[1, 6, 768])
Op: /encoder/layer.2/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2022, index:165, shape:[1, 6, 768])
Op: /encoder/layer.2/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2023, index:166, shape:[1, 6, 1])
Op: /encoder/layer.2/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2024, index:167, shape:[1, 6, 1])
Op: /encoder/layer.2/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2025, index:168, shape:[1, 6, 1])
Op: /encoder/layer.2/output/LayerNorm/Div (QuantizedDiv_8, node_id:2026, index:169, shape:[1, 6, 768])
Op: /encoder/layer.2/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2027, index:170, shape:[1, 6, 768])
Op: /encoder/layer.2/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2028, index:171, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/self/query/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2029, index:172, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/self/query/MatMul_requantize (Requantize_32to8, node_id:2030, index:173, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/self/query/Add (QuantizedAdd_8p8to8, node_id:2031, index:174, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/self/Reshape_2 (QuantizedReshape, node_id:2032, index:175, shape:[1, 6, 12, 64])
Op: /encoder/layer.3/attention/self/Transpose_1 (Transpose_8, node_id:2033, index:176, shape:[1, 12, 6, 64])
Op: /encoder/layer.3/attention/self/key/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2034, index:177, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/self/key/MatMul_requantize (Requantize_32to8, node_id:2035, index:178, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/self/key/Add (QuantizedAdd_8p8to8, node_id:2036, index:179, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/self/Reshape (QuantizedReshape, node_id:2037, index:180, shape:[1, 6, 12, 64])
Op: /encoder/layer.3/attention/self/Transpose_2 (Transpose_8, node_id:2038, index:181, shape:[1, 12, 64, 6])
Op: /encoder/layer.3/attention/self/MatMul_matmul (QuantizedBatchMatMul_8x8to32, node_id:2039, index:182, shape:[1, 12, 6, 6])
Op: /encoder/layer.3/attention/self/MatMul_requantize (Requantize_32to8, node_id:2040, index:183, shape:[1, 12, 6, 6])
Op: /encoder/layer.3/attention/self/Div (QuantizedDiv_8, node_id:2041, index:184, shape:[1, 12, 6, 6])
Op: /encoder/layer.3/attention/self/Add (QuantizedAdd_8p8to8, node_id:2042, index:185, shape:[1, 12, 6, 6])
Op: /encoder/layer.3/attention/self/Softmax (QuantizedSoftmax_8, node_id:2043, index:186, shape:[1, 12, 6, 6])
Op: /encoder/layer.3/attention/self/value/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2044, index:187, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/self/value/MatMul_requantize (Requantize_32to8, node_id:2045, index:188, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/self/value/Add (QuantizedAdd_8p8to8, node_id:2046, index:189, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/self/Reshape_1 (QuantizedReshape, node_id:2047, index:190, shape:[1, 6, 12, 64])
Op: /encoder/layer.3/attention/self/Transpose (Transpose_8, node_id:2048, index:191, shape:[1, 12, 6, 64])
Op: /encoder/layer.3/attention/self/MatMul_1_matmul (QuantizedBatchMatMul_8x8to32, node_id:2049, index:192, shape:[1, 12, 6, 64])
Op: /encoder/layer.3/attention/self/MatMul_1_requantize (Requantize_32to8, node_id:2050, index:193, shape:[1, 12, 6, 64])
Op: /encoder/layer.3/attention/self/Transpose_3 (Transpose_8, node_id:2051, index:194, shape:[1, 6, 12, 64])
Op: /encoder/layer.3/attention/self/Reshape_3 (QuantizedReshape, node_id:2052, index:195, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2053, index:196, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/output/dense/MatMul_requantize (Requantize_32to8, node_id:2054, index:197, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/output/dense/Add (QuantizedAdd_8p8to8, node_id:2055, index:198, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/output/Add (QuantizedAdd_8p8to8, node_id:2056, index:199, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2057, index:200, shape:[1, 6, 1])
Op: /encoder/layer.3/attention/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2058, index:201, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2059, index:202, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2060, index:203, shape:[1, 6, 1])
Op: /encoder/layer.3/attention/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2061, index:204, shape:[1, 6, 1])
Op: /encoder/layer.3/attention/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2062, index:205, shape:[1, 6, 1])
Op: /encoder/layer.3/attention/output/LayerNorm/Div (QuantizedDiv_8, node_id:2063, index:206, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2064, index:207, shape:[1, 6, 768])
Op: /encoder/layer.3/attention/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2065, index:208, shape:[1, 6, 768])
Op: /encoder/layer.3/intermediate/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2066, index:209, shape:[1, 6, 3072])
Op: /encoder/layer.3/intermediate/dense/MatMul_requantize (Requantize_32to8, node_id:2067, index:210, shape:[1, 6, 3072])
Op: Gelu_/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1 (QuantizedGelu_8, node_id:2068, index:211, shape:[1, 6, 3072])
Op: /encoder/layer.3/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2069, index:212, shape:[1, 6, 768])
Op: /encoder/layer.3/output/dense/MatMul_requantize (Requantize_32to8, node_id:2070, index:213, shape:[1, 6, 768])
Op: /encoder/layer.3/output/dense/Add (QuantizedAdd_8p8to8, node_id:2071, index:214, shape:[1, 6, 768])
Op: /encoder/layer.3/output/Add (QuantizedAdd_8p8to8, node_id:2072, index:215, shape:[1, 6, 768])
Op: /encoder/layer.3/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2073, index:216, shape:[1, 6, 1])
Op: /encoder/layer.3/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2074, index:217, shape:[1, 6, 768])
Op: /encoder/layer.3/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2075, index:218, shape:[1, 6, 768])
Op: /encoder/layer.3/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2076, index:219, shape:[1, 6, 1])
Op: /encoder/layer.3/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2077, index:220, shape:[1, 6, 1])
Op: /encoder/layer.3/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2078, index:221, shape:[1, 6, 1])
Op: /encoder/layer.3/output/LayerNorm/Div (QuantizedDiv_8, node_id:2079, index:222, shape:[1, 6, 768])
Op: /encoder/layer.3/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2080, index:223, shape:[1, 6, 768])
Op: /encoder/layer.3/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2081, index:224, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/self/query/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2082, index:225, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/self/query/MatMul_requantize (Requantize_32to8, node_id:2083, index:226, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/self/query/Add (QuantizedAdd_8p8to8, node_id:2084, index:227, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/self/Reshape_2 (QuantizedReshape, node_id:2085, index:228, shape:[1, 6, 12, 64])
Op: /encoder/layer.4/attention/self/Transpose_1 (Transpose_8, node_id:2086, index:229, shape:[1, 12, 6, 64])
Op: /encoder/layer.4/attention/self/key/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2087, index:230, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/self/key/MatMul_requantize (Requantize_32to8, node_id:2088, index:231, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/self/key/Add (QuantizedAdd_8p8to8, node_id:2089, index:232, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/self/Reshape (QuantizedReshape, node_id:2090, index:233, shape:[1, 6, 12, 64])
Op: /encoder/layer.4/attention/self/Transpose_2 (Transpose_8, node_id:2091, index:234, shape:[1, 12, 64, 6])
Op: /encoder/layer.4/attention/self/MatMul_matmul (QuantizedBatchMatMul_8x8to32, node_id:2092, index:235, shape:[1, 12, 6, 6])
Op: /encoder/layer.4/attention/self/MatMul_requantize (Requantize_32to8, node_id:2093, index:236, shape:[1, 12, 6, 6])
Op: /encoder/layer.4/attention/self/Div (QuantizedDiv_8, node_id:2094, index:237, shape:[1, 12, 6, 6])
Op: /encoder/layer.4/attention/self/Add (QuantizedAdd_8p8to8, node_id:2095, index:238, shape:[1, 12, 6, 6])
Op: /encoder/layer.4/attention/self/Softmax (QuantizedSoftmax_8, node_id:2096, index:239, shape:[1, 12, 6, 6])
Op: /encoder/layer.4/attention/self/value/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2097, index:240, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/self/value/MatMul_requantize (Requantize_32to8, node_id:2098, index:241, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/self/value/Add (QuantizedAdd_8p8to8, node_id:2099, index:242, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/self/Reshape_1 (QuantizedReshape, node_id:2100, index:243, shape:[1, 6, 12, 64])
Op: /encoder/layer.4/attention/self/Transpose (Transpose_8, node_id:2101, index:244, shape:[1, 12, 6, 64])
Op: /encoder/layer.4/attention/self/MatMul_1_matmul (QuantizedBatchMatMul_8x8to32, node_id:2102, index:245, shape:[1, 12, 6, 64])
Op: /encoder/layer.4/attention/self/MatMul_1_requantize (Requantize_32to8, node_id:2103, index:246, shape:[1, 12, 6, 64])
Op: /encoder/layer.4/attention/self/Transpose_3 (Transpose_8, node_id:2104, index:247, shape:[1, 6, 12, 64])
Op: /encoder/layer.4/attention/self/Reshape_3 (QuantizedReshape, node_id:2105, index:248, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2106, index:249, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/output/dense/MatMul_requantize (Requantize_32to8, node_id:2107, index:250, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/output/dense/Add (QuantizedAdd_8p8to8, node_id:2108, index:251, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/output/Add (QuantizedAdd_8p8to8, node_id:2109, index:252, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2110, index:253, shape:[1, 6, 1])
Op: /encoder/layer.4/attention/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2111, index:254, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2112, index:255, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2113, index:256, shape:[1, 6, 1])
Op: /encoder/layer.4/attention/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2114, index:257, shape:[1, 6, 1])
Op: /encoder/layer.4/attention/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2115, index:258, shape:[1, 6, 1])
Op: /encoder/layer.4/attention/output/LayerNorm/Div (QuantizedDiv_8, node_id:2116, index:259, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2117, index:260, shape:[1, 6, 768])
Op: /encoder/layer.4/attention/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2118, index:261, shape:[1, 6, 768])
Op: /encoder/layer.4/intermediate/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2119, index:262, shape:[1, 6, 3072])
Op: /encoder/layer.4/intermediate/dense/MatMul_requantize (Requantize_32to8, node_id:2120, index:263, shape:[1, 6, 3072])
Op: Gelu_/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1 (QuantizedGelu_8, node_id:2121, index:264, shape:[1, 6, 3072])
Op: /encoder/layer.4/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2122, index:265, shape:[1, 6, 768])
Op: /encoder/layer.4/output/dense/MatMul_requantize (Requantize_32to8, node_id:2123, index:266, shape:[1, 6, 768])
Op: /encoder/layer.4/output/dense/Add (QuantizedAdd_8p8to8, node_id:2124, index:267, shape:[1, 6, 768])
Op: /encoder/layer.4/output/Add (QuantizedAdd_8p8to8, node_id:2125, index:268, shape:[1, 6, 768])
Op: /encoder/layer.4/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2126, index:269, shape:[1, 6, 1])
Op: /encoder/layer.4/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2127, index:270, shape:[1, 6, 768])
Op: /encoder/layer.4/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2128, index:271, shape:[1, 6, 768])
Op: /encoder/layer.4/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2129, index:272, shape:[1, 6, 1])
Op: /encoder/layer.4/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2130, index:273, shape:[1, 6, 1])
Op: /encoder/layer.4/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2131, index:274, shape:[1, 6, 1])
Op: /encoder/layer.4/output/LayerNorm/Div (QuantizedDiv_8, node_id:2132, index:275, shape:[1, 6, 768])
Op: /encoder/layer.4/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2133, index:276, shape:[1, 6, 768])
Op: /encoder/layer.4/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2134, index:277, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/self/query/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2135, index:278, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/self/query/MatMul_requantize (Requantize_32to8, node_id:2136, index:279, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/self/query/Add (QuantizedAdd_8p8to8, node_id:2137, index:280, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/self/Reshape_2 (QuantizedReshape, node_id:2138, index:281, shape:[1, 6, 12, 64])
Op: /encoder/layer.5/attention/self/Transpose_1 (Transpose_8, node_id:2139, index:282, shape:[1, 12, 6, 64])
Op: /encoder/layer.5/attention/self/key/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2140, index:283, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/self/key/MatMul_requantize (Requantize_32to8, node_id:2141, index:284, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/self/key/Add (QuantizedAdd_8p8to8, node_id:2142, index:285, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/self/Reshape (QuantizedReshape, node_id:2143, index:286, shape:[1, 6, 12, 64])
Op: /encoder/layer.5/attention/self/Transpose_2 (Transpose_8, node_id:2144, index:287, shape:[1, 12, 64, 6])
Op: /encoder/layer.5/attention/self/MatMul_matmul (QuantizedBatchMatMul_8x8to32, node_id:2145, index:288, shape:[1, 12, 6, 6])
Op: /encoder/layer.5/attention/self/MatMul_requantize (Requantize_32to8, node_id:2146, index:289, shape:[1, 12, 6, 6])
Op: /encoder/layer.5/attention/self/Div (QuantizedDiv_8, node_id:2147, index:290, shape:[1, 12, 6, 6])
Op: /encoder/layer.5/attention/self/Add (QuantizedAdd_8p8to8, node_id:2148, index:291, shape:[1, 12, 6, 6])
Op: /encoder/layer.5/attention/self/Softmax (QuantizedSoftmax_8, node_id:2149, index:292, shape:[1, 12, 6, 6])
Op: /encoder/layer.5/attention/self/value/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2150, index:293, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/self/value/MatMul_requantize (Requantize_32to8, node_id:2151, index:294, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/self/value/Add (QuantizedAdd_8p8to8, node_id:2152, index:295, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/self/Reshape_1 (QuantizedReshape, node_id:2153, index:296, shape:[1, 6, 12, 64])
Op: /encoder/layer.5/attention/self/Transpose (Transpose_8, node_id:2154, index:297, shape:[1, 12, 6, 64])
Op: /encoder/layer.5/attention/self/MatMul_1_matmul (QuantizedBatchMatMul_8x8to32, node_id:2155, index:298, shape:[1, 12, 6, 64])
Op: /encoder/layer.5/attention/self/MatMul_1_requantize (Requantize_32to8, node_id:2156, index:299, shape:[1, 12, 6, 64])
Op: /encoder/layer.5/attention/self/Transpose_3 (Transpose_8, node_id:2157, index:300, shape:[1, 6, 12, 64])
Op: /encoder/layer.5/attention/self/Reshape_3 (QuantizedReshape, node_id:2158, index:301, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2159, index:302, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/output/dense/MatMul_requantize (Requantize_32to8, node_id:2160, index:303, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/output/dense/Add (QuantizedAdd_8p8to8, node_id:2161, index:304, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/output/Add (QuantizedAdd_8p8to8, node_id:2162, index:305, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2163, index:306, shape:[1, 6, 1])
Op: /encoder/layer.5/attention/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2164, index:307, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2165, index:308, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2166, index:309, shape:[1, 6, 1])
Op: /encoder/layer.5/attention/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2167, index:310, shape:[1, 6, 1])
Op: /encoder/layer.5/attention/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2168, index:311, shape:[1, 6, 1])
Op: /encoder/layer.5/attention/output/LayerNorm/Div (QuantizedDiv_8, node_id:2169, index:312, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2170, index:313, shape:[1, 6, 768])
Op: /encoder/layer.5/attention/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2171, index:314, shape:[1, 6, 768])
Op: /encoder/layer.5/intermediate/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2172, index:315, shape:[1, 6, 3072])
Op: /encoder/layer.5/intermediate/dense/MatMul_requantize (Requantize_32to8, node_id:2173, index:316, shape:[1, 6, 3072])
Op: Gelu_/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1 (QuantizedGelu_8, node_id:2174, index:317, shape:[1, 6, 3072])
Op: /encoder/layer.5/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2175, index:318, shape:[1, 6, 768])
Op: /encoder/layer.5/output/dense/MatMul_requantize (Requantize_32to8, node_id:2176, index:319, shape:[1, 6, 768])
Op: /encoder/layer.5/output/dense/Add (QuantizedAdd_8p8to8, node_id:2177, index:320, shape:[1, 6, 768])
Op: /encoder/layer.5/output/Add (QuantizedAdd_8p8to8, node_id:2178, index:321, shape:[1, 6, 768])
Op: /encoder/layer.5/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2179, index:322, shape:[1, 6, 1])
Op: /encoder/layer.5/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2180, index:323, shape:[1, 6, 768])
Op: /encoder/layer.5/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2181, index:324, shape:[1, 6, 768])
Op: /encoder/layer.5/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2182, index:325, shape:[1, 6, 1])
Op: /encoder/layer.5/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2183, index:326, shape:[1, 6, 1])
Op: /encoder/layer.5/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2184, index:327, shape:[1, 6, 1])
Op: /encoder/layer.5/output/LayerNorm/Div (QuantizedDiv_8, node_id:2185, index:328, shape:[1, 6, 768])
Op: /encoder/layer.5/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2186, index:329, shape:[1, 6, 768])
Op: /encoder/layer.5/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2187, index:330, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/self/query/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2188, index:331, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/self/query/MatMul_requantize (Requantize_32to8, node_id:2189, index:332, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/self/query/Add (QuantizedAdd_8p8to8, node_id:2190, index:333, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/self/Reshape_2 (QuantizedReshape, node_id:2191, index:334, shape:[1, 6, 12, 64])
Op: /encoder/layer.6/attention/self/Transpose_1 (Transpose_8, node_id:2192, index:335, shape:[1, 12, 6, 64])
Op: /encoder/layer.6/attention/self/key/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2193, index:336, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/self/key/MatMul_requantize (Requantize_32to8, node_id:2194, index:337, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/self/key/Add (QuantizedAdd_8p8to8, node_id:2195, index:338, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/self/Reshape (QuantizedReshape, node_id:2196, index:339, shape:[1, 6, 12, 64])
Op: /encoder/layer.6/attention/self/Transpose_2 (Transpose_8, node_id:2197, index:340, shape:[1, 12, 64, 6])
Op: /encoder/layer.6/attention/self/MatMul_matmul (QuantizedBatchMatMul_8x8to32, node_id:2198, index:341, shape:[1, 12, 6, 6])
Op: /encoder/layer.6/attention/self/MatMul_requantize (Requantize_32to8, node_id:2199, index:342, shape:[1, 12, 6, 6])
Op: /encoder/layer.6/attention/self/Div (QuantizedDiv_8, node_id:2200, index:343, shape:[1, 12, 6, 6])
Op: /encoder/layer.6/attention/self/Add (QuantizedAdd_8p8to8, node_id:2201, index:344, shape:[1, 12, 6, 6])
Op: /encoder/layer.6/attention/self/Softmax (QuantizedSoftmax_8, node_id:2202, index:345, shape:[1, 12, 6, 6])
Op: /encoder/layer.6/attention/self/value/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2203, index:346, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/self/value/MatMul_requantize (Requantize_32to8, node_id:2204, index:347, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/self/value/Add (QuantizedAdd_8p8to8, node_id:2205, index:348, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/self/Reshape_1 (QuantizedReshape, node_id:2206, index:349, shape:[1, 6, 12, 64])
Op: /encoder/layer.6/attention/self/Transpose (Transpose_8, node_id:2207, index:350, shape:[1, 12, 6, 64])
Op: /encoder/layer.6/attention/self/MatMul_1_matmul (QuantizedBatchMatMul_8x8to32, node_id:2208, index:351, shape:[1, 12, 6, 64])
Op: /encoder/layer.6/attention/self/MatMul_1_requantize (Requantize_32to8, node_id:2209, index:352, shape:[1, 12, 6, 64])
Op: /encoder/layer.6/attention/self/Transpose_3 (Transpose_8, node_id:2210, index:353, shape:[1, 6, 12, 64])
Op: /encoder/layer.6/attention/self/Reshape_3 (QuantizedReshape, node_id:2211, index:354, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2212, index:355, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/output/dense/MatMul_requantize (Requantize_32to8, node_id:2213, index:356, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/output/dense/Add (QuantizedAdd_8p8to8, node_id:2214, index:357, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/output/Add (QuantizedAdd_8p8to8, node_id:2215, index:358, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2216, index:359, shape:[1, 6, 1])
Op: /encoder/layer.6/attention/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2217, index:360, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2218, index:361, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2219, index:362, shape:[1, 6, 1])
Op: /encoder/layer.6/attention/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2220, index:363, shape:[1, 6, 1])
Op: /encoder/layer.6/attention/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2221, index:364, shape:[1, 6, 1])
Op: /encoder/layer.6/attention/output/LayerNorm/Div (QuantizedDiv_8, node_id:2222, index:365, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2223, index:366, shape:[1, 6, 768])
Op: /encoder/layer.6/attention/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2224, index:367, shape:[1, 6, 768])
Op: /encoder/layer.6/intermediate/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2225, index:368, shape:[1, 6, 3072])
Op: /encoder/layer.6/intermediate/dense/MatMul_requantize (Requantize_32to8, node_id:2226, index:369, shape:[1, 6, 3072])
Op: Gelu_/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1 (QuantizedGelu_8, node_id:2227, index:370, shape:[1, 6, 3072])
Op: /encoder/layer.6/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2228, index:371, shape:[1, 6, 768])
Op: /encoder/layer.6/output/dense/MatMul_requantize (Requantize_32to8, node_id:2229, index:372, shape:[1, 6, 768])
Op: /encoder/layer.6/output/dense/Add (QuantizedAdd_8p8to8, node_id:2230, index:373, shape:[1, 6, 768])
Op: /encoder/layer.6/output/Add (QuantizedAdd_8p8to8, node_id:2231, index:374, shape:[1, 6, 768])
Op: /encoder/layer.6/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2232, index:375, shape:[1, 6, 1])
Op: /encoder/layer.6/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2233, index:376, shape:[1, 6, 768])
Op: /encoder/layer.6/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2234, index:377, shape:[1, 6, 768])
Op: /encoder/layer.6/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2235, index:378, shape:[1, 6, 1])
Op: /encoder/layer.6/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2236, index:379, shape:[1, 6, 1])
Op: /encoder/layer.6/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2237, index:380, shape:[1, 6, 1])
Op: /encoder/layer.6/output/LayerNorm/Div (QuantizedDiv_8, node_id:2238, index:381, shape:[1, 6, 768])
Op: /encoder/layer.6/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2239, index:382, shape:[1, 6, 768])
Op: /encoder/layer.6/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2240, index:383, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/self/query/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2241, index:384, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/self/query/MatMul_requantize (Requantize_32to8, node_id:2242, index:385, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/self/query/Add (QuantizedAdd_8p8to8, node_id:2243, index:386, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/self/Reshape_2 (QuantizedReshape, node_id:2244, index:387, shape:[1, 6, 12, 64])
Op: /encoder/layer.7/attention/self/Transpose_1 (Transpose_8, node_id:2245, index:388, shape:[1, 12, 6, 64])
Op: /encoder/layer.7/attention/self/key/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2246, index:389, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/self/key/MatMul_requantize (Requantize_32to8, node_id:2247, index:390, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/self/key/Add (QuantizedAdd_8p8to8, node_id:2248, index:391, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/self/Reshape (QuantizedReshape, node_id:2249, index:392, shape:[1, 6, 12, 64])
Op: /encoder/layer.7/attention/self/Transpose_2 (Transpose_8, node_id:2250, index:393, shape:[1, 12, 64, 6])
Op: /encoder/layer.7/attention/self/MatMul_matmul (QuantizedBatchMatMul_8x8to32, node_id:2251, index:394, shape:[1, 12, 6, 6])
Op: /encoder/layer.7/attention/self/MatMul_requantize (Requantize_32to8, node_id:2252, index:395, shape:[1, 12, 6, 6])
Op: /encoder/layer.7/attention/self/Div (QuantizedDiv_8, node_id:2253, index:396, shape:[1, 12, 6, 6])
Op: /encoder/layer.7/attention/self/Add (QuantizedAdd_8p8to8, node_id:2254, index:397, shape:[1, 12, 6, 6])
Op: /encoder/layer.7/attention/self/Softmax (QuantizedSoftmax_8, node_id:2255, index:398, shape:[1, 12, 6, 6])
Op: /encoder/layer.7/attention/self/value/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2256, index:399, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/self/value/MatMul_requantize (Requantize_32to8, node_id:2257, index:400, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/self/value/Add (QuantizedAdd_8p8to8, node_id:2258, index:401, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/self/Reshape_1 (QuantizedReshape, node_id:2259, index:402, shape:[1, 6, 12, 64])
Op: /encoder/layer.7/attention/self/Transpose (Transpose_8, node_id:2260, index:403, shape:[1, 12, 6, 64])
Op: /encoder/layer.7/attention/self/MatMul_1_matmul (QuantizedBatchMatMul_8x8to32, node_id:2261, index:404, shape:[1, 12, 6, 64])
Op: /encoder/layer.7/attention/self/MatMul_1_requantize (Requantize_32to8, node_id:2262, index:405, shape:[1, 12, 6, 64])
Op: /encoder/layer.7/attention/self/Transpose_3 (Transpose_8, node_id:2263, index:406, shape:[1, 6, 12, 64])
Op: /encoder/layer.7/attention/self/Reshape_3 (QuantizedReshape, node_id:2264, index:407, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2265, index:408, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/output/dense/MatMul_requantize (Requantize_32to8, node_id:2266, index:409, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/output/dense/Add (QuantizedAdd_8p8to8, node_id:2267, index:410, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/output/Add (QuantizedAdd_8p8to8, node_id:2268, index:411, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2269, index:412, shape:[1, 6, 1])
Op: /encoder/layer.7/attention/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2270, index:413, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2271, index:414, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2272, index:415, shape:[1, 6, 1])
Op: /encoder/layer.7/attention/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2273, index:416, shape:[1, 6, 1])
Op: /encoder/layer.7/attention/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2274, index:417, shape:[1, 6, 1])
Op: /encoder/layer.7/attention/output/LayerNorm/Div (QuantizedDiv_8, node_id:2275, index:418, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2276, index:419, shape:[1, 6, 768])
Op: /encoder/layer.7/attention/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2277, index:420, shape:[1, 6, 768])
Op: /encoder/layer.7/intermediate/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2278, index:421, shape:[1, 6, 3072])
Op: /encoder/layer.7/intermediate/dense/MatMul_requantize (Requantize_32to8, node_id:2279, index:422, shape:[1, 6, 3072])
Op: Gelu_/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1 (QuantizedGelu_8, node_id:2280, index:423, shape:[1, 6, 3072])
Op: /encoder/layer.7/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2281, index:424, shape:[1, 6, 768])
Op: /encoder/layer.7/output/dense/MatMul_requantize (Requantize_32to8, node_id:2282, index:425, shape:[1, 6, 768])
Op: /encoder/layer.7/output/dense/Add (QuantizedAdd_8p8to8, node_id:2283, index:426, shape:[1, 6, 768])
Op: /encoder/layer.7/output/Add (QuantizedAdd_8p8to8, node_id:2284, index:427, shape:[1, 6, 768])
Op: /encoder/layer.7/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2285, index:428, shape:[1, 6, 1])
Op: /encoder/layer.7/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2286, index:429, shape:[1, 6, 768])
Op: /encoder/layer.7/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2287, index:430, shape:[1, 6, 768])
Op: /encoder/layer.7/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2288, index:431, shape:[1, 6, 1])
Op: /encoder/layer.7/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2289, index:432, shape:[1, 6, 1])
Op: /encoder/layer.7/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2290, index:433, shape:[1, 6, 1])
Op: /encoder/layer.7/output/LayerNorm/Div (QuantizedDiv_8, node_id:2291, index:434, shape:[1, 6, 768])
Op: /encoder/layer.7/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2292, index:435, shape:[1, 6, 768])
Op: /encoder/layer.7/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2293, index:436, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/self/query/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2294, index:437, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/self/query/MatMul_requantize (Requantize_32to8, node_id:2295, index:438, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/self/query/Add (QuantizedAdd_8p8to8, node_id:2296, index:439, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/self/Reshape_2 (QuantizedReshape, node_id:2297, index:440, shape:[1, 6, 12, 64])
Op: /encoder/layer.8/attention/self/Transpose_1 (Transpose_8, node_id:2298, index:441, shape:[1, 12, 6, 64])
Op: /encoder/layer.8/attention/self/key/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2299, index:442, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/self/key/MatMul_requantize (Requantize_32to8, node_id:2300, index:443, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/self/key/Add (QuantizedAdd_8p8to8, node_id:2301, index:444, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/self/Reshape (QuantizedReshape, node_id:2302, index:445, shape:[1, 6, 12, 64])
Op: /encoder/layer.8/attention/self/Transpose_2 (Transpose_8, node_id:2303, index:446, shape:[1, 12, 64, 6])
Op: /encoder/layer.8/attention/self/MatMul_matmul (QuantizedBatchMatMul_8x8to32, node_id:2304, index:447, shape:[1, 12, 6, 6])
Op: /encoder/layer.8/attention/self/MatMul_requantize (Requantize_32to8, node_id:2305, index:448, shape:[1, 12, 6, 6])
Op: /encoder/layer.8/attention/self/Div (QuantizedDiv_8, node_id:2306, index:449, shape:[1, 12, 6, 6])
Op: /encoder/layer.8/attention/self/Add (QuantizedAdd_8p8to8, node_id:2307, index:450, shape:[1, 12, 6, 6])
Op: /encoder/layer.8/attention/self/Softmax (QuantizedSoftmax_8, node_id:2308, index:451, shape:[1, 12, 6, 6])
Op: /encoder/layer.8/attention/self/value/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2309, index:452, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/self/value/MatMul_requantize (Requantize_32to8, node_id:2310, index:453, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/self/value/Add (QuantizedAdd_8p8to8, node_id:2311, index:454, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/self/Reshape_1 (QuantizedReshape, node_id:2312, index:455, shape:[1, 6, 12, 64])
Op: /encoder/layer.8/attention/self/Transpose (Transpose_8, node_id:2313, index:456, shape:[1, 12, 6, 64])
Op: /encoder/layer.8/attention/self/MatMul_1_matmul (QuantizedBatchMatMul_8x8to32, node_id:2314, index:457, shape:[1, 12, 6, 64])
Op: /encoder/layer.8/attention/self/MatMul_1_requantize (Requantize_32to8, node_id:2315, index:458, shape:[1, 12, 6, 64])
Op: /encoder/layer.8/attention/self/Transpose_3 (Transpose_8, node_id:2316, index:459, shape:[1, 6, 12, 64])
Op: /encoder/layer.8/attention/self/Reshape_3 (QuantizedReshape, node_id:2317, index:460, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2318, index:461, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/output/dense/MatMul_requantize (Requantize_32to8, node_id:2319, index:462, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/output/dense/Add (QuantizedAdd_8p8to8, node_id:2320, index:463, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/output/Add (QuantizedAdd_8p8to8, node_id:2321, index:464, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2322, index:465, shape:[1, 6, 1])
Op: /encoder/layer.8/attention/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2323, index:466, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2324, index:467, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2325, index:468, shape:[1, 6, 1])
Op: /encoder/layer.8/attention/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2326, index:469, shape:[1, 6, 1])
Op: /encoder/layer.8/attention/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2327, index:470, shape:[1, 6, 1])
Op: /encoder/layer.8/attention/output/LayerNorm/Div (QuantizedDiv_8, node_id:2328, index:471, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2329, index:472, shape:[1, 6, 768])
Op: /encoder/layer.8/attention/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2330, index:473, shape:[1, 6, 768])
Op: /encoder/layer.8/intermediate/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2331, index:474, shape:[1, 6, 3072])
Op: /encoder/layer.8/intermediate/dense/MatMul_requantize (Requantize_32to8, node_id:2332, index:475, shape:[1, 6, 3072])
Op: Gelu_/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1 (QuantizedGelu_8, node_id:2333, index:476, shape:[1, 6, 3072])
Op: /encoder/layer.8/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2334, index:477, shape:[1, 6, 768])
Op: /encoder/layer.8/output/dense/MatMul_requantize (Requantize_32to8, node_id:2335, index:478, shape:[1, 6, 768])
Op: /encoder/layer.8/output/dense/Add (QuantizedAdd_8p8to8, node_id:2336, index:479, shape:[1, 6, 768])
Op: /encoder/layer.8/output/Add (QuantizedAdd_8p8to8, node_id:2337, index:480, shape:[1, 6, 768])
Op: /encoder/layer.8/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2338, index:481, shape:[1, 6, 1])
Op: /encoder/layer.8/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2339, index:482, shape:[1, 6, 768])
Op: /encoder/layer.8/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2340, index:483, shape:[1, 6, 768])
Op: /encoder/layer.8/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2341, index:484, shape:[1, 6, 1])
Op: /encoder/layer.8/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2342, index:485, shape:[1, 6, 1])
Op: /encoder/layer.8/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2343, index:486, shape:[1, 6, 1])
Op: /encoder/layer.8/output/LayerNorm/Div (QuantizedDiv_8, node_id:2344, index:487, shape:[1, 6, 768])
Op: /encoder/layer.8/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2345, index:488, shape:[1, 6, 768])
Op: /encoder/layer.8/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2346, index:489, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/self/query/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2347, index:490, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/self/query/MatMul_requantize (Requantize_32to8, node_id:2348, index:491, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/self/query/Add (QuantizedAdd_8p8to8, node_id:2349, index:492, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/self/Reshape_2 (QuantizedReshape, node_id:2350, index:493, shape:[1, 6, 12, 64])
Op: /encoder/layer.9/attention/self/Transpose_1 (Transpose_8, node_id:2351, index:494, shape:[1, 12, 6, 64])
Op: /encoder/layer.9/attention/self/key/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2352, index:495, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/self/key/MatMul_requantize (Requantize_32to8, node_id:2353, index:496, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/self/key/Add (QuantizedAdd_8p8to8, node_id:2354, index:497, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/self/Reshape (QuantizedReshape, node_id:2355, index:498, shape:[1, 6, 12, 64])
Op: /encoder/layer.9/attention/self/Transpose_2 (Transpose_8, node_id:2356, index:499, shape:[1, 12, 64, 6])
Op: /encoder/layer.9/attention/self/MatMul_matmul (QuantizedBatchMatMul_8x8to32, node_id:2357, index:500, shape:[1, 12, 6, 6])
Op: /encoder/layer.9/attention/self/MatMul_requantize (Requantize_32to8, node_id:2358, index:501, shape:[1, 12, 6, 6])
Op: /encoder/layer.9/attention/self/Div (QuantizedDiv_8, node_id:2359, index:502, shape:[1, 12, 6, 6])
Op: /encoder/layer.9/attention/self/Add (QuantizedAdd_8p8to8, node_id:2360, index:503, shape:[1, 12, 6, 6])
Op: /encoder/layer.9/attention/self/Softmax (QuantizedSoftmax_8, node_id:2361, index:504, shape:[1, 12, 6, 6])
Op: /encoder/layer.9/attention/self/value/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2362, index:505, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/self/value/MatMul_requantize (Requantize_32to8, node_id:2363, index:506, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/self/value/Add (QuantizedAdd_8p8to8, node_id:2364, index:507, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/self/Reshape_1 (QuantizedReshape, node_id:2365, index:508, shape:[1, 6, 12, 64])
Op: /encoder/layer.9/attention/self/Transpose (Transpose_8, node_id:2366, index:509, shape:[1, 12, 6, 64])
Op: /encoder/layer.9/attention/self/MatMul_1_matmul (QuantizedBatchMatMul_8x8to32, node_id:2367, index:510, shape:[1, 12, 6, 64])
Op: /encoder/layer.9/attention/self/MatMul_1_requantize (Requantize_32to8, node_id:2368, index:511, shape:[1, 12, 6, 64])
Op: /encoder/layer.9/attention/self/Transpose_3 (Transpose_8, node_id:2369, index:512, shape:[1, 6, 12, 64])
Op: /encoder/layer.9/attention/self/Reshape_3 (QuantizedReshape, node_id:2370, index:513, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2371, index:514, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/output/dense/MatMul_requantize (Requantize_32to8, node_id:2372, index:515, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/output/dense/Add (QuantizedAdd_8p8to8, node_id:2373, index:516, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/output/Add (QuantizedAdd_8p8to8, node_id:2374, index:517, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2375, index:518, shape:[1, 6, 1])
Op: /encoder/layer.9/attention/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2376, index:519, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2377, index:520, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2378, index:521, shape:[1, 6, 1])
Op: /encoder/layer.9/attention/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2379, index:522, shape:[1, 6, 1])
Op: /encoder/layer.9/attention/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2380, index:523, shape:[1, 6, 1])
Op: /encoder/layer.9/attention/output/LayerNorm/Div (QuantizedDiv_8, node_id:2381, index:524, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2382, index:525, shape:[1, 6, 768])
Op: /encoder/layer.9/attention/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2383, index:526, shape:[1, 6, 768])
Op: /encoder/layer.9/intermediate/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2384, index:527, shape:[1, 6, 3072])
Op: /encoder/layer.9/intermediate/dense/MatMul_requantize (Requantize_32to8, node_id:2385, index:528, shape:[1, 6, 3072])
Op: Gelu_/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1 (QuantizedGelu_8, node_id:2386, index:529, shape:[1, 6, 3072])
Op: /encoder/layer.9/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2387, index:530, shape:[1, 6, 768])
Op: /encoder/layer.9/output/dense/MatMul_requantize (Requantize_32to8, node_id:2388, index:531, shape:[1, 6, 768])
Op: /encoder/layer.9/output/dense/Add (QuantizedAdd_8p8to8, node_id:2389, index:532, shape:[1, 6, 768])
Op: /encoder/layer.9/output/Add (QuantizedAdd_8p8to8, node_id:2390, index:533, shape:[1, 6, 768])
Op: /encoder/layer.9/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2391, index:534, shape:[1, 6, 1])
Op: /encoder/layer.9/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2392, index:535, shape:[1, 6, 768])
Op: /encoder/layer.9/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2393, index:536, shape:[1, 6, 768])
Op: /encoder/layer.9/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2394, index:537, shape:[1, 6, 1])
Op: /encoder/layer.9/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2395, index:538, shape:[1, 6, 1])
Op: /encoder/layer.9/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2396, index:539, shape:[1, 6, 1])
Op: /encoder/layer.9/output/LayerNorm/Div (QuantizedDiv_8, node_id:2397, index:540, shape:[1, 6, 768])
Op: /encoder/layer.9/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2398, index:541, shape:[1, 6, 768])
Op: /encoder/layer.9/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2399, index:542, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/self/query/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2400, index:543, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/self/query/MatMul_requantize (Requantize_32to8, node_id:2401, index:544, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/self/query/Add (QuantizedAdd_8p8to8, node_id:2402, index:545, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/self/Reshape_2 (QuantizedReshape, node_id:2403, index:546, shape:[1, 6, 12, 64])
Op: /encoder/layer.10/attention/self/Transpose_1 (Transpose_8, node_id:2404, index:547, shape:[1, 12, 6, 64])
Op: /encoder/layer.10/attention/self/key/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2405, index:548, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/self/key/MatMul_requantize (Requantize_32to8, node_id:2406, index:549, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/self/key/Add (QuantizedAdd_8p8to8, node_id:2407, index:550, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/self/Reshape (QuantizedReshape, node_id:2408, index:551, shape:[1, 6, 12, 64])
Op: /encoder/layer.10/attention/self/Transpose_2 (Transpose_8, node_id:2409, index:552, shape:[1, 12, 64, 6])
Op: /encoder/layer.10/attention/self/MatMul_matmul (QuantizedBatchMatMul_8x8to32, node_id:2410, index:553, shape:[1, 12, 6, 6])
Op: /encoder/layer.10/attention/self/MatMul_requantize (Requantize_32to8, node_id:2411, index:554, shape:[1, 12, 6, 6])
Op: /encoder/layer.10/attention/self/Div (QuantizedDiv_8, node_id:2412, index:555, shape:[1, 12, 6, 6])
Op: /encoder/layer.10/attention/self/Add (QuantizedAdd_8p8to8, node_id:2413, index:556, shape:[1, 12, 6, 6])
Op: /encoder/layer.10/attention/self/Softmax (QuantizedSoftmax_8, node_id:2414, index:557, shape:[1, 12, 6, 6])
Op: /encoder/layer.10/attention/self/value/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2415, index:558, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/self/value/MatMul_requantize (Requantize_32to8, node_id:2416, index:559, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/self/value/Add (QuantizedAdd_8p8to8, node_id:2417, index:560, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/self/Reshape_1 (QuantizedReshape, node_id:2418, index:561, shape:[1, 6, 12, 64])
Op: /encoder/layer.10/attention/self/Transpose (Transpose_8, node_id:2419, index:562, shape:[1, 12, 6, 64])
Op: /encoder/layer.10/attention/self/MatMul_1_matmul (QuantizedBatchMatMul_8x8to32, node_id:2420, index:563, shape:[1, 12, 6, 64])
Op: /encoder/layer.10/attention/self/MatMul_1_requantize (Requantize_32to8, node_id:2421, index:564, shape:[1, 12, 6, 64])
Op: /encoder/layer.10/attention/self/Transpose_3 (Transpose_8, node_id:2422, index:565, shape:[1, 6, 12, 64])
Op: /encoder/layer.10/attention/self/Reshape_3 (QuantizedReshape, node_id:2423, index:566, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2424, index:567, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/output/dense/MatMul_requantize (Requantize_32to8, node_id:2425, index:568, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/output/dense/Add (QuantizedAdd_8p8to8, node_id:2426, index:569, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/output/Add (QuantizedAdd_8p8to8, node_id:2427, index:570, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2428, index:571, shape:[1, 6, 1])
Op: /encoder/layer.10/attention/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2429, index:572, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2430, index:573, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2431, index:574, shape:[1, 6, 1])
Op: /encoder/layer.10/attention/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2432, index:575, shape:[1, 6, 1])
Op: /encoder/layer.10/attention/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2433, index:576, shape:[1, 6, 1])
Op: /encoder/layer.10/attention/output/LayerNorm/Div (QuantizedDiv_8, node_id:2434, index:577, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2435, index:578, shape:[1, 6, 768])
Op: /encoder/layer.10/attention/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2436, index:579, shape:[1, 6, 768])
Op: /encoder/layer.10/intermediate/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2437, index:580, shape:[1, 6, 3072])
Op: /encoder/layer.10/intermediate/dense/MatMul_requantize (Requantize_32to8, node_id:2438, index:581, shape:[1, 6, 3072])
Op: Gelu_/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1 (QuantizedGelu_8, node_id:2439, index:582, shape:[1, 6, 3072])
Op: /encoder/layer.10/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2440, index:583, shape:[1, 6, 768])
Op: /encoder/layer.10/output/dense/MatMul_requantize (Requantize_32to8, node_id:2441, index:584, shape:[1, 6, 768])
Op: /encoder/layer.10/output/dense/Add (QuantizedAdd_8p8to8, node_id:2442, index:585, shape:[1, 6, 768])
Op: /encoder/layer.10/output/Add (QuantizedAdd_8p8to8, node_id:2443, index:586, shape:[1, 6, 768])
Op: /encoder/layer.10/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2444, index:587, shape:[1, 6, 1])
Op: /encoder/layer.10/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2445, index:588, shape:[1, 6, 768])
Op: /encoder/layer.10/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2446, index:589, shape:[1, 6, 768])
Op: /encoder/layer.10/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2447, index:590, shape:[1, 6, 1])
Op: /encoder/layer.10/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2448, index:591, shape:[1, 6, 1])
Op: /encoder/layer.10/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2449, index:592, shape:[1, 6, 1])
Op: /encoder/layer.10/output/LayerNorm/Div (QuantizedDiv_8, node_id:2450, index:593, shape:[1, 6, 768])
Op: /encoder/layer.10/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2451, index:594, shape:[1, 6, 768])
Op: /encoder/layer.10/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2452, index:595, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/self/query/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2453, index:596, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/self/query/MatMul_requantize (Requantize_32to8, node_id:2454, index:597, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/self/query/Add (QuantizedAdd_8p8to8, node_id:2455, index:598, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/self/Reshape_2 (QuantizedReshape, node_id:2456, index:599, shape:[1, 6, 12, 64])
Op: /encoder/layer.11/attention/self/Transpose_1 (Transpose_8, node_id:2457, index:600, shape:[1, 12, 6, 64])
Op: /encoder/layer.11/attention/self/key/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2458, index:601, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/self/key/MatMul_requantize (Requantize_32to8, node_id:2459, index:602, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/self/key/Add (QuantizedAdd_8p8to8, node_id:2460, index:603, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/self/Reshape (QuantizedReshape, node_id:2461, index:604, shape:[1, 6, 12, 64])
Op: /encoder/layer.11/attention/self/Transpose_2 (Transpose_8, node_id:2462, index:605, shape:[1, 12, 64, 6])
Op: /encoder/layer.11/attention/self/MatMul_matmul (QuantizedBatchMatMul_8x8to32, node_id:2463, index:606, shape:[1, 12, 6, 6])
Op: /encoder/layer.11/attention/self/MatMul_requantize (Requantize_32to8, node_id:2464, index:607, shape:[1, 12, 6, 6])
Op: /encoder/layer.11/attention/self/Div (QuantizedDiv_8, node_id:2465, index:608, shape:[1, 12, 6, 6])
Op: /encoder/layer.11/attention/self/Add (QuantizedAdd_8p8to8, node_id:2466, index:609, shape:[1, 12, 6, 6])
Op: /encoder/layer.11/attention/self/Softmax (QuantizedSoftmax_8, node_id:2467, index:610, shape:[1, 12, 6, 6])
Op: /encoder/layer.11/attention/self/value/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2468, index:611, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/self/value/MatMul_requantize (Requantize_32to8, node_id:2469, index:612, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/self/value/Add (QuantizedAdd_8p8to8, node_id:2470, index:613, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/self/Reshape_1 (QuantizedReshape, node_id:2471, index:614, shape:[1, 6, 12, 64])
Op: /encoder/layer.11/attention/self/Transpose (Transpose_8, node_id:2472, index:615, shape:[1, 12, 6, 64])
Op: /encoder/layer.11/attention/self/MatMul_1_matmul (QuantizedBatchMatMul_8x8to32, node_id:2473, index:616, shape:[1, 12, 6, 64])
Op: /encoder/layer.11/attention/self/MatMul_1_requantize (Requantize_32to8, node_id:2474, index:617, shape:[1, 12, 6, 64])
Op: /encoder/layer.11/attention/self/Transpose_3 (Transpose_8, node_id:2475, index:618, shape:[1, 6, 12, 64])
Op: /encoder/layer.11/attention/self/Reshape_3 (QuantizedReshape, node_id:2476, index:619, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2477, index:620, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/output/dense/MatMul_requantize (Requantize_32to8, node_id:2478, index:621, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/output/dense/Add (QuantizedAdd_8p8to8, node_id:2479, index:622, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/output/Add (QuantizedAdd_8p8to8, node_id:2480, index:623, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2481, index:624, shape:[1, 6, 1])
Op: /encoder/layer.11/attention/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2482, index:625, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2483, index:626, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2484, index:627, shape:[1, 6, 1])
Op: /encoder/layer.11/attention/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2485, index:628, shape:[1, 6, 1])
Op: /encoder/layer.11/attention/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2486, index:629, shape:[1, 6, 1])
Op: /encoder/layer.11/attention/output/LayerNorm/Div (QuantizedDiv_8, node_id:2487, index:630, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2488, index:631, shape:[1, 6, 768])
Op: /encoder/layer.11/attention/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2489, index:632, shape:[1, 6, 768])
Op: /encoder/layer.11/intermediate/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2490, index:633, shape:[1, 6, 3072])
Op: /encoder/layer.11/intermediate/dense/MatMul_requantize (Requantize_32to8, node_id:2491, index:634, shape:[1, 6, 3072])
Op: Gelu_/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1 (QuantizedGelu_8, node_id:2492, index:635, shape:[1, 6, 3072])
Op: /encoder/layer.11/output/dense/MatMul_matmul (QuantizedMatMul_8x8to32, node_id:2493, index:636, shape:[1, 6, 768])
Op: /encoder/layer.11/output/dense/MatMul_requantize (Requantize_32to8, node_id:2494, index:637, shape:[1, 6, 768])
Op: /encoder/layer.11/output/dense/Add (QuantizedAdd_8p8to8, node_id:2495, index:638, shape:[1, 6, 768])
Op: /encoder/layer.11/output/Add (QuantizedAdd_8p8to8, node_id:2496, index:639, shape:[1, 6, 768])
Op: /encoder/layer.11/output/LayerNorm/ReduceMean (QuantizedMean_8, node_id:2497, index:640, shape:[1, 6, 1])
Op: /encoder/layer.11/output/LayerNorm/Sub (QuantizedSub_8p8to8, node_id:2498, index:641, shape:[1, 6, 768])
Op: /encoder/layer.11/output/LayerNorm/Pow (QuantizedMul_8x8to8, node_id:2499, index:642, shape:[1, 6, 768])
Op: /encoder/layer.11/output/LayerNorm/ReduceMean_1 (QuantizedMean_8, node_id:2500, index:643, shape:[1, 6, 1])
Op: /encoder/layer.11/output/LayerNorm/Add (QuantizedAdd_8p8to8, node_id:2501, index:644, shape:[1, 6, 1])
Op: /encoder/layer.11/output/LayerNorm/Sqrt (QuantizedSqrt_8, node_id:2502, index:645, shape:[1, 6, 1])
Op: /encoder/layer.11/output/LayerNorm/Div (QuantizedDiv_8, node_id:2503, index:646, shape:[1, 6, 768])
Op: /encoder/layer.11/output/LayerNorm/Mul (QuantizedMul_8x8to8, node_id:2504, index:647, shape:[1, 6, 768])
Op: mace_output_node_/encoder/layer.11/output/LayerNorm/Add_1 (QuantizedAdd_8p8to8, node_id:2505, index:648, shape:[1, 6, 768])
Op: pooler_output (DequantizeOUTPUT_8tof, node_id:2511, index:)
